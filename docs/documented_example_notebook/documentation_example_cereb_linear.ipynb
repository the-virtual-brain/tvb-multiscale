{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVB-NEST: Bridging multiscale activity by co-simulation\n",
    "\n",
    "## Step-by-step learn how to perform a co-simulation embedding spiking neural networks into large-scale brain networks using TVB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import Image, display\n",
    "display(Image(filename='./pics/ConceptGraph1.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./pics/ConceptGraph2.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tvb-multiscale toolbox:\n",
    "\n",
    "### https://github.com/the-virtual-brain/tvb-multiscale\n",
    "\n",
    "For questions use the git issue tracker, or write an e-mail to me: dionysios.perdikis@charite.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T13:37:40.905578Z",
     "start_time": "2019-07-11T13:37:40.894958Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TVB - NEST co-simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear TVB mean field model\n",
    "\n",
    "For every region node $n\\prime$ modelled as a mean-field node in TVB:\n",
    "\n",
    "(Post)Synaptic gating dynamics (i.e., proportion of synapse channels open at any given time):\n",
    "\n",
    "$\\tau\\dot{R_{n\\prime}} = - {R_{n\\prime}}(t) + G\\sum_{{m}\\neq {n\\prime}}C_{{m}{n\\prime}}R_{m}(t-\\tau_{{m}{n\\prime}})(t) + I_o(t) $\n",
    "\n",
    "for $n\\prime$ regions modelled in TVB ($m$ all nodes), \n",
    "\n",
    "and\n",
    "\n",
    "$\\tau_{Rin}\\dot{R_{n}} = - {R_{n}}(t) + {Rin_{n}}(t) $\n",
    "\n",
    "for $n$ region modelled in NEST, and updating TVB via the ${Rin_{n}}(t)$ instant rate.\n",
    "\n",
    " ${Rin_{n\\prime}}(t) = 0.0$ for all $n\\prime$ TVB nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters:\n",
    "\n",
    "- structural TVB connectivity weights $C_{{m\\prime}{n\\prime}}$ (${m\\prime}->{n\\prime}$)\n",
    "- structural TVB connectivity delays $\\tau_{{m\\prime}{n\\prime}}$  (${m\\prime}->{n\\prime}$)\n",
    "- global structural brain connectivity coupling constant $G$\n",
    "- overall effective external input current $I_o = 0.0 except for stimulua application where I_o = 100$ \n",
    "- time constant $\\tau = 10 ms$ \n",
    "- time constant of linear integration of NEST instant rate update $\\tau_{Rin} = 10 ms$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cerebellum Spiking network model in NEST\n",
    "\n",
    "To be filled in!..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVB to NEST coupling\n",
    "TVB couples to NEST via instantaneous spike rate $ interface_{weight} * R(t) $, \n",
    "\n",
    "Spike generator NEST devices are used as TVB \"proxy\" nodes and generate spike trains \n",
    "\n",
    "$ \\left[ \\sum_k \\delta(t-\\tau_{n\\prime n}-{t_j}^k) \\right]_{j \\in n\\prime} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./pics/Rate_cereb_linear.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEST to TVB update\n",
    "\n",
    "A NEST spike detector device is used to count spike for each time step, and convert it to an instantaneous population mean rate that overrides an auxiliary TVB state variables $R_{in}(t)$:\n",
    "\n",
    "$ {R_{in_{n}}}(t) =  \\frac{\\sum_j\\left[ \\sum_k \\delta(t-\\tau_n-{t_j}^k) \\right]_{j \\in R_n}}{nNeurons * dt} $ in  spikes/sec.\n",
    "\n",
    "This update process concerns only the TVB region nodes that are simulated exclusively in NEST, as spiking networks. All the rest of TVB nodes will follow the equations of the mean field model described above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./pics/NESTtoTVB_cereb_linear.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator loop\n",
    "\n",
    "### Simulating several (i.e., 4) NEST time steps for every 1 TVB time step for stable integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:57.561354Z",
     "start_time": "2019-07-12T20:35:52.475653Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from tvb.basic.profile import TvbProfile\n",
    "TvbProfile.set_profile(TvbProfile.LIBRARY_PROFILE)\n",
    "\n",
    "from tvb_multiscale.tvb_nest.config import *\n",
    "home_path = \"/home/docker/packages/tvb-multiscale\"\n",
    "notebooks_path = os.path.join(home_path, \"docs/documented_example_notebook\")\n",
    "config = Config(output_base=os.path.join(notebooks_path, \"outputs_Cereb\"))\n",
    "config.figures.SHOW_FLAG = True \n",
    "config.figures.SAVE_FLAG = True\n",
    "config.figures.FIG_FORMAT = 'png'\n",
    "config.figures.DEFAULT_SIZE= config.figures.NOTEBOOK_SIZE\n",
    "FIGSIZE = config.figures.DEFAULT_SIZE\n",
    "\n",
    "from tvb_multiscale.core.plot.plotter import Plotter\n",
    "plotter = Plotter(config.figures)\n",
    "\n",
    "# For interactive plotting:\n",
    "# %matplotlib notebook  \n",
    "\n",
    "# Otherwise:\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Load structural data <br> (minimally a TVB connectivity)  <br> & prepare TVB simulator  <br> (region mean field model, integrator, monitors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:59.690799Z",
     "start_time": "2019-07-12T20:35:57.571529Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from tvb.simulator.models.linear_with_stimulus import Linear\n",
    "from tvb.datatypes.connectivity import Connectivity\n",
    "from tvb.simulator.cosimulator import CoSimulator\n",
    "from tvb.simulator.integrators import HeunStochastic\n",
    "from tvb.simulator.monitors import Raw  # , Bold, EEG\n",
    "\n",
    "\n",
    "# Create a TVB simulator and set all desired inputs\n",
    "# (connectivity, model, surface, stimuli etc)\n",
    "# We choose all defaults in this example\n",
    "simulator = CoSimulator()\n",
    "model_params = {\"I_o\": np.array([0.0]), \"G\": np.array([16.0]), \"tau\": np.array([10.0]), \"tau_rin\": np.array([10.0])}\n",
    "simulator.model = Linear(**model_params)\n",
    "\n",
    "simulator.integrator = HeunStochastic()\n",
    "simulator.integrator.dt = 0.1\n",
    "simulator.integrator.noise.nsig = np.array([0.001])\n",
    "\n",
    "\n",
    "# Load connectivity\n",
    "# config.DEFAULT_CONNECTIVITY_ZIP = \"/home/docker/packages/tvb_data/tvb_data/mouse/allen_2mm/ConnectivityAllen2mm.zip\"                                  \n",
    "# connectivity = Connectivity.from_file(config.DEFAULT_CONNECTIVITY_ZIP)\n",
    "import os\n",
    "DATA_PATH = os.path.join(home_path, \"examples/data\")\n",
    "w = np.loadtxt(os.path.join(DATA_PATH, \"mouse_cereb_sum_weights.txt\"))\n",
    "# t = np.loadtxt(os.path.join(DATA_PATH, \"tract_lengths_Count_plusCRBL.txt\"))\n",
    "# forcing one time step delay for all connections:\n",
    "speed = 4.0\n",
    "t = speed * simulator.integrator.dt * np.ones(w.shape)  \n",
    "# brain_regions_path = os.path.join(DATA_PATH, \"centres_brain_MNI.txt\")\n",
    "# rl = np.loadtxt(brain_regions_path,dtype=\"str\", usecols=(0,))\n",
    "with open(os.path.join(DATA_PATH, \"mouse_cereb_regions_labels.txt\"), \"r\") as text: \n",
    "    rl = [] \n",
    "    for line in text: \n",
    "        rl.append(line)\n",
    "rl = np.array(rl)\n",
    "# c = np.loadtxt(brain_regions_path, usecols=range(1,3))\n",
    "c = np.random.uniform((w.shape[0], 3))\n",
    "connectivity=Connectivity(region_labels=rl, weights=w, centres=c, tract_lengths=t)\n",
    "\n",
    "# Normalize connectivity weights\n",
    "connectivity.weights = connectivity.scaled_weights(mode=\"region\")\n",
    "connectivity.weights /= np.percentile(connectivity.weights, 99)\n",
    "connectivity.weights[connectivity.weights > 1.0] = 1.0\n",
    "\n",
    "connectivity.speed = np.array([speed])\n",
    "connectivity.configure()\n",
    "\n",
    "#white_matter_coupling = coupling.Linear(a=0.014)\n",
    "simulator.connectivity = connectivity\n",
    "\n",
    "simulator.model.I_o = simulator.model.I_o[0] * np.ones((simulator.connectivity.number_of_regions, ))\n",
    "\n",
    "simulator.initial_conditions = np.zeros((2, 2, simulator.connectivity.number_of_regions, 1))\n",
    "\n",
    "mon_raw = Raw(period=1.0)  # ms\n",
    "simulator.monitors = (mon_raw, )\n",
    "\n",
    "plotter.plot_tvb_connectivity(simulator.connectivity);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build and connect the NEST network model <br> (networks of spiking neural populations for fine-scale <br>regions, stimulation devices, spike detectors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the regions for the fine scale modeling with NEST spiking networks\n",
    "nest_nodes_ids = []\n",
    "for i_region, reg_lbl in enumerate(simulator.connectivity.region_labels):\n",
    "    if \"cereb\" in reg_lbl.lower():\n",
    "        nest_nodes_ids.append(i_region)  # the indices of fine scale regions modeled with NEST\n",
    "if len(nest_nodes_ids) == 0:\n",
    "    nest_nodes_ids = [simulator.connectivity.number_of_regions-1]\n",
    "\n",
    "print([\"%d. %s\" % (nest_node_id, simulator.connectivity.region_labels[nest_node_id]) for nest_node_id in nest_nodes_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "connections_to_cereb = simulator.connectivity.weights[:, nest_nodes_ids[0]]\n",
    "sorted_connections_to_cereb = np.argsort(connections_to_cereb)[::-1]\n",
    "print(\"sorted_connections_to_cereb =\\n\") \n",
    "for conn_id in sorted_connections_to_cereb:\n",
    "    print(\"\\n%d. %s, w = %g\" % \n",
    "          (conn_id, simulator.connectivity.region_labels[conn_id], connections_to_cereb[conn_id]))\n",
    "connections_from_cereb = simulator.connectivity.weights[nest_nodes_ids[0], :]\n",
    "sorted_connections_from_cereb = np.argsort(connections_from_cereb)[::-1]\n",
    "print(\"sorted_connections_from_cereb =\\n\") \n",
    "for conn_id in sorted_connections_from_cereb:\n",
    "    print(\"\\n%d. %s, w = %g\" % \n",
    "          (conn_id, simulator.connectivity.region_labels[conn_id], connections_from_cereb[conn_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_node_id = 42\n",
    "print(\"TVB stimulus to %d. Right Intermediate reticular nucleus, w = %g\" % \n",
    "      (stim_node_id, connections_to_cereb[stim_node_id]))\n",
    "connections_from_stim = simulator.connectivity.weights[stim_node_id, :]\n",
    "sorted_connections_from_stim = np.argsort(connections_from_stim)[::-1]\n",
    "print(\"which connects to...\")\n",
    "print(\"sorted_connections_from 42. Right Intermediate reticular nucleus =\\n\") \n",
    "for conn_id in sorted_connections_from_stim:\n",
    "    print(\"\\n%d. %s, w = %g\" % \n",
    "          (conn_id, simulator.connectivity.region_labels[conn_id], connections_from_stim[conn_id]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:10.862262Z",
     "start_time": "2019-07-12T20:36:10.000332Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a NEST network model with the corresponding builder\n",
    "from tvb_multiscale.tvb_nest.nest_models.builders.models.cereb import CerebBuilder\n",
    "\n",
    "# Using all default parameters for this example\n",
    "nest_model_builder = CerebBuilder(simulator, nest_nodes_ids, \n",
    "                                  os.path.join(DATA_PATH, \"cerebellar_cortex_scaffold_dcn.hdf5\"),\n",
    "                                  config=config)\n",
    "nest_model_builder.modules_to_install = [\"cereb\"]\n",
    "\n",
    "# or...\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------------------\n",
    "# # ----Uncomment below to modify the builder by changing the default  builder configuration------------------------\n",
    "# # ----------------------------------------------------------------------------------------------------------------\n",
    "# import h5py\n",
    "\n",
    "# # Synapse parameters: in E-GLIF, 3 synaptic receptors are present:\n",
    "# # the first is always associated to exc,\n",
    "# # the second to inh,\n",
    "# # the third to remaining synapse type\n",
    "# Erev_exc = 0.0  # [mV]\t# [Cavallari et al, 2014]\n",
    "# Erev_inh = -80.0  # [mV]\n",
    "# # tau_exc for pc is for pf input; tau_exc for goc is for mf input; tau_exc for mli is for pf input:\n",
    "# tau_exc = {'golgi': 0.23, 'granule': 5.8, 'purkinje': 1.1, 'basket': 0.64, 'stellate': 0.64, 'dcn': 1.0,\n",
    "#            'dcnp': 3.64,\n",
    "#            'io': 1.0}\n",
    "# tau_inh = {'golgi': 10.0, 'granule': 13.61, 'purkinje': 2.8, 'basket': 2.0, 'stellate': 2.0, 'dcn': 0.7,\n",
    "#            'dcnp': 1.14, 'io': 60.0}\n",
    "# tau_exc_cfpc = 0.4\n",
    "# tau_exc_pfgoc = 0.5\n",
    "# tau_exc_cfmli = 1.2\n",
    "\n",
    "# # Single neuron parameters:\n",
    "# nest_model_builder.neuron_param = {\n",
    "#         'golgi_cell': {'t_ref': 2.0, 'C_m': 145.0, 'tau_m': 44.0, 'V_th': -55.0, 'V_reset': -75.0, 'Vinit': -62.0,\n",
    "#                        'E_L': -62.0, 'Vmin': -150.0,\n",
    "#                        'lambda_0': 1.0, 'tau_V': 0.4, 'I_e': 16.214, 'kadap': 0.217, 'k1': 0.031, 'k2': 0.023,\n",
    "#                        'A1': 259.988, 'A2': 178.01,\n",
    "#                        'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc, 'tau_syn1': tau_exc['golgi'],\n",
    "#                        'tau_syn2': tau_inh['golgi'], 'tau_syn3': tau_exc_pfgoc},\n",
    "#         'granule_cell': {'t_ref': 1.5, 'C_m': 7.0, 'tau_m': 24.15, 'V_th': -41.0, 'V_reset': -70.0, 'Vinit': -62.0,\n",
    "#                          'E_L': -62.0, 'Vmin': -150.0,\n",
    "#                          'lambda_0': 1.0, 'tau_V': 0.3, 'I_e': -0.888, 'kadap': 0.022, 'k1': 0.311, 'k2': 0.041,\n",
    "#                          'A1': 0.01, 'A2': -0.94,\n",
    "#                          'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc, 'tau_syn1': tau_exc['granule'],\n",
    "#                          'tau_syn2': tau_inh['granule'], 'tau_syn3': tau_exc['granule']},\n",
    "#         'purkinje_cell': {'t_ref': 0.5, 'C_m': 334.0, 'tau_m': 47.0, 'V_th': -43.0, 'V_reset': -69.0, 'Vinit': -59.0,\n",
    "#                           'E_L': -59.0,\n",
    "#                           'lambda_0': 4.0, 'tau_V': 3.5, 'I_e': 742.54, 'kadap': 1.492, 'k1': 0.1950, 'k2': 0.041,\n",
    "#                           'A1': 157.622, 'A2': 172.622,\n",
    "#                           'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc, 'tau_syn1': tau_exc['purkinje'],\n",
    "#                           'tau_syn2': tau_inh['purkinje'], 'tau_syn3': tau_exc_cfpc},\n",
    "#         'basket_cell': {'t_ref': 1.59, 'C_m': 14.6, 'tau_m': 9.125, 'V_th': -53.0, 'V_reset': -78.0, 'Vinit': -68.0,\n",
    "#                         'E_L': -68.0,\n",
    "#                         'lambda_0': 1.8, 'tau_V': 1.1, 'I_e': 3.711, 'kadap': 2.025, 'k1': 1.887, 'k2': 1.096,\n",
    "#                         'A1': 5.953, 'A2': 5.863,\n",
    "#                         'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc, 'tau_syn1': tau_exc['basket'],\n",
    "#                         'tau_syn2': tau_inh['basket'], 'tau_syn3': tau_exc_cfmli},\n",
    "#         'stellate_cell': {'t_ref': 1.59, 'C_m': 14.6, 'tau_m': 9.125, 'V_th': -53.0, 'V_reset': -78.0, 'Vinit': -68.0,\n",
    "#                           'E_L': -68.0,\n",
    "#                           'lambda_0': 1.8, 'tau_V': 1.1, 'I_e': 3.711, 'kadap': 2.025, 'k1': 1.887, 'k2': 1.096,\n",
    "#                           'A1': 5.953, 'A2': 5.863,\n",
    "#                           'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc, 'tau_syn1': tau_exc['basket'],\n",
    "#                           'tau_syn2': tau_inh['basket'], 'tau_syn3': tau_exc_cfmli},\n",
    "#         'dcn_cell': {'t_ref': 0.8, 'C_m': 142.0,'tau_m': 33.0,'V_th': -36.0,'V_reset': -55.0,'Vinit': -45.0,'E_L': -45.0,\n",
    "#                          'lambda_0':3.5, 'tau_V':3.0,'I_e': 75.385,'kadap': 0.408,'k1': 0.697, 'k2': 0.047,'A1': 13.857,'A2':3.477,\n",
    "#                          'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc,'tau_syn1': tau_exc['dcn'], 'tau_syn2': tau_inh['dcn']}}\n",
    "\n",
    "# # Connection weights\n",
    "# nest_model_builder.conn_weights = {'mossy_to_glomerulus': 1.0, 'ascending_axon_to_golgi': 0.05, 'ascending_axon_to_purkinje': 0.175,\n",
    "#                     'basket_to_purkinje': 3.638,\n",
    "#                     'glomerulus_to_golgi': 0.0125, 'glomerulus_to_granule': 0.361, 'golgi_to_granule': 0.338,\n",
    "#                     'parallel_fiber_to_basket': 0.002, 'parallel_fiber_to_golgi': 0.008,\n",
    "#                     'parallel_fiber_to_purkinje': 0.044,\n",
    "#                     'parallel_fiber_to_stellate': 0.003, 'stellate_to_purkinje': 1.213, \n",
    "#                     'mossy_to_dcn': 0.5, 'purkinje_to_dcn': 0.45}\n",
    "\n",
    "# # Connection delays\n",
    "# nest_model_builder.conn_delays = \\\n",
    "#     {'mossy_to_glomerulus': 1.0, 'ascending_axon_to_golgi': 2.0, 'ascending_axon_to_purkinje': 2.0,\n",
    "#      'basket_to_purkinje': 4.0, 'glomerulus_to_golgi': 4.0, 'glomerulus_to_granule': 4.0, 'golgi_to_granule': 2.0,\n",
    "#      'parallel_fiber_to_basket': 5.0, 'parallel_fiber_to_golgi': 5.0, 'parallel_fiber_to_purkinje': 5.0,\n",
    "#      'parallel_fiber_to_stellate': 5.0, 'stellate_to_purkinje': 5.0, \n",
    "#      'mossy_to_dcn': 4.0, 'purkinje_to_dcn': 4.0}\n",
    "\n",
    "# # Connection receptors\n",
    "# nest_model_builder.conn_receptors = \\\n",
    "#     {'ascending_axon_to_golgi': 3, 'ascending_axon_to_purkinje': 1, 'basket_to_purkinje': 2,\n",
    "#      'glomerulus_to_golgi': 1, 'glomerulus_to_granule': 1, 'golgi_to_granule': 2,\n",
    "#      'parallel_fiber_to_basket': 1, 'parallel_fiber_to_golgi': 3, 'parallel_fiber_to_purkinje': 1,\n",
    "#      'parallel_fiber_to_stellate': 1, 'stellate_to_purkinje': 2, \n",
    "#      'mossy_to_dcn': 1, 'purkinje_to_dcn': 2}\n",
    "\n",
    "# # Connection pre and post-synaptic neurons\n",
    "# nest_model_builder.conn_pre_post = \\\n",
    "#     {'mossy_to_glomerulus': {'pre': 'mossy_fibers', 'post': 'glomerulus'},\n",
    "#      'ascending_axon_to_golgi': {'pre': 'granule_cell', 'post': 'golgi_cell'},\n",
    "#      'ascending_axon_to_purkinje': {'pre': 'granule_cell', 'post': 'purkinje_cell'},\n",
    "#      'basket_to_purkinje': {'pre': 'basket_cell', 'post': 'purkinje_cell'},\n",
    "#      'glomerulus_to_golgi': {'pre': 'glomerulus', 'post': 'golgi_cell'},\n",
    "#      'glomerulus_to_granule': {'pre': 'glomerulus', 'post': 'granule_cell'},\n",
    "#      'golgi_to_granule': {'pre': 'golgi_cell', 'post': 'granule_cell'},\n",
    "#      'parallel_fiber_to_basket': {'pre': 'granule_cell', 'post': 'basket_cell'},\n",
    "#      'parallel_fiber_to_golgi': {'pre': 'granule_cell', 'post': 'golgi_cell'},\n",
    "#      'parallel_fiber_to_purkinje': {'pre': 'granule_cell', 'post': 'purkinje_cell'},\n",
    "#      'parallel_fiber_to_stellate': {'pre': 'granule_cell', 'post': 'stellate_cell'},\n",
    "#      'stellate_to_purkinje': {'pre': 'stellate_cell', 'post': 'purkinje_cell'}, \n",
    "#      'purkinje_to_dcn': {'pre': 'purkinje_cell', 'post': 'dcn_cell'}}\n",
    "\n",
    "# nest_model_builder.RECORD_VM = True\n",
    "# nest_model_builder.TOT_DURATION = 350.  # 350 mseconds\n",
    "# nest_model_builder.STIM_START = 150.  # 150 beginning of stimulation\n",
    "# nest_model_builder.STIM_END = 250.  # 250 end of stimulation\n",
    "# nest_model_builder.STIM_FREQ = 100.  # Frequency in Hz\n",
    "# nest_model_builder.BACKGROUND_FREQ = 4.\n",
    "\n",
    "# # Load the network source file:\n",
    "# nest_model_builder.net_src_file = h5py.File(nest_model_builder.path_to_network_source_file, 'r+')\n",
    "\n",
    "# # Populations' configurations\n",
    "# nest_model_builder.neuron_types = list(nest_model_builder.net_src_file['cells/placement'].keys())\n",
    "# ordered_neuron_types = []\n",
    "# nest_model_builder.ordered_neuron_types = ['mossy_fibers', 'glomerulus', \"granule_cell\", \"golgi_cell\",\n",
    "#                                            \"basket_cell\", \"stellate_cell\", \"purkinje_cell\", \"dcn_cell\"]\n",
    "# for neuron_type in nest_model_builder.ordered_neuron_types:\n",
    "#     ordered_neuron_types.append(\n",
    "#         nest_model_builder.neuron_types.pop(\n",
    "#             nest_model_builder.neuron_types.index(neuron_type)))\n",
    "# ordered_neuron_types += nest_model_builder.neuron_types\n",
    "# nest_model_builder.neuron_types = ordered_neuron_types\n",
    "\n",
    "# nest_model_builder.populations = []\n",
    "# nest_model_builder.start_id_scaffold = {}\n",
    "# # All cells are modelled as E-GLIF models;\n",
    "# # with the only exception of Glomeruli and Mossy Fibers (not cells, just modeled as\n",
    "# # relays; i.e., parrot neurons)\n",
    "# for neuron_name in nest_model_builder.neuron_types:\n",
    "#     if neuron_name != 'glomerulus' and neuron_name != 'mossy_fibers':\n",
    "#         model = 'eglif_cond_alpha_multisyn'\n",
    "#     else:\n",
    "#         model = 'parrot_neuron'\n",
    "#     n_neurons = np.array(nest_model_builder.net_src_file['cells/placement/' + neuron_name + '/identifiers'])[1]\n",
    "#     nest_model_builder.populations.append(\n",
    "#                 {\"label\": neuron_name, \"model\": model,\n",
    "#                  \"params\": nest_model_builder.neuron_param.get(neuron_name, {}),\n",
    "#                  \"scale\": n_neurons,\n",
    "#                  \"nodes\": None})\n",
    "#     nest_model_builder.start_id_scaffold[neuron_name] = \\\n",
    "#                 np.array(nest_model_builder.net_src_file['cells/placement/' + neuron_name + '/identifiers'])[0]\n",
    "\n",
    "# class NeuronsIndsFun(object):\n",
    "#     conns = np.array([])\n",
    "#     start_id_scaffold = 0\n",
    "\n",
    "#     def __init__(self, start_id_scaffold, conns):\n",
    "#         self.start_id_scaffold = start_id_scaffold\n",
    "#         self.conns = conns\n",
    "\n",
    "#     def __call__(self, neurons_inds):\n",
    "#         return [int(x - self.start_id_scaffold + neurons_inds[0])\n",
    "#                 for x in self.conns]\n",
    "    \n",
    "# # Within brain regions' nodes connections among populations:\n",
    "# nest_model_builder.default_populations_connection[\"conn_spec\"][\"rule\"] = \"one_to_one\"\n",
    "# nest_model_builder.populations_connections = []\n",
    "# for conn_name in nest_model_builder.conn_weights.keys():\n",
    "#     conn = np.array(nest_model_builder.net_src_file['cells/connections/'+conn_name])\n",
    "#     pre_name = nest_model_builder.conn_pre_post[conn_name][\"pre\"]\n",
    "#     post_name = nest_model_builder.conn_pre_post[conn_name][\"post\"]\n",
    "#     nest_model_builder.populations_connections.append(\n",
    "#         {\"source\": pre_name, \"target\": post_name,\n",
    "#          \"source_inds\": NeuronsIndsFun(nest_model_builder.start_id_scaffold[pre_name], conn[:, 0].flatten()),\n",
    "#          \"target_inds\": NeuronsIndsFun(nest_model_builder.start_id_scaffold[post_name], conn[:, 1].flatten()),\n",
    "#          \"synapse_model\": 'static_synapse',\n",
    "#          \"conn_spec\": nest_model_builder.default_populations_connection[\"conn_spec\"],\n",
    "#          \"weight\": nest_model_builder.conn_weights[conn_name],\n",
    "#          \"delay\": nest_model_builder.conn_delays[conn_name],\n",
    "#          \"receptor_type\": nest_model_builder.conn_receptors.get(conn_name, 0),\n",
    "#          \"nodes\": None\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# # No among brain region regions' nodes' connectivity yet for the NEST Cerebellum network! \n",
    "# # Assuming a single Cerebellum region.\n",
    "\n",
    "# # We don't need the network source file any more. Close it:\n",
    "# nest_model_builder.net_src_file.close()\n",
    "\n",
    "# def neurons_inds_fun(neurons_inds, n_neurons=100):\n",
    "#     # We use this in order to measure up to n_neurons neurons from every population\n",
    "#     n_neurons_inds = len(neurons_inds)\n",
    "#     if n_neurons_inds > n_neurons:\n",
    "#         return tuple(np.array(neurons_inds)[0:-1:int(np.ceil(1.0*n_neurons_inds/n_neurons))])\n",
    "#     else:\n",
    "#         return neurons_inds\n",
    "    \n",
    "# # Output Devices:\n",
    "# nest_model_builder.output_devices = []\n",
    "# # Spike detectors:\n",
    "# connections = OrderedDict()\n",
    "# #          label <- target population\n",
    "# for pop in nest_model_builder.populations:\n",
    "#     connections[pop[\"label\"] + \"_spikes\"] = pop[\"label\"]\n",
    "#     params = dict(nest_model_builder.config.NEST_OUTPUT_DEVICES_PARAMS_DEF[\"spike_detector\"])\n",
    "#     nest_model_builder.output_devices.append(\n",
    "#         {\"model\": \"spike_detector\", \"params\": params,\n",
    "#          \"connections\": connections, \"nodes\": None})  # None means all here\n",
    "\n",
    "# if nest_model_builder.RECORD_VM:    \n",
    "#     # Multimeters:\n",
    "#     connections = OrderedDict()\n",
    "#     #               label    <- target population\n",
    "#     for pop in nest_model_builder.populations:\n",
    "#         if pop[\"label\"] != 'glomerulus' and pop[\"label\"] != 'mossy_fibers':\n",
    "#             connections[pop[\"label\"]] = pop[\"label\"]\n",
    "#         params = dict(nest_model_builder.config.NEST_OUTPUT_DEVICES_PARAMS_DEF[\"multimeter\"])\n",
    "#         params[\"interval\"] = nest_model_builder.monitor_period\n",
    "#         nest_model_builder.output_devices.append(\n",
    "#                 {\"model\": \"multimeter\", \"params\": params,\n",
    "#                  \"neurons_inds\": lambda node, neurons_inds: neurons_inds_fun(neurons_inds),\n",
    "#                  \"connections\": connections, \"nodes\": None})  # None means all here\n",
    "    \n",
    "# # Input (stimulus) Devices (needed only when there is no TVB input to the Cerebellum):\n",
    "# nest_model_builder.input_devices = []\n",
    "# # # Background spike stimulus :\n",
    "# # connections = OrderedDict()\n",
    "# # #             label <- target population\n",
    "# # connections[\"Background\"] = ['mossy_fibers']\n",
    "# # nest_model_builder.input_devices.append(\n",
    "# #     {\"model\": \"poisson_generator\",\n",
    "# #      \"params\": {\"rate\": nest_model_builder.BACKGROUND_FREQ, \n",
    "# #                 \"origin\": 0.0, \"start\": 0.0}, # not necessary: \"stop\": nest_model_builder.TOT_DURATION\n",
    "# #      \"connections\": connections, \"nodes\": None,\n",
    "# #      \"weights\": 1.0, \"delays\": 0.0, \"receptor_type\": 0})\n",
    "# # # Spike stimulus \n",
    "# # connections = OrderedDict()\n",
    "# # #             label <- target population\n",
    "# # connections[\"Stimulus\"] = ['mossy_fibers']\n",
    "# # nest_model_builder.input_devices.append(\n",
    "# #     {\"model\": \"poisson_generator\",\n",
    "# #      \"params\": {\"rate\": nest_model_builder.STIM_FREQ, \"origin\": 0.0, \n",
    "# #                 \"start\": nest_model_builder.STIM_START, \"stop\": nest_model_builder.STIM_END},\n",
    "# #      \"connections\": connections, \"nodes\": None,\n",
    "# #      \"weights\": 1.0, \"delays\": 0.0, \"receptor_type\": 0})\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------------------\n",
    "# # ----------------------------------------------------------------------------------------------------------------\n",
    "# # ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# nest_network = nest_model_builder.build_spiking_network()\n",
    "\n",
    "\n",
    "# or build the network without using the TVB-NEST NEST network builder...:\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----Uncomment below to build the NEST network without using the NEST model builder of TVB-NEST------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "import h5py\n",
    "!rm *.gdf\n",
    "!rm *.dat\n",
    "\n",
    "nest_model_builder.compile_install_nest_modules([\"cereb\"])\n",
    "\n",
    "# Synapse parameters: in E-GLIF, 3 synaptic receptors are present: the first is always associated to exc, the second to inh, the third to remaining synapse type\n",
    "Erev_exc = 0.0\t\t# [mV]\t#[Cavallari et al, 2014]\n",
    "Erev_inh = -80.0\t\t# [mV]\n",
    "tau_exc = {'golgi': 0.23, 'granule': 5.8, 'purkinje': 1.1, 'basket': 0.64, 'stellate': 0.64, 'dcn': 1.0, 'dcnp': 3.64, 'io': 1.0}\t\t#tau_exc for pc is for pf input; tau_exc for goc is for mf input; tau_exc for mli is for pf input\n",
    "tau_inh = {'golgi': 10.0, 'granule': 13.61, 'purkinje': 2.8, 'basket': 2.0, 'stellate': 2.0, 'dcn': 0.7, 'dcnp': 1.14, 'io': 60.0}\n",
    "tau_exc_cfpc = 0.4\n",
    "tau_exc_pfgoc = 0.5\n",
    "tau_exc_cfmli = 1.2\n",
    "\n",
    "# Single neuron parameters:\n",
    "neuron_param = {'golgi_cell': {'t_ref': 2.0, 'C_m': 145.0,'tau_m': 44.0,'V_th': -55.0,'V_reset': -75.0,'Vinit': -62.0,'E_L': -62.0,'Vmin':-150.0,\n",
    "                         'lambda_0':1.0, 'tau_V':0.4,'I_e': 16.214,'kadap': 0.217,'k1': 0.031, 'k2': 0.023,'A1': 259.988,'A2':178.01,\n",
    "                         'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc,'tau_syn1': tau_exc['golgi'], 'tau_syn2': tau_inh['golgi'], 'tau_syn3': tau_exc_pfgoc},\n",
    "               'granule_cell': {'t_ref': 1.5, 'C_m': 7.0,'tau_m': 24.15,'V_th': -41.0,'V_reset': -70.0,'Vinit': -62.0,'E_L': -62.0,'Vmin': -150.0,\n",
    "                           'lambda_0':1.0, 'tau_V':0.3,'I_e': -0.888,'kadap': 0.022,'k1': 0.311, 'k2': 0.041,'A1': 0.01,'A2':-0.94,\n",
    "                           'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc,'tau_syn1': tau_exc['granule'], 'tau_syn2': tau_inh['granule'], 'tau_syn3': tau_exc['granule']},\n",
    "               'purkinje_cell': {'t_ref': 0.5, 'C_m': 334.0,'tau_m': 47.0,'V_th': -43.0,'V_reset': -69.0,'Vinit': -59.0,'E_L': -59.0,\n",
    "                            'lambda_0':4.0, 'tau_V':3.5,'I_e': 742.54,'kadap': 1.492,'k1': 0.1950, 'k2': 0.041,'A1': 157.622,'A2':172.622,\n",
    "                            'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc,'tau_syn1': tau_exc['purkinje'], 'tau_syn2': tau_inh['purkinje'], 'tau_syn3': tau_exc_cfpc},\n",
    "               'basket_cell': {'t_ref': 1.59, 'C_m': 14.6,'tau_m': 9.125,'V_th': -53.0,'V_reset': -78.0,'Vinit': -68.0,'E_L': -68.0,\n",
    "                          'lambda_0':1.8, 'tau_V':1.1,'I_e': 3.711,'kadap': 2.025,'k1': 1.887, 'k2': 1.096,'A1': 5.953,'A2':5.863,\n",
    "                          'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc,'tau_syn1': tau_exc['basket'], 'tau_syn2': tau_inh['basket'], 'tau_syn3': tau_exc_cfmli},\n",
    "               'stellate_cell': {'t_ref': 1.59, 'C_m': 14.6,'tau_m': 9.125,'V_th': -53.0,'V_reset': -78.0,'Vinit': -68.0,'E_L': -68.0,\n",
    "                            'lambda_0':1.8, 'tau_V':1.1,'I_e': 3.711,'kadap': 2.025,'k1': 1.887, 'k2': 1.096,'A1': 5.953,'A2':5.863,\n",
    "                            'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc,'tau_syn1': tau_exc['basket'], 'tau_syn2': tau_inh['basket'], 'tau_syn3': tau_exc_cfmli},\n",
    "               'dcn_cell': {'t_ref': 0.8, 'C_m': 142.0,'tau_m': 33.0,'V_th': -36.0,'V_reset': -55.0,'Vinit': -45.0,'E_L': -45.0,\n",
    "                         'lambda_0':3.5, 'tau_V':3.0,'I_e': 75.385,'kadap': 0.408,'k1': 0.697, 'k2': 0.047,'A1': 13.857,'A2':3.477,\n",
    "                         'E_rev1': Erev_exc, 'E_rev2': Erev_inh, 'E_rev3': Erev_exc,'tau_syn1': tau_exc['dcn'], 'tau_syn2': tau_inh['dcn']}}\n",
    "\n",
    "\n",
    "# Connection weights\n",
    "conn_weights = {'mossy_to_glomerulus': 1.0,'ascending_axon_to_golgi': 0.05, 'ascending_axon_to_purkinje': 0.175, 'basket_to_purkinje': 3.638,\\\n",
    "                'glomerulus_to_golgi': 0.0125, 'glomerulus_to_granule': 0.361, 'golgi_to_granule': 0.338,\\\n",
    "                'parallel_fiber_to_basket': 0.002, 'parallel_fiber_to_golgi': 0.008,'parallel_fiber_to_purkinje': 0.044,\\\n",
    "                'parallel_fiber_to_stellate': 0.003, 'stellate_to_purkinje': 1.213,\\\n",
    "                'mossy_to_dcn': 0.5, 'purkinje_to_dcn': 0.45}\n",
    "\n",
    "\n",
    "# Connection delays\n",
    "conn_delays = {'mossy_to_glomerulus': 1.0,'ascending_axon_to_golgi': 2.0, 'ascending_axon_to_purkinje': 2.0, 'basket_to_purkinje': 4.0,\n",
    "               'glomerulus_to_golgi': 4.0, 'glomerulus_to_granule': 4.0, 'golgi_to_granule': 2.0,\n",
    "               'parallel_fiber_to_basket': 5.0, 'parallel_fiber_to_golgi': 5.0,'parallel_fiber_to_purkinje': 5.0,\n",
    "               'parallel_fiber_to_stellate': 5.0, 'stellate_to_purkinje':5.0,\\\n",
    "               'mossy_to_dcn': 4.0, 'purkinje_to_dcn': 4.0}\n",
    "\n",
    "# Connection receptors\n",
    "conn_receptors = {'ascending_axon_to_golgi': 3, 'ascending_axon_to_purkinje': 1, 'basket_to_purkinje': 2,\n",
    "               'glomerulus_to_golgi': 1, 'glomerulus_to_granule': 1, 'golgi_to_granule': 2,\n",
    "               'parallel_fiber_to_basket': 1, 'parallel_fiber_to_golgi': 3,'parallel_fiber_to_purkinje': 1,\n",
    "               'parallel_fiber_to_stellate': 1, 'stellate_to_purkinje': 2, \\\n",
    "               'mossy_to_dcn': 1, 'purkinje_to_dcn': 2}\n",
    "\n",
    "\n",
    "# Connection pre and post-synaptic neurons\n",
    "conn_pre_post = {'mossy_to_glomerulus': {'pre': 'mossy_fibers', 'post': 'glomerulus'},\\\n",
    "                 'ascending_axon_to_golgi': {'pre': 'granule_cell', 'post': 'golgi_cell'},\\\n",
    "                 'ascending_axon_to_purkinje': {'pre': 'granule_cell', 'post': 'purkinje_cell'},\\\n",
    "                 'basket_to_purkinje': {'pre': 'basket_cell', 'post': 'purkinje_cell'},\\\n",
    "                 'glomerulus_to_golgi': {'pre': 'glomerulus', 'post': 'golgi_cell'}, \\\n",
    "                 'glomerulus_to_granule': {'pre': 'glomerulus', 'post': 'granule_cell'}, \\\n",
    "                 'golgi_to_granule': {'pre': 'golgi_cell', 'post': 'granule_cell'},\\\n",
    "                 'parallel_fiber_to_basket': {'pre': 'granule_cell', 'post': 'basket_cell'}, \\\n",
    "                 'parallel_fiber_to_golgi': {'pre': 'granule_cell', 'post': 'golgi_cell'},\\\n",
    "                 'parallel_fiber_to_purkinje': {'pre': 'granule_cell', 'post': 'purkinje_cell'},\\\n",
    "                 'parallel_fiber_to_stellate': {'pre': 'granule_cell', 'post': 'stellate_cell'}, \\\n",
    "                 'stellate_to_purkinje': {'pre': 'stellate_cell', 'post': 'purkinje_cell'},\\\n",
    "                 'mossy_to_dcn': {'pre': 'mossy_fibers', 'post': 'dcn_cell'},\\\n",
    "                 'purkinje_to_dcn': {'pre': 'purkinje_cell', 'post': 'dcn_cell'}}\n",
    "\n",
    "\n",
    "# Get the nest instance of the NEST model builder:\n",
    "nest = nest_model_builder.nest_instance\n",
    "nest_model_builder._configure_nest_kernel()\n",
    "\n",
    "# Prepare the NEST kernel:\n",
    "# nest.ResetKernel()\n",
    "# nest.set_verbosity('M_ERROR')\n",
    "# nest.SetKernelStatus({\"local_num_threads\" : cpu_count()})\n",
    "\n",
    "# Load the network source file:\n",
    "f = h5py.File(nest_model_builder.path_to_network_source_file, 'r+')\n",
    "\n",
    "neuron_types = list(f['cells/placement'].keys())\n",
    "ordered_neuron_types = []\n",
    "for neuron_type in ['mossy_fibers', 'glomerulus', \"granule_cell\", \"golgi_cell\", \n",
    "                    \"basket_cell\", \"stellate_cell\", \"purkinje_cell\"]:\n",
    "    ordered_neuron_types.append(neuron_types.pop(neuron_types.index(neuron_type)))\n",
    "ordered_neuron_types += neuron_types\n",
    "neuron_types = ordered_neuron_types\n",
    "print(neuron_types)\n",
    "\n",
    "neuron_number = {}\n",
    "start_id_scaffold = {}\n",
    "\n",
    "# ### Creating population of neurons\n",
    "# Instantiate conductance based Extended-Generalized Leaky Integrate and Fire models (E-GLIF) for each cell type. \n",
    "# The only exception is represented by Glomeruli and Mossy Fibers; these are not actual cells but just 'relays', \n",
    "# used to deliver input spikes to other cells. Here, Glomeruli are created as *parrot_neurons*\n",
    "\n",
    "# Create a dictionary; keys = cell names, values = lists to store neuron models\n",
    "neuron_models = {key: [] for key in neuron_types}\n",
    "\n",
    "# All cells are modelled as E-GLIF models;\n",
    "# with the only exception of Glomeruli and Mossy Fibers (not cells, just modeled as\n",
    "# relays; i.e., parrot neurons)\n",
    "from tvb_multiscale.tvb_nest.nest_models.brain import NESTBrain\n",
    "from tvb_multiscale.tvb_nest.nest_models.region_node import NESTRegionNode\n",
    "from tvb_multiscale.tvb_nest.nest_models.population import NESTPopulation\n",
    "nest_region_label = simulator.connectivity.region_labels[nest_nodes_ids[0]]\n",
    "nest_brain = NESTBrain(nest_instance=nest)\n",
    "nest_brain[nest_region_label] = NESTRegionNode(label=nest_region_label, nest_instance=nest)\n",
    "for neuron_name in neuron_types:\n",
    "    if neuron_name  != 'glomerulus' and neuron_name != 'mossy_fibers':\n",
    "        if neuron_name not in nest.Models():\n",
    "            model = 'eglif_cond_alpha_multisyn'\n",
    "            nest.CopyModel('eglif_cond_alpha_multisyn', neuron_name)\n",
    "            nest.SetDefaults(neuron_name, neuron_param[neuron_name])\n",
    "    else:\n",
    "        model = 'parrot_neuron'\n",
    "        if neuron_name not in nest.Models():\n",
    "            nest.CopyModel('parrot_neuron', neuron_name)\n",
    "    \n",
    "    neuron_number[neuron_name] = np.array(f['cells/placement/'+neuron_name+'/identifiers'])[1]\n",
    "    start_id_scaffold[neuron_name] = np.array(f['cells/placement/'+neuron_name+'/identifiers'])[0]\n",
    "    \n",
    "    neuron_models[neuron_name] = nest.Create(neuron_name, neuron_number[neuron_name])\n",
    "    \n",
    "    # Set the neurons' indices into a NESTPopulation class instance inside the NESTBrain class instance:\n",
    "    nest_brain[nest_region_label][neuron_name] = NESTPopulation(neuron_models[neuron_name],\n",
    "                                                                label=neuron_name, model=model, \n",
    "                                                                nest_instance=nest)\n",
    "\n",
    "    \n",
    "# ### Creating synaptic connections\n",
    "# Here we create synaptic connections among neurons. \n",
    "# A message will be printed below the next cell when each connection type is done:\n",
    "\n",
    "### Load connections from hdf5 file and create them in NEST:\n",
    "for conn in conn_weights.keys():\n",
    "    conn_name = conn\n",
    "    conn = np.array(f['cells/connections/'+conn_name])\n",
    "    pre_name = conn_pre_post[conn_name][\"pre\"]\n",
    "    post_name = conn_pre_post[conn_name][\"post\"]\n",
    "    pre = [int(x-start_id_scaffold[pre_name]+neuron_models[pre_name].tolist()[0]) for x in conn[:,0]]\n",
    "    post = [int(x-start_id_scaffold[post_name]+neuron_models[post_name].tolist()[0]) for x in conn[:,1]]\n",
    "    if conn_name==\"mossy_to_glomerulus\":\n",
    "        syn_param = {\"synapse_model\": \"static_synapse\", \"weight\": conn_weights[conn_name], \"delay\": conn_delays[conn_name]}\n",
    "    else:\n",
    "        syn_param = {\"synapse_model\": \"static_synapse\", \"weight\": conn_weights[conn_name], \"delay\": conn_delays[conn_name],\"receptor_type\":conn_receptors[conn_name]}\n",
    "    nest.Connect(nest.NodeCollection(pre), nest.NodeCollection(post), {\"rule\": \"one_to_one\"}, syn_param)\n",
    "    print(\"Connections \", conn_name, \" done!\")\n",
    "\n",
    "    \n",
    "from pandas import Series\n",
    "from tvb_multiscale.core.spiking_models.devices import DeviceSet\n",
    "from tvb_multiscale.tvb_nest.nest_models.devices import NESTPoissonGenerator, NESTSpikeDetector, NESTMultimeter\n",
    "\n",
    "input_devices = Series()\n",
    "\n",
    "# ### Defining stimuli (needed only when there is no TVB input to the Cerebellum)\n",
    "# Into the next cell, the user can define the parameters value for the simulation. The background input is a 4 Hz Poisson process to glomeruli, for 300 ms. Then a 100-Hz burst is provided, lasting 100 ms. The user can set the following parameters:\n",
    "# 1. RECORD_VM: by default, spike data are recorded. If you want to record voltage-traces too, please set this variable to 'True', but consider that this is going to increase the computational time of the simulation.\n",
    "# 2. TOT_DURATION: duration of whole simulation, in milliseconds. \n",
    "# 3. STIM_START: when the burst (a Poisson process spike train) should start.\n",
    "# 4. STIM_END : when the burst should stop.\n",
    "# 5. STIM_FREQ: frequency of the burst\n",
    "RECORD_VM = True\n",
    "TOT_DURATION = 350. # 350 mseconds\n",
    "STIM_START = 150.   # 150 beginning of stimulation\n",
    "STIM_END = 250.     # 250 end of stimulation\n",
    "STIM_FREQ = 100.    # Frequency in Hz \n",
    "BACKGROUND_FREQ = 4.\n",
    "\n",
    "# # Create stimulation devices in NEST and connect to input neural populations (mossy_fibers).\n",
    "# mossy_fibers_num = len(neuron_models['mossy_fibers'])\n",
    "\n",
    "# STIM = nest.Create('poisson_generator', params={'rate':STIM_FREQ, 'start': STIM_START, 'stop': STIM_END})\n",
    "# # STIM as Poisson process\n",
    "# # TODO: Find out what this is!!!\n",
    "# # mossy_fibers_pos = np.array(f['cells/placement/mossy_fibers/positions'])\n",
    "# # x_c, z_c = 200., 200.\n",
    "\n",
    "# # Connection to glomeruli \n",
    "# nest.Connect(STIM, neuron_models['mossy_fibers']) \n",
    "# # Set it in a TVB-NEST DeviceSet class instance for the specific brain region:\n",
    "# input_devices[\"Stimulus\"] = DeviceSet(label=\"Stimulus\", model=\"poisson_generator\")\n",
    "# input_devices[\"Stimulus\"][nest_region_label] = NESTPoissonGenerator(STIM, nest)\n",
    "\n",
    "# # Background as Poisson process\n",
    "# background = nest.Create('poisson_generator',params={'rate':BACKGROUND_FREQ, 'start': 0.0, 'stop': TOT_DURATION}) \n",
    "# nest.Connect(background,neuron_models['mossy_fibers'])     \n",
    "# # Set it in a TVB-NEST DeviceSet class instance for the specific brain region:\n",
    "# input_devices[\"Background\"] = DeviceSet(label=\"Background\", model=\"poisson_generator\")\n",
    "# input_devices[\"Background\"][nest_region_label] = NESTPoissonGenerator(background, nest)\n",
    "\n",
    "\n",
    "# ### Defining recording devices\n",
    "output_devices = Series()\n",
    "\n",
    "# Create spike detectors and connect them to the cells; if the user selected RECORD_VM, also voltage will be recorded\n",
    "## Record spikes from granule and Golgi cells\n",
    "moss_fib_spikes = nest.Create(\"spike_detector\",\n",
    "                               params={\"record_to\": \"memory\", \"label\": \"mossy_fibers_spikes\"})\n",
    "glom_spikes = nest.Create(\"spike_detector\", params={\"record_to\": \"memory\", \"label\": \"glomerulus_spikes\"})\n",
    "grc_spikes = nest.Create(\"spike_detector\", params={\"record_to\": \"memory\", \"label\": \"granule_cell_spikes\"})\n",
    "goc_spikes = nest.Create(\"spike_detector\", params={\"record_to\": \"memory\", \"label\": \"golgi_cell_spikes\"})\n",
    "bc_spikes = nest.Create(\"spike_detector\", params={\"record_to\": \"memory\", \"label\": \"basket_cell_spikes\"})\n",
    "sc_spikes = nest.Create(\"spike_detector\", params={\"record_to\": \"memory\", \"label\": \"stellate_cell_spikes\"})\n",
    "pc_spikes = nest.Create(\"spike_detector\", params={\"record_to\": \"memory\", \"label\": \"purkinje_cell_spikes\"})\n",
    "dcn_spikes = nest.Create(\"spike_detector\", params={\"record_to\": \"memory\", \"label\": \"dcn_cell_spikes\"})\n",
    "\n",
    "# Here you can choose which devices you want to connect and thus the neural populations you want to record.\n",
    "# Increasing the number of recorded cells can increase the duration of the simulation\n",
    "nest.Connect(neuron_models['mossy_fibers'], moss_fib_spikes)\n",
    "nest.Connect(neuron_models['glomerulus'], glom_spikes)\n",
    "nest.Connect(neuron_models['granule_cell'], grc_spikes)\n",
    "nest.Connect(neuron_models['golgi_cell'], goc_spikes)\n",
    "nest.Connect(neuron_models['basket_cell'], bc_spikes)\n",
    "nest.Connect(neuron_models['stellate_cell'], sc_spikes)\n",
    "nest.Connect(neuron_models['purkinje_cell'], pc_spikes)\n",
    "nest.Connect(neuron_models['dcn_cell'], dcn_spikes)\n",
    "\n",
    "# Set them in a TVB-NEST DeviceSet class instance for the specific brain region:\n",
    "for device_id, label in zip([moss_fib_spikes, glom_spikes, grc_spikes, goc_spikes, \n",
    "                             bc_spikes, sc_spikes, pc_spikes, dcn_spikes], \n",
    "                            ['mossy_fibers', \"glomerulus_spikes\", \"granule_cell_spikes\", \"golgi_cell_spikes\", \n",
    "                             \"basket_cell_spikes\", \"stellate_cell_spikes\", \"purkinje_cell_spikes\", \"dcn_cell_spikes\"]):\n",
    "    output_devices[label] = DeviceSet(label=label, model=\"spike_detector\")\n",
    "    output_devices[label][nest_region_label] = NESTSpikeDetector(device_id, nest)\n",
    "\n",
    "    \n",
    "if RECORD_VM:\n",
    "    \n",
    "    def neurons_inds_fun(neurons_inds, n_neurons=100):\n",
    "        # We use this in order to measure up to n_neurons neurons from every population\n",
    "        n_neurons_inds = len(neurons_inds)\n",
    "        if n_neurons_inds > n_neurons:\n",
    "            return tuple(np.array(neurons_inds)[0:-1:int(np.ceil(1.0*n_neurons_inds/n_neurons))])\n",
    "        else:\n",
    "            return neurons_inds\n",
    "            \n",
    "    print(\"Recording membrane voltage\")\n",
    "    grc_vm = nest.Create(\"multimeter\")\n",
    "    goc_vm = nest.Create(\"multimeter\")\n",
    "    bc_vm = nest.Create(\"multimeter\")\n",
    "    sc_vm = nest.Create(\"multimeter\")                     \n",
    "    pc_vm = nest.Create(\"multimeter\")\n",
    "    dcn_vm = nest.Create(\"multimeter\")\n",
    "\n",
    "    nest.SetStatus(grc_vm, {\"record_from\": [\"V_m\"], \"record_to\": \"memory\", \"label\": \"granule_cell_vm\"})\n",
    "    nest.SetStatus(goc_vm, {\"record_from\": [\"V_m\"], \"record_to\": \"memory\", \"label\": \"golgi_cell_vm\"})\n",
    "    nest.SetStatus(bc_vm, {\"record_from\": [\"V_m\"], \"record_to\": \"memory\", \"label\": \"basket_cell_vm\"})\n",
    "    nest.SetStatus(sc_vm, {\"record_from\": [\"V_m\"], \"record_to\": \"memory\", \"label\": \"stellate_cell_vm\"})\n",
    "    nest.SetStatus(pc_vm, {\"record_from\": [\"V_m\"], \"record_to\": \"memory\", \"label\": \"purkinje_cell_vm\"})\n",
    "    nest.SetStatus(dcn_vm, {\"record_from\": [\"V_m\"], \"record_to\": \"memory\", \"label\": \"dcn_cell_vm\"})\n",
    "\n",
    "    nest.Connect(grc_vm, neurons_inds_fun(neuron_models['granule_cell']))\n",
    "    nest.Connect(goc_vm, neurons_inds_fun(neuron_models['golgi_cell']))\n",
    "    nest.Connect(bc_vm, neurons_inds_fun(neuron_models['basket_cell']))\n",
    "    nest.Connect(sc_vm, neurons_inds_fun(neuron_models['stellate_cell']))\n",
    "    nest.Connect(pc_vm, neurons_inds_fun(neuron_models['purkinje_cell']))\n",
    "    nest.Connect(dcn_vm, neurons_inds_fun(neuron_models['dcn_cell']))\n",
    "\n",
    "# Set them in a TVB-NEST DeviceSet class instance for the specific brain region:\n",
    "for device_id, label in zip([grc_vm, goc_vm, bc_vm, \n",
    "                             sc_vm, pc_vm, dcn_vm], \n",
    "                            [\"granule_cell_vm\", \"golgi_cell_vm\", \"basket_cell_vm\", \n",
    "                             \"stellate_cell_vm\", \"purkinje_cell_vm\", \"dcn_cell_vm\"]):\n",
    "    output_devices[label] = DeviceSet(label=label, model=\"multimeter\")\n",
    "    output_devices[label][nest_region_label] = NESTMultimeter(device_id, nest)\n",
    "\n",
    "    \n",
    "f.close()\n",
    "\n",
    "# Finally construct the NEST network model:\n",
    "from tvb_multiscale.tvb_nest.nest_models.network import NESTNetwork\n",
    "nest_model_builder._update_default_min_delay()\n",
    "nest_network = NESTNetwork(nest_instance=nest,\n",
    "                           brain_regions=nest_brain,\n",
    "                           output_devices=output_devices,\n",
    "                           input_devices=input_devices, \n",
    "                           config=nest_model_builder.config)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if \"nest_model_builder\" in globals():\n",
    "    populations_sizes = []\n",
    "    print(\"Population sizes: \")\n",
    "    for pop in nest_model_builder.populations:\n",
    "        populations_sizes.append(int(np.round(pop[\"scale\"] * nest_model_builder.population_order)))\n",
    "        print(\"%s: %d\" % (pop[\"label\"], populations_sizes[-1]))\n",
    "if \"nest_network\" in globals():\n",
    "    print(nest_network.print_str(connectivity=True))\n",
    "else:\n",
    "    nest_network = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:19:09.725185Z",
     "start_time": "2019-07-11T10:19:09.721072Z"
    }
   },
   "source": [
    "## 3. Build the TVB-NEST interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:11.137992Z",
     "start_time": "2019-07-12T20:36:10.880947Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tvb_multiscale.tvb_nest.interfaces.builders.models.linear_cereb import LinearCerebBuilder\n",
    "\n",
    "# Build a TVB-NEST interface with all the appropriate connections between the\n",
    "# TVB and NEST modelled regions\n",
    "tvb_nest_builder = \\\n",
    "    LinearCerebBuilder(simulator, nest_network, nest_nodes_ids, \n",
    "                       exclusive_nodes=True, populations_sizes=populations_sizes)\n",
    "\n",
    "tvb_to_nest_mode = \"rate\"\n",
    "nest_to_tvb = True\n",
    "\n",
    "# Using all default parameters for this example\n",
    "\n",
    "# or...\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----Uncomment below to modify the builder by changing the default options:--------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# TVB -> NEST\n",
    "\n",
    "\n",
    "# --------For spike transmission from TVB to NEST devices acting as TVB proxy nodes with TVB delays:--------\n",
    "from tvb_multiscale.core.spiking_models.builders.templates import scale_tvb_weight, tvb_delay\n",
    "\n",
    "tvb_nest_builder.G = tvb_nest_builder.tvb_simulator.model.G[0].item()\n",
    "tvb_nest_builder.global_coupling_scaling = tvb_nest_builder.tvb_simulator.coupling.a[0].item() * tvb_nest_builder.G\n",
    "    \n",
    "tvb_weight_fun = \\\n",
    "    lambda tvb_node_id: 200*tvb_nest_builder.global_coupling_scaling * \\\n",
    "                        tvb_nest_builder.tvb_weights[tvb_node_id, tvb_nest_builder.spiking_nodes_ids].sum()           \n",
    "\n",
    "tvb_delay_fun = \\\n",
    "    lambda source_node, target_node: \\\n",
    "        np.maximum(tvb_nest_builder.tvb_dt, tvb_delay(source_node, target_node, tvb_nest_builder.tvb_delays))\n",
    "\n",
    "tvb_nest_builder.tvb_to_spikeNet_interfaces = []\n",
    "if tvb_to_nest_mode == \"rate\":\n",
    "    # Mean spike rates are applied in parallel to all target neurons\n",
    "\n",
    "    tvb_nest_builder.tvb_to_spikeNet_interfaces.append(\n",
    "            {\"model\": \"inhomogeneous_poisson_generator\",\n",
    "             \"params\": {\"allow_offgrid_times\": False},\n",
    "             # ---Property potentially set as function handles with args (tvb_node_id=None),-----------\n",
    "             # ---applied outside NEST for each interface device-------------------------------------\n",
    "             \"interface_weights\": tvb_weight_fun, \n",
    "             # ----Properties potentially set as function handles with args (tvb_node_id=None, nest_node_id=None)---\n",
    "            \"weights\": 1.0, # lambda tvb_node_id, nest_node_id: tvb_weight_fun(tvb_node_id, nest_node_id),\n",
    "            \"delays\": tvb_delay_fun,\n",
    "            \"receptor_type\": 0,\n",
    "             # -----------------------------------------------------------------------------------------------------\n",
    "             #            TVB sv -> NEST population\n",
    "            \"connections\": {\"R\": \"mossy_fibers\"},\n",
    "            \"source_nodes\": None, \"target_nodes\": None} # None means all nodes\n",
    "    )   \n",
    "    \n",
    "if nest_to_tvb:\n",
    "    tvb_nest_builder.spikeNet_to_tvb_interfaces = []\n",
    "    # TVB <-- NEST:\n",
    "    connections = OrderedDict()    \n",
    "    #            TVB <- NEST\n",
    "    connections[\"Rin\"] = \"dcn_cell\"\n",
    "    tvb_nest_builder.spikeNet_to_tvb_interfaces.append(\n",
    "            {\"model\": \"spike_detector\", \"params\": {},\n",
    "             # --Properties potentially set as function handles with args (nest_node_id=None)----\n",
    "             \"interface_weights\": 5.0, \"delays\": 0.0,\n",
    "             # ----------------------------------------------------------------------------------\n",
    "             \"connections\": {\"Rin\": \"dcn_cell\"}, \"nodes\": None})  # None means all nodes\n",
    "\n",
    "tvb_nest_builder.w_tvb_to_spike_rate = 1.0\n",
    "# We return from a NEST spike_detector the ratio number_of_population_spikes / number_of_population_neurons\n",
    "# for every TVB time step, which is already a quantity in the range [0.0, 1.0],\n",
    "# as long as a neuron cannot fire twice during a TVB time step, i.e.,\n",
    "# as long as the TVB time step (usually 0.001 to 0.1 ms)\n",
    "# is smaller than the neurons' refractory time, t_ref (usually 1-2 ms)\n",
    "tvb_nest_builder.w_spikes_to_tvb = 1000.0\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "tvb_nest_model = tvb_nest_builder.build_interface(tvb_to_nest_mode=tvb_to_nest_mode, nest_to_tvb=nest_to_tvb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"tvb_nest_model\" in globals():\n",
    "    print(tvb_nest_model.print_str(detailed_output=True, connectivity=False))\n",
    "else:\n",
    "    tvb_nest_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure simulator, simulate, gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simulation and transient (to be optionally removed from resutls) times:\n",
    "simulation_length = nest_model_builder.TOT_DURATION\n",
    "transient = nest_model_builder.STIM_START / 3\n",
    "if transient:\n",
    "    exclude_times = [0.0, transient]\n",
    "else:\n",
    "    exclude_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:18.879872Z",
     "start_time": "2019-07-12T20:36:11.148945Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Configure the simulator with the TVB-NEST interface...\n",
    "# ...and simulate!\n",
    "tic = time.time()\n",
    "if tvb_nest_model is None:\n",
    "    print(\"Simulating only NEST...\")\n",
    "    nest_network.nest_instance.Prepare()\n",
    "    # Integrate NEST for simulation_length + 1 NEST time step so that multimeters get the last time point\n",
    "    # unless you plan to continue simulation later\n",
    "    nest_network.nest_instance.Run(simulation_length + nest_network.nest_instance.GetKernelStatus(\"resolution\"))\n",
    "    nest_network.nest_instance.Cleanup()\n",
    "    results = None\n",
    "else:\n",
    "    print(\"Simulating TVB-NEST...\")\n",
    "    simulator.configure(tvb_spikeNet_interface=tvb_nest_model)\n",
    "    # results = simulator.run(simulation_length=simulation_length)\n",
    "    print(\"...simulating brackground resting state...\")\n",
    "    results1 = simulator.run(simulation_length=nest_model_builder.STIM_START)\n",
    "    print(\"...simulating stimulus activity...\")\n",
    "    simulator.model.I_o[stim_node_id] = 10.0 # 0.75\n",
    "    results2 = simulator.run(simulation_length=nest_model_builder.STIM_END-nest_model_builder.STIM_START, \n",
    "                             configure_spiking_simulator=False)\n",
    "    print(\"...simulating relaxation to resting state...\")\n",
    "    simulator.model.I_o[stim_node_id] = 0.0\n",
    "    results3 = simulator.run(simulation_length=simulation_length-nest_model_builder.STIM_END, \n",
    "                             configure_spiking_simulator=False)\n",
    "    results = [[np.concatenate([results1[0][0], results2[0][0], results3[0][0]]),  # concat time\n",
    "                np.concatenate([results1[0][1], results2[0][1], results3[0][1]])]] # concat data\n",
    "    del results1, results2, results3\n",
    "    # Integrate NEST for one more NEST time step so that multimeters get the last time point\n",
    "    # unless you plan to continue simulation later\n",
    "    simulator.run_spiking_simulator(simulator.tvb_spikeNet_interface.nest_instance.GetKernelStatus(\"resolution\"))\n",
    "    # Clean-up NEST simulation\n",
    "    simulator.tvb_spikeNet_interface.nest_instance.Cleanup()\n",
    "print(\"\\nSimulated in %f secs!\" % (time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot results and write them to HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False for faster plotting of only mean field variables and dates, apart from spikes\" rasters:\n",
    "plot_per_neuron = True  \n",
    "# from examples.plot_write_results import plot_write_results\n",
    "# populations = []\n",
    "# populations_sizes = []\n",
    "# for pop in nest_model_builder.populations:\n",
    "#     populations.append(pop[\"label\"])\n",
    "#     populations_sizes.append(int(np.round(pop[\"scale\"] * nest_model_builder.population_order)))\n",
    "# plot_write_results(results, simulator, populations=populations, populations_sizes=populations_sizes, \n",
    "#                    transient=transient, tvb_state_variable_type_label=\"State Variables\", \n",
    "#                    tvb_state_variables_labels=simulator.model.variables_of_interest, \n",
    "#                    plot_per_neuron=plot_per_neuron, plotter=plotter, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to see what the function above does, take the steps, one by one\n",
    "try:\n",
    "    # We need framework_tvb for writing and reading from HDF5 files\n",
    "    from tvb_multiscale.core.io.h5_writer import H5Writer\n",
    "    writer = H5Writer()\n",
    "except:\n",
    "    writer = False\n",
    "    \n",
    "from tvb.contrib.scripts.datatypes.time_series import TimeSeriesRegion\n",
    "from tvb.contrib.scripts.datatypes.time_series_xarray import TimeSeriesRegion as TimeSeriesXarray\n",
    "\n",
    "# Put the results in a Timeseries instance\n",
    "from tvb.contrib.scripts.datatypes.time_series import TimeSeriesRegion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. TVB results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:18.997574Z",
     "start_time": "2019-07-12T20:36:18.885020Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "source_ts = None\n",
    "if results is not None:\n",
    "    source_ts = TimeSeriesXarray(  # substitute with TimeSeriesRegion fot TVB like functionality\n",
    "            data=results[0][1], time=results[0][0],\n",
    "            connectivity=simulator.connectivity,\n",
    "            labels_ordering=[\"Time\", \"State Variable\", \"Region\", \"Neurons\"],\n",
    "            labels_dimensions={\"State Variable\": list(simulator.model.variables_of_interest),\n",
    "                               \"Region\": simulator.connectivity.region_labels.tolist()},\n",
    "            sample_period=simulator.integrator.dt)\n",
    "    source_ts.configure()\n",
    "\n",
    "    # Remove transient, if any\n",
    "    if transient:\n",
    "        source_ts = source_ts[transient:]\n",
    "        exclude_times = [0.0, transient]\n",
    "    else:\n",
    "        exclude_times = []\n",
    "    t = source_ts.time\n",
    "\n",
    "    # Write to file\n",
    "    if writer:\n",
    "        writer.write_tvb_to_h5(TimeSeriesRegion().from_xarray_DataArray(source_ts._data,\n",
    "                                                                        connectivity=source_ts.connectivity),\n",
    "                               os.path.join(config.out.FOLDER_RES, source_ts.title)+\".h5\")\n",
    "    source_ts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if source_ts is not None:\n",
    "    # Plot TVB time series\n",
    "    source_ts.plot_timeseries(plotter_config=plotter.config, per_variable=True, figsize=FIGSIZE, add_legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if source_ts is not None:\n",
    "    # TVB time series raster plot:\n",
    "    if source_ts.number_of_labels > 9:\n",
    "        source_ts.plot_raster(plotter_config=plotter.config, per_variable=True, figsize=FIGSIZE, add_legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more informative figure with the 10 regions with highest mean firing rate and legend:\n",
    "MeanRate = source_ts.data[:, 0].mean(axis=0).flatten()\n",
    "inds = np.argsort(MeanRate)[::-1][:10]\n",
    "source_ts[:,\"R\",inds, :].plot_timeseries(plotter_config=plotter.config, per_variable=True, figsize=FIGSIZE, add_legend=True);\n",
    "from matplotlib import pyplot\n",
    "fontsize = 20\n",
    "for ax in pyplot.gcf().axes:\n",
    "#     ax.get_yticks().set_fontsize(fontsize)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_title(ax.get_ylabel(), fontsize=fontsize)\n",
    "    ax.set_ylabel(\"\")\n",
    "    for text in ax.get_legend().get_texts():\n",
    "        text.set_fontsize(16)\n",
    "    ax.get_legend().get_title().set_fontsize(18)\n",
    "    \n",
    "source_ts[:,\"Rin\",inds, :].plot_timeseries(plotter_config=plotter.config, per_variable=True, figsize=FIGSIZE, add_legend=False);\n",
    "for ax in pyplot.gcf().axes:\n",
    "#     ax.get_yticks().set_fontsize(fontsize)\n",
    "#     ax.get_xticks().set_fontsize(fontsize)\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=fontsize)\n",
    "    ax.set_title(ax.get_ylabel(), fontsize=fontsize)\n",
    "    ax.set_ylabel(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ...interactively as well\n",
    "# # For interactive plotting:\n",
    "# %matplotlib notebook \n",
    "# plotter.plot_timeseries_interactive(source_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The stimunlated region:\n",
    "# source_ts[:, :, stim_node_id].plot_timeseries(plotter_config=plotter.config, per_variable=True, figsize=FIGSIZE,\n",
    "#                                              figname=\"Stimulated region TVB Time Series\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Focus on the nodes modelled in NEST:\n",
    "# try:\n",
    "#     tvb_nest_model = simulator.tvb_spikeNet_interface\n",
    "# except:\n",
    "#     pass\n",
    "# source_ts_nest = None\n",
    "# if tvb_nest_model is not None:\n",
    "#     n_spiking_nodes = len(simulator.tvb_spikeNet_interface.spiking_nodes_ids)\n",
    "#     source_ts_nest = source_ts[:, :, simulator.tvb_spikeNet_interface.spiking_nodes_ids]\n",
    "#     source_ts_nest.plot_timeseries(plotter_config=plotter.config, per_variable=True, figsize=FIGSIZE,\n",
    "#                                    figname=\"Spiking nodes TVB Time Series\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Focus on the nodes modelled in NEST: raster plot\n",
    "# if source_ts_nest is not None:\n",
    "#     source_ts_nest.plot_raster(plotter_config=plotter.config, per_variable=True, figsize=FIGSIZE,\n",
    "#                                figname=\"Spiking nodes TVB Time Series Raster\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Spiking Network plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb_multiscale.tvb_elephant.spiking_network_analyser import SpikingNetworkAnalyser\n",
    "# Create a SpikingNetworkAnalyzer:\n",
    "spikeNet_analyzer = \\\n",
    "    SpikingNetworkAnalyser(spikeNet=nest_network,\n",
    "                           start_time=source_ts.time[0], end_time=source_ts.time[-1], \n",
    "                           period=simulator.monitors[0].period,\n",
    "                           time_series_output_type=\"TVB\", return_data=True, \n",
    "                           force_homogeneous_results=True, connectivity=simulator.connectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spikes' raster and mean spike rates and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spikes rates and correlations per Population and Region\n",
    "spikes_res = \\\n",
    "    spikeNet_analyzer.\\\n",
    "        compute_spikeNet_spikes_rates_and_correlations(\n",
    "            populations_devices=None, regions=None,\n",
    "            rates_methods=[], rates_kwargs=[{}],rate_results_names=[],\n",
    "            corrs_methods=[], corrs_kwargs=[{}], corrs_results_names=[], bin_kwargs={},\n",
    "            data_method=spikeNet_analyzer.get_spikes_from_device, data_kwargs={},\n",
    "            return_devices=False\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(spikes_res[\"mean_rate\"])\n",
    "    print(spikes_res[\"spikes_correlation_coefficient\"])\n",
    "    # Plot spikes' rasters together with mean population's spikes' rates' time series\n",
    "    if plotter:\n",
    "        plotter.plot_spike_events(spikes_res[\"spikes\"], rates=spikes_res[\"mean_rate_time_series\"], figsize=FIGSIZE)\n",
    "        from tvb_multiscale.core.plot.correlations_plot import plot_correlations\n",
    "        plot_correlations(spikes_res[\"spikes_correlation_coefficient\"], plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_res and writer:\n",
    "    writer.write_object(spikes_res[\"spikes\"].to_dict(), \n",
    "                        path=os.path.join(config.out.FOLDER_RES,  \"Spikes\") + \".h5\");\n",
    "    writer.write_object(spikes_res[\"mean_rate\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"mean_rate\"].name) + \".h5\");\n",
    "    writer.write_tvb_to_h5(TimeSeriesRegion().from_xarray_DataArray(\n",
    "                              spikes_res[\"mean_rate_time_series\"]._data,\n",
    "                               connectivity=spikes_res[\"mean_rate_time_series\"].connectivity),\n",
    "                           os.path.join(config.out.FOLDER_RES,\n",
    "                                        spikes_res[\"mean_rate_time_series\"].title) + \".h5\",\n",
    "                           recursive=False);\n",
    "    writer.write_object(spikes_res[\"spikes_correlation_coefficient\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"spikes_correlation_coefficient\"].name) + \".h5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  SpikingNetwork mean field variable time series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous time variables' data of spiking neurons\n",
    "if plot_per_neuron:\n",
    "    spikeNet_analyzer.return_data = True\n",
    "else:\n",
    "    spikeNet_analyzer.return_data = False\n",
    "spikeNet_ts = \\\n",
    "    spikeNet_analyzer. \\\n",
    "         compute_spikeNet_mean_field_time_series(populations_devices=None, regions=None, variables=None,\n",
    "                                                 computations_kwargs={}, data_kwargs={}, return_devices=False)\n",
    "if spikeNet_ts:\n",
    "    if plot_per_neuron:\n",
    "        mean_field_ts = spikeNet_ts[\"mean_field_time_series\"]  # mean field\n",
    "        spikeNet_ts = spikeNet_ts[\"data_by_neuron\"]  # per neuron data\n",
    "    else:\n",
    "        mean_field_ts = spikeNet_ts\n",
    "        spikeNet_ts = None\n",
    "    if mean_field_ts and mean_field_ts.size > 0:\n",
    "        mean_field_ts.plot_timeseries(plotter_config=plotter.config, per_variable=True)\n",
    "        if mean_field_ts.shape[2] > 3:\n",
    "            mean_field_ts.plot_raster(plotter_config=plotter.config, per_variable=True,\n",
    "                                      linestyle=\"--\", alpha=0.5, linewidth=0.5)\n",
    "else:\n",
    "    mean_field_ts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to file:\n",
    "if mean_field_ts and writer:\n",
    "    writer.write_tvb_to_h5(TimeSeriesRegion().from_xarray_DataArray(\n",
    "                                       mean_field_ts._data,\n",
    "                                       connectivity=mean_field_ts.connectivity),\n",
    "                           os.path.join(config.out.FOLDER_RES, mean_field_ts.title) + \".h5\", \n",
    "                           recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute per neuron spikes' rates times series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_res and plot_per_neuron:\n",
    "    from tvb.simulator.plot.base_plotter import pyplot\n",
    "    spikeNet_analyzer.return_data = False\n",
    "    rates_ts_per_neuron = \\\n",
    "        spikeNet_analyzer. \\\n",
    "            compute_spikeNet_rates_time_series(populations_devices=None, regions=None,\n",
    "                                               computations_kwargs={}, data_kwargs={},\n",
    "                                               return_spikes_trains=False, return_devices=False);\n",
    "    if rates_ts_per_neuron is not None and rates_ts_per_neuron.size:\n",
    "        # Regions in rows\n",
    "        row = rates_ts_per_neuron.dims[2] if rates_ts_per_neuron.shape[2] > 1 else None\n",
    "        if row is None:\n",
    "            # Populations in rows\n",
    "            row = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "            col = None\n",
    "        else:\n",
    "            # Populations in columns\n",
    "            col = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "        pyplot.figure()\n",
    "        rates_ts_per_neuron.plot(y=rates_ts_per_neuron.dims[3], row=row, col=col, cmap=\"jet\")\n",
    "        plotter.base._save_figure(figure_name=\"Spike rates per neuron\")\n",
    "        # del rates_ts_per_neuron # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot per neuron SpikingNetwork time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regions in rows\n",
    "if spikeNet_ts is not None and spikeNet_ts.size:\n",
    "    row = spikeNet_ts.dims[2] if spikeNet_ts.shape[2] > 1 else None\n",
    "    if row is None:\n",
    "        # Populations in rows\n",
    "        row = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "        col = None\n",
    "    else:\n",
    "        # Populations in cols\n",
    "         col = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "    for var in spikeNet_ts.coords[spikeNet_ts.dims[1]]:\n",
    "        this_var_ts = spikeNet_ts.loc[:, var, :, :, :]\n",
    "        this_var_ts.name = var.item()\n",
    "        pyplot.figure()\n",
    "        this_var_ts.plot(y=spikeNet_ts.dims[4], row=row, col=col, cmap=\"jet\", figsize=FIGSIZE)\n",
    "        plotter.base._save_figure(\n",
    "            figure_name=\"Spiking Network variables' time series per neuron: %s\" % this_var_ts.name)\n",
    "    del spikeNet_ts # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# References\n",
    "\n",
    "1 Paula Sanz Leon, Stuart A. Knock, M. Marmaduke Woodman, Lia Domide, <br>\n",
    "  Jochen Mersmann, Anthony R. McIntosh, Viktor Jirsa (2013) <br>\n",
    "  The Virtual Brain: a simulator of primate brain network dynamics. <br>\n",
    "  Frontiers in Neuroinformatics (7:10. doi: 10.3389/fninf.2013.00010) <br>\n",
    "  https://www.thevirtualbrain.org/tvb/zwei <br>\n",
    "  https://github.com/the-virtual-brain <br>\n",
    "\n",
    "2 Ritter P, Schirner M, McIntosh AR, Jirsa VK. 2013.  <br>\n",
    "  The Virtual Brain integrates computational modeling  <br>\n",
    "  and multimodal neuroimaging. Brain Connectivity 3:121145. <br>\n",
    "\n",
    "3 Jordan, Jakob; Mrk, Hkon; Vennemo, Stine Brekke;   Terhorst, Dennis; Peyser, <br>\n",
    "  Alexander; Ippen, Tammo; Deepu, Rajalekshmi;   Eppler, Jochen Martin; <br>\n",
    "  van Meegen, Alexander;   Kunkel, Susanne; Sinha, Ankur; Fardet, Tanguy; Diaz, <br>\n",
    "  Sandra; Morrison, Abigail; Schenck, Wolfram; Dahmen, David;   Pronold, Jari; <br>\n",
    "  Stapmanns, Jonas;   Trensch, Guido; Spreizer, Sebastian;   Mitchell, Jessica; <br>\n",
    "  Graber, Steffen; Senk, Johanna; Linssen, Charl; Hahne, Jan; Serenko, Alexey; <br>\n",
    "  Naoumenko, Daniel; Thomson, Eric;   Kitayama, Itaru; Berns, Sebastian;   <br>\n",
    "  Plesser, Hans Ekkehard <br>\n",
    "  NEST is a simulator for spiking neural network models that focuses <br>\n",
    "  on the dynamics, size and structure of neural systems rather than on <br>\n",
    "  the exact morphology of individual neurons. <br>\n",
    "  For further information, visit http://www.nest-simulator.org. <br>\n",
    "  The release notes for this release are available at  <br>\n",
    "  https://github.com/nest/nest-simulator/releases/tag/v2.18.0 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
