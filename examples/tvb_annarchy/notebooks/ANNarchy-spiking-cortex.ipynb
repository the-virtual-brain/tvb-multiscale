{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVB-ANNarchy: Bridging multiscale activity by co-simulation\n",
    "\n",
    "## Step-by-step learn how to perform a co-simulation embedding spiking neural networks into large-scale brain networks using TVB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Izhikevich Spiking network model in ANNarchy\n",
    "\n",
    "For every neuron $i$ in region node $n$ modelled in ANNarchy as a spiking network:\n",
    "\n",
    "Membrane potential:\n",
    "\n",
    "$ \\dot{V}_m = n_2V_m^2 + n_1V_m + n_0140 - U_m/C $\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;- g_{AMPA}(V_m-E_{AMPA}) - g_{GABA}(V_m-E_{GABA}) - g_{BASE}V_m + I_e $\n",
    "\n",
    "where the conductances follow the equations:\n",
    "\n",
    "$ \\dot{g}_{AMPA} = - g_{AMPA} / \\tau_{AMPA} + \\left[\\sum_k \\delta(t-t_k) \\right]_{Exc}$\n",
    "\n",
    "$ \\dot{g}_{GABA} = - g_{GABA} / \\tau_{GABA} + \\left[\\sum_k \\delta(t-t_k) \\right]_{Inh}$\n",
    "\n",
    "$ \\dot{g}_{BASE} = - g_{BASE} / \\tau_{BASE} + \\left[\\sum_k \\delta(t-t_k) \\right]_{BASE}$\n",
    "\n",
    "and recovery variable:\n",
    "\n",
    "$ \\dot{U}_m = a(bV_m - U_m)$\n",
    "\n",
    "\n",
    "When $ V_m > V_{th} $ , $ V_m $ is set to $ c $, and $ U_m $ is incremented by $ d $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:57.561354Z",
     "start_time": "2019-07-12T20:35:52.475653Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from tvb.basic.profile import TvbProfile\n",
    "TvbProfile.set_profile(TvbProfile.LIBRARY_PROFILE)\n",
    "\n",
    "from tvb_multiscale.tvb_annarchy.config import *\n",
    "\n",
    "work_path = os.getcwd()\n",
    "data_path = os.path.expanduser(\"~/packages/tvb-multiscale/examples/data/basal_ganglia\")\n",
    "fit_data_path = os.path.join(data_path, \"ANNarchyFittedModels/dataFits_2020_02_05/databestfits\", )\n",
    "data_mode = \"patient\" # \"control\" \"patient\"\n",
    "control_data = os.path.join(fit_data_path, \"controlleft/OutputSim_Patient08.mat\")\n",
    "patient_data = os.path.join(fit_data_path, \"patientleft/OutputSim_Patient09.mat\")\n",
    "if data_mode == \"patient\":\n",
    "    subject_data = patient_data\n",
    "else:\n",
    "    subject_data = control_data\n",
    "    \n",
    "simulation_length = 1500.0\n",
    "transient = 500.0 # simulation_length/11\n",
    "start_stimulus = 400.0\n",
    "\n",
    "SPIKING_NODES_DELAYS = False\n",
    "\n",
    "ANNARCHY_CORTEX_MODE = \"Izhikevich\" # \"Izhikevich\", \"PoissonCorr\", or \"Poisson\"\n",
    "\n",
    "noise = 35.0\n",
    "\n",
    "simulation_mode = \"rs\"       # \"stim\" or \"rs\"\n",
    "stim_target = \"STN\"          #     \"STN\"          \"GPi\"\n",
    "stim_mode = \"bi\"         # \"bi\"  | \"mono\" | \"simple\"\n",
    "                             # -------------------------\n",
    "stim_freq = 130.0              # 130.0 |  120.0 |    0.0 \n",
    "stim_ampl =20.0            #  20.0 |  -35.0 |  -10.0 \n",
    "stim_duration = 0.3          #   0.3 |    0.3 |    -\n",
    "if simulation_mode == \"stim\":\n",
    "    simulation_mode = simulation_mode + \"_%s_%s\" % (stim_target, stim_mode)\n",
    "    if noise > 0.0:\n",
    "        simulation_mode += \"_n%g\" % noise\n",
    "        \n",
    "outputs_path = os.path.join(work_path, \"outputs\")\n",
    "sim_mode_dirname = \"SpikingPoissonCortex\" if ANNARCHY_CORTEX_MODE==\"PoissonCorr\" else \"SpikingCortex\"\n",
    "sim_mode_path = os.path.join(outputs_path, sim_mode_dirname, data_mode, simulation_mode)\n",
    "config = Config(output_base=sim_mode_path)\n",
    "config.figures.SHOW_FLAG = True \n",
    "config.figures.SAVE_FLAG = True\n",
    "config.figures.FIG_FORMAT = 'png'\n",
    "config.figures.DEFAULT_SIZE= config.figures.NOTEBOOK_SIZE\n",
    "FIGSIZE = config.figures.DEFAULT_SIZE\n",
    "\n",
    "from tvb_multiscale.core.plot.plotter import Plotter\n",
    "plotter = Plotter(config.figures)\n",
    "\n",
    "# For interactive plotting:\n",
    "# %matplotlib notebook  \n",
    "\n",
    "# Otherwise:\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Load structural data <br> (minimally a TVB connectivity)  <br> & prepare TVB simulator  <br> (region mean field model, integrator, monitors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:59.690799Z",
     "start_time": "2019-07-12T20:35:57.571529Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from tvb_multiscale.core.tvb.cosimulator.models.reduced_wong_wang_exc_io import ReducedWongWangExcIO\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----Uncomment below to modify the simulator by changing the default options:--------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "from tvb.datatypes.connectivity import Connectivity\n",
    "from tvb_multiscale.core.tvb.cosimulator.cosimulator_serial import CoSimulatorSerial as CoSimulator\n",
    "from tvb.simulator.integrators import HeunStochastic\n",
    "from tvb.simulator.monitors import Raw  # , Bold, EEG\n",
    "    \n",
    "\n",
    "conn_path = os.path.join(data_path, \"conn_incl_cortex\")\n",
    "\n",
    "w=np.zeros((11,11))\n",
    "c=np.loadtxt(os.path.join(conn_path, \"aal_plus_BG_centers_incl_cortex.txt\"), usecols=range(1,4))\n",
    "rl= np.loadtxt(os.path.join(conn_path, \"aal_plus_BG_centers_incl_cortex.txt\"), dtype=\"str\", usecols=(0,))\n",
    "t= np.loadtxt(os.path.join(conn_path, \"BGplusAAL_tract_lengths_incl_cortex.txt\"))\n",
    "\n",
    "# Keep only the BG and a single Cortex node:\n",
    "c = c[:11]\n",
    "rl = rl[:11]\n",
    "rl[10] = \"Cortex\"\n",
    "w = w[:11][:, :11]\n",
    "t = t[:11][:, :11]\n",
    "\n",
    "# Keep only left hemisphere and the Cortex:\n",
    "inds = np.arange(0,10,2).astype(\"i\").tolist() + [10]\n",
    "c = c[inds] \n",
    "rl = rl[inds]\n",
    "print(\"Region labels:\\n%s\" % rl)\n",
    "# 0. GPe_Left, 1. GPi_Left, 2. STN_Left, 3. Striatum_Left, 4. Thal_Left, 5. Cortex\n",
    "w = w[inds][:, inds]\n",
    "t = t[inds][:, inds]\n",
    "\n",
    "# % loadedParams ={\n",
    "# %     \t'D1GPi_probs': probs[0],\n",
    "# %     \t'D1GPi_weights'  : weights[0],\n",
    "# %     \t'D2GPe_probs'   : probs[1],\n",
    "# %     \t'D2GPe_weights'  : weights[1],\n",
    "# %     \t'GPeSTN_probs'   : probs[2],\n",
    "# %     \t'GPeSTN_weights'  : weights[2],\n",
    "# %     \t'STNGPe_probs'   : probs[3],\n",
    "# %     \t'STNGPe_weights'  : weights[3],\n",
    "# %     \t'STNGPi_probs'   : probs[4],\n",
    "# %     \t'STNGPi_weights' : weights[4],\n",
    "# %     \t'GPeGPi_probs'   : probs[5],\n",
    "# %     \t'GPeGPi_weights'  : weights[5],\n",
    "# %     \t'GPeGPe_probs'   : probs[6],\n",
    "# %     \t'GPeGPe_weights'  : weights[6],\n",
    "# %     \t'GPiGPi_probs'   : probs[7],\n",
    "# %     \t'GPiGPi_weights'  : weights[7],\n",
    "# %     \t'GPiThal_probs'   : probs[8],\n",
    "# %     \t'GPiThal_weights'  : weights[8],\n",
    "# %     \t'ThaliSN_probs'   : probs[9],\n",
    "# %     \t'ThaliSN_weights'  : weights[9],\n",
    "# %     \t'ThaldSN_probs'   : probs[10],\n",
    "# %     \t'ThaldSN_weights'  : weights[10],\n",
    "# %     \t'dSNdSN_probs'   : probs[11],\n",
    "# %     \t'dSNdSN_weights'  : weights[11],\n",
    "# %     \t'iSNiSN_probs'   : probs[12],\n",
    "# %     \t'iSNiSN_weights'  : weights[12],\n",
    "# %     \t'CdSN_probs'   : probs[13],\n",
    "# %     \t'CdSN_weights'  : weights[13],\n",
    "# %     \t'CiSN_probs'   : probs[14],\n",
    "# %     \t'CiSN_weights'  : weights[14],\n",
    "# %     \t'CSTN_probs'   : probs[15],\n",
    "# %     \t'CSTN_weights'  : weights[15],\n",
    "# %     \t'V1Inh_probs'    : probs[16],\n",
    "# %     \t'V1Inh_weights'  : weights[16],\n",
    "# %     \t'InhV1_probs'    : probs[17],\n",
    "# %     \t'InhV1_weights'  : weights[17],\n",
    "# %     \t'InhInh_probs'   : probs[18],\n",
    "# %     \t'InhInh_weights'  : weights[18]}\n",
    "\n",
    "\n",
    "# 0. GPe_Left, 1. GPi_Left, 2. STN_Left, 3. Striatum_Left, 4. Thal_Left\n",
    "BG_opt_matrix_weights = np.zeros((5, 5))\n",
    "conn_mode = \"subject\" # \"average\"\n",
    "if conn_mode == \"average\":\n",
    "    weights_maith = np.array([1.93, 3.56, 1.46, 4.51, 3.52, 2.30, 2.34, 3.78, 1.98, \n",
    "                             1.30, 1.82, 3.56, 3.02, 1.78, 1.36, 2.27, 4.13, 2.74, 3.27])*1e-3  # controls\n",
    "#     weights_maith = np.array([3.27, 3.80, 2.65, 3.66, 3.06, 3.06, 3.25, 4.02, 3.32, \n",
    "#                             2.98, 3.45, 3.64, 2.50, 2.12, 2.86, 2.79, 3.96, 3.69, 3.87])*1e-3   # patients\n",
    "    # probs_maith = ????\n",
    "else:\n",
    "    import scipy.io as sio\n",
    "    weights=sio.loadmat(subject_data) # weights start from index 19\n",
    "    weights_maith = weights[\"X\"][0, 19:] # these are indices 19 till 37\n",
    "    probs_maith = weights[\"X\"][0, :19] # these are indices 0 till 18\n",
    "\n",
    "wdSNGPi = BG_opt_matrix_weights[3, 1] = weights_maith[0]\n",
    "wiSNGPe = BG_opt_matrix_weights[3, 0] = weights_maith[1]\n",
    "wGPeSTN = BG_opt_matrix_weights[0, 2] = weights_maith[2]\n",
    "wSTNGPe = BG_opt_matrix_weights[2, 0] = weights_maith[3]\n",
    "wSTNGPi = BG_opt_matrix_weights[2, 1] = weights_maith[4]\n",
    "wGPeGPi = BG_opt_matrix_weights[0, 1] = weights_maith[5]  \n",
    "wGPiTh = BG_opt_matrix_weights[1, 4] = weights_maith[8]\n",
    "wThdSN = BG_opt_matrix_weights[4, 3] = weights_maith[10] # Th -> dSN\n",
    "    \n",
    "sliceBGnet = slice(0,5)\n",
    "w[sliceBGnet, sliceBGnet] = BG_opt_matrix_weights\n",
    "\n",
    "wGPeGPe = weights_maith[6]             # \"GPe\" -> \"GPe\" \n",
    "wGPiGPi = weights_maith[7]             # \"GPi\" -> \"GPi\" \n",
    "wThiSN = weights_maith[9]              # \"Eth\" -> \"IiSN\" \n",
    "\n",
    "wdSNdSN = weights_maith[11]            # \"IdSN\" -> \"IdSN\" \n",
    "wiSNiSN = weights_maith[12]            # \"IiSN\" -> \"IiSN\" \n",
    "wCtxdSN = w[5, 3] = weights_maith[13]  # \"CxE\" -> \"IdSN\" \n",
    "wCtxiSN = weights_maith[14]            # \"CxE\" -> \"IiSN\" \n",
    "wCtxSTN = w[5, 2] = weights_maith[15]  # \"CxE\" -> \"Estn\"\n",
    "wCtxEtoI = weights_maith[16]           # \"CxE\" -> \"CxI\"\n",
    "wCtxItoE = weights_maith[17]           # \"CxI\" -> \"CxE\"\n",
    "wCtxItoI = weights_maith[18]           # \"CxI\" -> \"CxI\"\n",
    "\n",
    "pdSNGPi = probs_maith[0]\n",
    "piSNGPe = probs_maith[1]\n",
    "pGPeSTN = probs_maith[2]\n",
    "pSTNGPe = probs_maith[3]\n",
    "pSTNGPi = probs_maith[4]\n",
    "pGPeGPi = probs_maith[5]  \n",
    "pGPeGPe = probs_maith[6]            # \"GPe\" -> \"GPe\" \n",
    "pGPiGPi = probs_maith[7]            # \"GPi\" -> \"GPi\" \n",
    "pGPiTh = probs_maith[8]\n",
    "pThiSN =  probs_maith[9]            # \"Eth\" -> \"IiSN\n",
    "pThdSN = probs_maith[10]            # Th --> dSN\n",
    "pdSNdSN = probs_maith[11]           # \"IdSN\" -> \"IdSN\" \n",
    "piSNiSN = probs_maith[12]           # \"IiSN\" -> \"IiSN\" \n",
    "pCtxdSN = probs_maith[13]           # \"CxE\" -> \"IdSN\" \n",
    "pCtxiSN = probs_maith[14]           # \"CxE\" -> \"IiSN\" \n",
    "pCtxSTN = probs_maith[15]           # \"CxE\" -> \"Estn\"\n",
    "pCtxEtoI = probs_maith[16]          # \"CxE\" -> \"CxI\"\n",
    "pCtxItoE = probs_maith[17]          # \"CxI\" -> \"CxE\"\n",
    "pCtxItoI = probs_maith[18]          # \"CxI\" -> \"CxI\"\n",
    "\n",
    "pCtxCtx = probs_maith[16:19].mean() # \"Ctx\" <-> \"Ctx\"\n",
    "\n",
    "loadedParams ={'dSNGPi_probs': probs_maith[0],\n",
    "    \t'dSNGPi_weights'  : weights_maith[0],\n",
    "    \t'iSNGPe_probs'   : probs_maith[1],\n",
    "    \t'iSNGPe_weights'  : weights_maith[1],\n",
    "    \t'GPeSTN_probs'   : probs_maith[2],\n",
    "    \t'GPeSTN_weights'  : weights_maith[2],\n",
    "    \t'STNGPe_probs'   : probs_maith[3],\n",
    "    \t'STNGPe_weights'  : weights_maith[3],\n",
    "    \t'STNGPi_probs'   : probs_maith[4],\n",
    "    \t'STNGPi_weights' : weights_maith[4],\n",
    "    \t'GPeGPi_probs'   : probs_maith[5],\n",
    "    \t'GPeGPi_weights'  : weights_maith[5],\n",
    "    \t'GPeGPe_probs'   : probs_maith[6],\n",
    "    \t'GPeGPe_weights'  : weights_maith[6],\n",
    "    \t'GPiGPi_probs'   : probs_maith[7],\n",
    "    \t'GPiGPi_weights'  : weights_maith[7],\n",
    "    \t'GPiThal_probs'   : probs_maith[8],\n",
    "    \t'GPiThal_weights'  : weights_maith[8],\n",
    "    \t'ThaliSN_probs'   : probs_maith[9],\n",
    "    \t'ThaliSN_weights'  : weights_maith[9],\n",
    "    \t'ThaldSN_probs'   : probs_maith[10],\n",
    "    \t'ThaldSN_weights'  : weights_maith[10],\n",
    "    \t'dSNdSN_probs'   : probs_maith[11],\n",
    "    \t'dSNdSN_weights'  : weights_maith[11],\n",
    "    \t'iSNiSN_probs'   : probs_maith[12],\n",
    "    \t'iSNiSN_weights'  : weights_maith[12],\n",
    "    \t'CtxdSN_probs'   : probs_maith[13],\n",
    "    \t'CtxdSN_weights'  : weights_maith[13],\n",
    "    \t'CtxiSN_probs'   : probs_maith[14],\n",
    "    \t'CtxiSN_weights'  : weights_maith[14],\n",
    "    \t'CtxSTN_probs'   : probs_maith[15],\n",
    "    \t'CtxSTN_weights'  : weights_maith[15],\n",
    "    \t'CtxECtxI_probs'    : probs_maith[16],\n",
    "    \t'CtxECtxI_weights'  : weights_maith[16],\n",
    "    \t'CtxICtxE_probs'    : probs_maith[17],\n",
    "    \t'CtxICtxE_weights'  : weights_maith[17],\n",
    "    \t'CtxICtxI_probs'   : probs_maith[18],\n",
    "    \t'CtxICtxI_weights'  : weights_maith[18],\n",
    "        'CtxThal_weights': 0.0,\n",
    "        'CtxThal_probs': 1.0}\n",
    "print(loadedParams)\n",
    "\n",
    "assert_loadedParams = dict(zip(loadedParams.values(), loadedParams.keys()))\n",
    "\n",
    "# Finally form the TVB Connectivity\n",
    "dt = 0.1\n",
    "speed = 4.0\n",
    "if not SPIKING_NODES_DELAYS:\n",
    "    t = dt * speed * np.ones(t.shape)\n",
    "connectivity=Connectivity(region_labels=rl, weights=w.T, # !!!NOTE TVB indices convention!!!\n",
    "                          centres=c, tract_lengths=t)\n",
    "\n",
    "connectivity.speed = np.array([speed])\n",
    "connectivity.configure()\n",
    "\n",
    "# Create a TVB simulator\n",
    "# We choose all defaults in this example\n",
    "simulator = CoSimulator()\n",
    "#simulator.use_numba = False\n",
    "model_params = {}\n",
    "simulator.model = ReducedWongWangExcIO(**model_params)\n",
    "\n",
    "simulator.connectivity = connectivity\n",
    "\n",
    "simulator.integrator = HeunStochastic()\n",
    "simulator.integrator.dt = dt\n",
    "simulator.integrator.noise.nsig = np.array([0.001])\n",
    "\n",
    "mon_raw = Raw(period=1.0)  # ms\n",
    "simulator.monitors = (mon_raw, )\n",
    "\n",
    "plotter.plot_tvb_connectivity(simulator.connectivity);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build and connect the ANNarchy network model <br> (networks of spiking neural populations for fine-scale <br>regions, stimulation devices, spike detectors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:10.862262Z",
     "start_time": "2019-07-12T20:36:10.000332Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tvb_multiscale.tvb_annarchy.annarchy_models.models.basal_ganglia_izhikevich import BasalGangliaIzhikevichBuilder\n",
    "from tvb_multiscale.tvb_annarchy.annarchy.models import Izhikevich_Hamker\n",
    "from ANNarchy import HomogeneousCorrelatedSpikeTrains, PoissonPopulation\n",
    "\n",
    "# Select the regions for the fine scale modeling with ANNarchy spiking networks\n",
    "#including cortex node:\n",
    "spiking_nodes_ids = [0, 1, 2, 3, 4, 5]  # the indices of fine scale regions modeled with ANNarchy\n",
    "\n",
    "# Build a ANNarchy network model with the corresponding builder\n",
    "ann_model_builder = BasalGangliaIzhikevichBuilder(simulator, spiking_nodes_ids, config=config)\n",
    "\n",
    "\n",
    "# or...\n",
    "\n",
    "# # ----------------------------------------------------------------------------------------------------------------\n",
    "# # ----Uncomment below to modify the builder by changing the default options:--------------------------------------\n",
    "# # ----------------------------------------------------------------------------------------------------------------\n",
    "from copy import deepcopy\n",
    "\n",
    "population_neuron_model = Izhikevich_Hamker\n",
    "\n",
    "ann_model_builder.population_order = 200 # reduce for speed\n",
    "\n",
    "# When any of the properties model, params and scale below depends on regions,\n",
    "# set a handle to a function with\n",
    "# arguments (region_index=None) returning the corresponding property\n",
    "\n",
    "ann_model_builder.params_common = \\\n",
    "    {\"v\": -70.0, \"u\": -18.55, \"E_ampa\": 0.0, \"E_gaba\": -90.0, \"v_th\": 30.0, \"Vr\": 0.0, \"c\": -65.0,\n",
    "     \"C\": 1.0, \"I\": 0.0,\n",
    "     \"tau_syn\": 1.0, \"tau_ampa\": 10.0, \"tau_gaba\": 10.0,\n",
    "     \"n0\": 140.0, \"n1\": 5.0, \"n2\": 0.04, \n",
    "     \"v\": -72.0, \"u\": -14.0, \n",
    "     \"noise\": 0.0}\n",
    "\n",
    "ann_model_builder._paramsI = deepcopy(ann_model_builder.params_common)\n",
    "ann_model_builder._paramsI.update({\"a\": 0.005, \"b\": 0.585, \"d\": 4.0, \n",
    "                                   \"v\": -70.0, \"u\": -18.55})\n",
    "ann_model_builder._paramsE = deepcopy(ann_model_builder.params_common)\n",
    "ann_model_builder._paramsE.update({\"v\": -70.0, \"u\": -18.55})\n",
    "\n",
    "ann_model_builder.paramsStr = deepcopy(ann_model_builder.params_common)\n",
    "ann_model_builder.paramsStr.update({\"v_th\": 40.0, \"C\": 50.0, \"Vr\": -80.0,\n",
    "                                    \"n0\": 61.65119, \"n1\": 2.594639, \"n2\": 0.022799, \n",
    "                                    \"a\": 0.05, \"b\": -20.0, \"c\": -55.0, \"d\": 377.0, \n",
    "                                    \"v\": -70.0, \"u\": -18.55})\n",
    "\n",
    "ann_model_builder.Igpe_nodes_ids = [0]\n",
    "ann_model_builder.Igpi_nodes_ids = [1]\n",
    "ann_model_builder.Estn_nodes_ids = [2]\n",
    "ann_model_builder.Eth_nodes_ids = [4]\n",
    "ann_model_builder.Istr_nodes_ids = [3]\n",
    "#including cortex node:\n",
    "ann_model_builder.Crtx_nodes_ids = [5]\n",
    "\n",
    "I_nodes_ids = ann_model_builder.Igpe_nodes_ids + ann_model_builder.Igpi_nodes_ids\n",
    "E_nodes_ids = ann_model_builder.Estn_nodes_ids + ann_model_builder.Eth_nodes_ids\n",
    "\n",
    "\n",
    "\n",
    "def paramsE_fun(node_id, cortex_noise=noise):\n",
    "    paramsE = deepcopy(ann_model_builder._paramsE)\n",
    "    if node_id in ann_model_builder.Estn_nodes_ids:\n",
    "        paramsE.update({\"a\": 0.005, \"b\": 0.265, \"d\": 2.0, \"I\": 3.0})  # dictionary of params for Estn\n",
    "    elif node_id in ann_model_builder.Eth_nodes_ids:\n",
    "        paramsE.update({\"a\": 0.02, \"b\": 0.25, \"d\": 0.05, \"I\": 3.5}) # dictionary of params for Eth\n",
    "    elif node_id in ann_model_builder.Crtx_nodes_ids:\n",
    "        paramsE.update({\"v\": -72.0, \"u\": -14.0, \n",
    "                        \"a\": 0.02, \"b\": 0.2, \"d\": 6.0,\"c\": -72.0, \n",
    "                        \"I\": 7.0, }) # 50.0 dictionary of params for CortexExcitatory\n",
    "        if cortex_noise > 0.0:\n",
    "            paramsE.update({\"noise\": cortex_noise})  # *paramsE[\"I\"]\n",
    "    return paramsE\n",
    "    \n",
    "def paramsI_fun(node_id):\n",
    "    # For the moment they are identical, unless you differentiate the noise parameters\n",
    "    paramsI = deepcopy(ann_model_builder._paramsI)\n",
    "    if node_id in ann_model_builder.Igpe_nodes_ids:\n",
    "        paramsI.update({\"I\": 12.0})\n",
    "    elif node_id in ann_model_builder.Igpi_nodes_ids:\n",
    "        paramsI.update({\"I\": 30.0})\n",
    "    elif node_id in ann_model_builder.Crtx_nodes_ids:\n",
    "        paramsI.update({\"v\": -72.0, \"u\": -14.0, \n",
    "                        \"c\": -72.0,\"a\": 0.02, \"b\": 0.2, \"d\": 6.0, \n",
    "                        \"I_e\": 0.0})\n",
    "    return paramsI\n",
    "\n",
    "\n",
    "\n",
    "ann_model_builder.populations = []\n",
    "if ANNARCHY_CORTEX_MODE == \"Izhikevich\":\n",
    "    E_nodes_ids += ann_model_builder.Crtx_nodes_ids\n",
    "    I_nodes_ids += ann_model_builder.Crtx_nodes_ids\n",
    "    Ectx = \"E\"\n",
    "    ann_model_builder.populations += [\n",
    "        {\"label\": \"E\", \"model\": population_neuron_model,  \n",
    "          \"params\":  paramsE_fun, \n",
    "          \"nodes\": E_nodes_ids,  # Estn in [2], Eth in [4], Cortex in [5]\n",
    "          \"scale\": lambda node_id: 3.0 if node_id in ann_model_builder.Crtx_nodes_ids else 1.0},\n",
    "        {\"label\": \"I\", \"model\": population_neuron_model,  \n",
    "          \"params\": paramsI_fun, \n",
    "          \"nodes\": I_nodes_ids,  # Igpe in [0], Igpi in [1], Cortex in [5]\n",
    "          \"scale\": lambda node_id: 0.75 if node_id in ann_model_builder.Crtx_nodes_ids else 1.0}\n",
    "    ]\n",
    "     \n",
    "else:\n",
    "    Ectx = \"Ectx\"\n",
    "\n",
    "    if \"corr\" in ANNARCHY_CORTEX_MODE.lower():\n",
    "        crtx_model = HomogeneousCorrelatedSpikeTrains\n",
    "        # For Homogeneous Correlated Poisson SpikeTrains Cortex:\n",
    "        # Populations' configurations\n",
    "        # When any of the properties model, params and scale below depends on regions,\n",
    "        # set a handle to a function with\n",
    "        # arguments (region_index=None) returning the corresponding property\n",
    "        #  \"corr\"     \"tau\"     cortex eff rate: 0.9pCtxCtx, \n",
    "        #   0.99       1.7       35\n",
    "        #   0.9        1.5       31\n",
    "        #   0.5        0.9       29\n",
    "        #   0.3        0.5       20+ for Thal: 17\n",
    "        #   0.25       0.4       21 for Thal: 16\n",
    "        crtx_params = {\"rates\": 15.0, \"corr\": 0.3, \"tau\": 10.0}\n",
    "    else:\n",
    "        crtx_model = PoissonPopulation\n",
    "        crtx_params = {\"rates\": 15.0}\n",
    "        \n",
    "    ann_model_builder.populations += [\n",
    "        {\"label\": Ectx, \"model\": crtx_model, \n",
    "         \"params\": crtx_params, \n",
    "         \"nodes\": ann_model_builder.Crtx_nodes_ids,\n",
    "         \"scale\": 3.0},  # Cortex in [5]\n",
    "        {\"label\": \"E\", \"model\": population_neuron_model,  \n",
    "         \"params\":  paramsE_fun, \n",
    "         \"nodes\": E_nodes_ids,  # Estn in [2], Eth in [4]\n",
    "         \"scale\": 1.0},\n",
    "        {\"label\": \"I\", \"model\": population_neuron_model,  \n",
    "         \"params\": paramsI_fun, \n",
    "         \"nodes\": I_nodes_ids,  # Igpe in [0], Igpi in [1]\n",
    "         \"scale\": 1.0}\n",
    "    ]\n",
    "\n",
    "        \n",
    "ann_model_builder.populations += [\n",
    "    {\"label\": \"IdSN\", \"model\": population_neuron_model,   \n",
    "     \"params\": ann_model_builder.paramsStr, \n",
    "     \"nodes\": ann_model_builder.Istr_nodes_ids,  # IdSN in [3]\n",
    "     \"scale\": 1.0},\n",
    "    {\"label\": \"IiSN\", \"model\": population_neuron_model,   # IiSN in [3]\n",
    "     \"params\": ann_model_builder.paramsStr, \n",
    "     \"nodes\": ann_model_builder.Istr_nodes_ids,  # None means \"all\"\n",
    "     \"scale\": 1.0}\n",
    "]\n",
    "\n",
    "# Within region-node connections\n",
    "# When any of the properties model, conn_spec, weight, delay, receptor_type below\n",
    "# set a handle to a function with\n",
    "# arguments (region_index=None) returning the corresponding property\n",
    "\n",
    "synapse_model = \"DefaultSpikingSynapse\"\n",
    "conn_spec = {'rule': \"all_to_all\", \n",
    "             \"allow_self_connections\": True, \"force_multiple_weights\": False}\n",
    "conn_spec_fixed_probability = conn_spec.copy()\n",
    "conn_spec_fixed_probability.update({'rule': \"fixed_probability\", \"probability\": 0.1})\n",
    "\n",
    "def conn_spec_fixed_prob(prob=None):\n",
    "    output = conn_spec_fixed_probability.copy()\n",
    "    if prob is not None:\n",
    "        output[\"probability\"] = prob\n",
    "    return output\n",
    "\n",
    "within_node_delay = 1.0\n",
    "        \n",
    "\n",
    "# for each connection, we have a different probability\n",
    "ann_model_builder.populations_connections = []\n",
    "if ANNARCHY_CORTEX_MODE == \"Izhikevich\":\n",
    "    ann_model_builder.populations_connections += [\n",
    "        {\"source\": \"I\", \"target\": \"I\",  # I -> I This is a self-connection for population \"CxI\"\n",
    "         \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pCtxItoI),  # conn_spec\n",
    "         \"weight\": np.abs(wCtxItoI), \"delay\": within_node_delay,\n",
    "         \"receptor_type\": \"gaba\", \"nodes\": ann_model_builder.Crtx_nodes_ids},  # None means apply to all\n",
    "        {\"source\": \"E\", \"target\": \"I\",          # \"CxE\" -> \"CxI\" #\n",
    "         \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pCtxEtoI),  # conn_spec\n",
    "         \"weight\": np.abs(wCtxEtoI), \"delay\": within_node_delay,  \n",
    "         \"receptor_type\": \"ampa\", \"nodes\": ann_model_builder.Crtx_nodes_ids},  # None means apply to all\n",
    "        {\"source\": \"I\", \"target\": \"E\",          # \"CxI\" -> \"CxE\" \n",
    "         \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pCtxItoE),  # conn_spec\n",
    "         \"weight\": np.abs(wCtxItoE), \"delay\": within_node_delay,  \n",
    "         \"receptor_type\": \"gaba\", \"nodes\": ann_model_builder.Crtx_nodes_ids}  # None means apply to all   \n",
    "    ]\n",
    "    \n",
    "ann_model_builder.populations_connections += [\n",
    "     #        source   ->   target\n",
    "    {\"source\": \"I\", \"target\": \"I\",  # I -> I This is a self-connection for population \"Igpe\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pGPeGPe),  # conn_spec\n",
    "     \"weight\": np.abs(wGPeGPe), \"delay\": within_node_delay,\n",
    "     \"receptor_type\": \"gaba\", \"nodes\": ann_model_builder.Igpe_nodes_ids},  # None means apply to all\n",
    "    {\"source\": \"I\", \"target\": \"I\",  # I -> I This is a self-connection for population \"Igpi\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pGPiGPi),  # conn_spec\n",
    "     \"weight\": np.abs(wGPiGPi), \"delay\": within_node_delay,\n",
    "     \"receptor_type\": \"gaba\", \"nodes\": ann_model_builder.Igpi_nodes_ids},  # None means apply to all\n",
    "    {\"source\": \"IdSN\", \"target\": \"IdSN\",  # IdSN -> IdSN This is a self-connection for population \"IdSN\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pdSNdSN),  # conn_spec\n",
    "     \"weight\": np.abs(wdSNdSN), \"delay\": within_node_delay,\n",
    "     \"receptor_type\": \"gaba\", \"nodes\": ann_model_builder.Istr_nodes_ids},\n",
    "    {\"source\": \"IiSN\", \"target\": \"IiSN\",  # IiSN -> IiSN This is a self-connection for population \"IiSN\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(piSNiSN),  # conn_spec\n",
    "     \"weight\": np.abs(wiSNiSN), \"delay\": within_node_delay,\n",
    "     \"receptor_type\": \"gaba\", \"nodes\": ann_model_builder.Istr_nodes_ids},\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "# Among/Between region-node connections\n",
    "# Given that only the AMPA population of one region-node couples to\n",
    "# all populations of another region-node,\n",
    "# we need only one connection type\n",
    "        \n",
    "# When any of the properties model, conn_spec, weight, delay, receptor_type below\n",
    "# depends on regions, set a handle to a function with\n",
    "# arguments (source_region_index=None, target_region_index=None)\n",
    "\n",
    "from tvb_multiscale.core.spiking_models.builders.templates import scale_tvb_weight, tvb_delay\n",
    "\n",
    "# We set global coupling scaling to 1.0,\n",
    "# because we need the Maith et al optimized weights without any scaling:\n",
    "ann_model_builder.global_coupling_scaling = 1.0 \n",
    "        \n",
    "# Function that will return the TVB weight with optional scaling:\n",
    "class TVBWeightFun(object):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 global_coupling_scaling=ann_model_builder.global_coupling_scaling, \n",
    "                 tvb_weights = ann_model_builder.tvb_weights):\n",
    "        self.global_coupling_scaling = float(global_coupling_scaling)\n",
    "        self.tvb_weights = tvb_weights.copy()\n",
    "    \n",
    "    def __call__(self, source_node, target_node):\n",
    "        return scale_tvb_weight(source_node, target_node, self.tvb_weights,\n",
    "                                scale=self.global_coupling_scaling)\n",
    "\n",
    "# Function that will return the TVB delay unless SPIKING_NODES_DELAYS == False:\n",
    "tvb_delay_fun = \\\n",
    "    lambda source_node, target_node: \\\n",
    "        np.maximum(ann_model_builder.tvb_dt, \n",
    "                   tvb_delay(source_node, target_node, ann_model_builder.tvb_delays)) \\\n",
    "            if SPIKING_NODES_DELAYS else within_node_delay\n",
    "\n",
    "\n",
    "# Total excitatory spikes of one region node will be distributed to\n",
    "ann_model_builder.nodes_connections = [\n",
    "    #        source    ->     target\n",
    "    {\"source\": \"IdSN\", \"target\": \"I\",             # \"IdSN\" -> \"Igpi\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pdSNGPi),  # conn_spec\n",
    "     \"weight\": TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"gaba\", \n",
    "     \"source_nodes\": ann_model_builder.Istr_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Igpi_nodes_ids},  # None means apply to all\n",
    "    {\"source\": \"IiSN\", \"target\": \"I\",            # \"IiSN\" -> \"Igpe\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(piSNGPe),  # conn_spec\n",
    "     \"weight\": TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"gaba\", \n",
    "     \"source_nodes\": ann_model_builder.Istr_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Igpe_nodes_ids},  # None means apply to all\n",
    "    {\"source\": \"I\", \"target\": \"I\",             # \"Igpe\" -> \"Igpi\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pGPeGPi),  # conn_spec\n",
    "     \"weight\": TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"gaba\", \n",
    "     \"source_nodes\": ann_model_builder.Igpe_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Igpi_nodes_ids},  # None means apply to all\n",
    "    {\"source\": \"I\", \"target\": \"E\",              # \"Igpi\" -> \"Eth\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pGPiTh),  # conn_spec\n",
    "     \"weight\": TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"gaba\", \n",
    "     \"source_nodes\": ann_model_builder.Igpi_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Eth_nodes_ids},  # None means apply to all\n",
    "    {\"source\": \"I\", \"target\": \"E\",             # \"Igpe\" -> \"Estn\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pGPeSTN),  # conn_spec\n",
    "     \"weight\": TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"gaba\", \n",
    "     \"source_nodes\": ann_model_builder.Igpe_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Estn_nodes_ids},  # None means apply to all\n",
    "    {\"source\": \"E\", \"target\": \"IdSN\",   # \"Eth\" -> [\"IdSN\"] \n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pThdSN),  # conn_spec\n",
    "     \"weight\": wThdSN, # TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"ampa\", \n",
    "     \"source_nodes\": ann_model_builder.Eth_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Istr_nodes_ids},  # None means apply to all\n",
    "    {\"source\": \"E\", \"target\": \"IiSN\",   # \"Eth\" -> [\"IiSN\"] \n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pThiSN),  # conn_spec\n",
    "     \"weight\": wThiSN,\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"ampa\", \n",
    "     \"source_nodes\": ann_model_builder.Eth_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Istr_nodes_ids},  # No\n",
    "    {\"source\": \"E\", \"target\": \"I\",          # \"Estn\" -> [\"Igpe\"]\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pSTNGPe),  # conn_spec\n",
    "     \"weight\": TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"ampa\", \n",
    "     \"source_nodes\": ann_model_builder.Estn_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Igpe_nodes_ids},\n",
    "    {\"source\": \"E\", \"target\": \"I\",          # \"Estn\" -> [\"Igpi\"]\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pSTNGPi),  # conn_spec\n",
    "     \"weight\": TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"ampa\", \n",
    "     \"source_nodes\": ann_model_builder.Estn_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Igpi_nodes_ids},\n",
    "    {\"source\": Ectx, \"target\": \"E\",          # \"Ectx\" -> \"Eth\"\n",
    "     \"model\": synapse_model, \"conn_spec\": conn_spec, # No probability here?!\n",
    "     \"weight\": TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"ampa\", \n",
    "     \"source_nodes\": ann_model_builder.Crtx_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Eth_nodes_ids},  # None means apply to all\n",
    "    {\"source\": Ectx, \"target\": \"E\",          # \"Ectx\" -> \"Estn\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pCtxSTN),  # conn_spec\n",
    "     \"weight\": TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"ampa\", \n",
    "     \"source_nodes\": ann_model_builder.Crtx_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Estn_nodes_ids},  # None means apply to all\n",
    "    {\"source\": Ectx, \"target\": \"IdSN\",          # \"Ectx\" -> \"IdSN\" \n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pCtxdSN),  # conn_spec\n",
    "     \"weight\": wCtxdSN, # TVBWeightFun(),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"ampa\", \n",
    "     \"source_nodes\": ann_model_builder.Crtx_nodes_ids, \n",
    "     \"target_nodes\": ann_model_builder.Istr_nodes_ids},  # None means apply to all\n",
    "    {\"source\": Ectx, \"target\": \"IiSN\",          # \"Ectx\" -> \"IiSN\" \n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pCtxiSN),  # conn_spec\n",
    "     \"weight\": wCtxiSN, # TVBWeightFun(ann_model_builder.tvb_weights, \n",
    "                            # wCrtxdSNtoCrtxiSN * ann_model_builder.global_coupling_scaling),\n",
    "     \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),  \n",
    "     \"receptor_type\": \"ampa\", \n",
    "     \"source_nodes\": ann_model_builder.Crtx_nodes_ids,\n",
    "     \"target_nodes\": ann_model_builder.Istr_nodes_ids}  # None means apply to all\n",
    "     ]\n",
    "\n",
    "\n",
    "# Creating  devices to be able to observe ANNarchy activity:\n",
    "\n",
    "ann_model_builder.output_devices = []\n",
    "\n",
    "period = 1.0\n",
    "\n",
    "# Creating  devices to be able to observe ANNarchy activity:\n",
    "params = deepcopy(ann_model_builder.config.ANNARCHY_OUTPUT_DEVICES_PARAMS_DEF[\"SpikeMonitor\"])\n",
    "for pop in ann_model_builder.populations:\n",
    "    connections = OrderedDict({})\n",
    "    #                      label <- target population\n",
    "    connections[pop[\"label\"]] = pop[\"label\"]\n",
    "    ann_model_builder.output_devices.append(\n",
    "        {\"model\": \"SpikeMonitor\", \"params\": deepcopy(params),\n",
    "         \"connections\": connections, \"nodes\": pop[\"nodes\"]})  # None means apply to \"all\"\n",
    "\n",
    "# Labels have to be different for every connection to every distinct population\n",
    "# params for baladron implementation commented out for the moment\n",
    "# TODO: use baladron neurons\n",
    "params = deepcopy(ann_model_builder.config.ANNARCHY_OUTPUT_DEVICES_PARAMS_DEF[\"Monitor\"])\n",
    "params.update({\"period\": period,  \n",
    "               'variables': [\"v\", \"u\", \"I_syn\", \"I_syn_ex\", \"I_syn_in\", \"g_ampa\", \"g_gaba\", \"g_base\"]})\n",
    "for pop in ann_model_builder.populations:\n",
    "    if pop['label'] != \"Ectx\":\n",
    "        connections = OrderedDict({})\n",
    "        #               label    <- target population\n",
    "        connections[pop[\"label\"] + \"_ts\"] = pop[\"label\"]\n",
    "        ann_model_builder.output_devices.append(\n",
    "            {\"model\": \"Monitor\", \"params\": deepcopy(params),\n",
    "             \"connections\": connections, \"nodes\": pop[\"nodes\"]})  # None means apply to all\n",
    "    \n",
    "    \n",
    "# # Create a spike stimulus input device\n",
    "ann_model_builder.input_devices = []  #\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "ann_model_builder.configure()\n",
    "\n",
    "ann_network = ann_model_builder.build(set_defaults=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The stimuli models:\n",
    "\n",
    "if simulation_mode != \"rs\":\n",
    "    annarchy_instance = ann_network.annarchy_instance\n",
    "\n",
    "    # amplitude in mV or V? Was V in Michmizos paper, but had value 5.\n",
    "    # frequency in Hz and later divided by 1000 because time scale is ms\n",
    "    # duration in ms!\n",
    "    #dt inside annarchy needs to be <=0.01 to realize a 60Âµs pulse width, but setting it to that leads to errors. \n",
    "    # realistic \"duration\" parameter for DBSInput would be 0.06\n",
    "\n",
    "    if stim_mode.find(\"mono\") > -1:\n",
    "        DBSInput = annarchy_instance.Neuron(\n",
    "            parameters=\"\"\"\n",
    "                amplitude = 5.0\n",
    "                kappa = 8\n",
    "                frequency = 130\n",
    "                duration = 0.1\n",
    "            \"\"\",\n",
    "            equations=\"\"\"\n",
    "                h1 = if sin(2*pi*(frequency/1000)*t) > 0 : 1 else : 0\n",
    "                h2 = if sin(2*pi*(frequency/1000)*(t+duration)) > 0 : 1 else : 0\n",
    "                r = amplitude*kappa*h1*(1-h2)\n",
    "            \"\"\"\n",
    "        )\n",
    "    elif stim_mode.find(\"bi\") > -1:\n",
    "        DBSInput = annarchy_instance.Neuron(\n",
    "            parameters=\"\"\"\n",
    "                amplitude = 5.0\n",
    "                ampfactor = 10\n",
    "                kappa = 8\n",
    "                frequency = 130\n",
    "                duration = 0.3\n",
    "            \"\"\",\n",
    "            equations=\"\"\"\n",
    "                h1 = if sin(2*pi*(frequency/1000)*t) > 0 : 1 else : 0\n",
    "                h2 = if sin(2*pi*(frequency/1000)*(t-duration)) > 0 : 1 else : 0\n",
    "                h4 = if sin(2*pi*(frequency/1000)*(t-((ampfactor+1)*duration))) > 0 : 1 else : 0\n",
    "                i1 = amplitude*(1+ 1/ampfactor)*kappa*h1*(1-h2)\n",
    "                i2 = (-amplitude/ampfactor) *kappa *h1*(1-h4)\n",
    "                r = i1 + i2\n",
    "            \"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the stimuli:\n",
    "\n",
    "if simulation_mode != \"rs\":\n",
    "    \n",
    "    if stim_target.find(\"STN\") > -1:\n",
    "        stim_target = \"STN_Left\" \n",
    "    else:\n",
    "        stim_target = \"GPi_Left\" \n",
    "        \n",
    "    if stim_mode != \"simple\":\n",
    "        # now add DBS population invisible to TVB for now\n",
    "        target_pop = ann_network.brain_regions[stim_target][0].population\n",
    "        dbs_pop = annarchy_instance.Population(target_pop.size, DBSInput)\n",
    "        dbs_proj = annarchy_instance.CurrentInjection(dbs_pop, target_pop, 'dbs')\n",
    "        dbs_proj.connect_current()\n",
    "        # switch the stimulation off for the first time segment\n",
    "        dbs_pop.amplitude = 0\n",
    "        dbs_pop.frequency = stim_freq\n",
    "        dbs_pop.duration = stim_duration\n",
    "    #     # if a pulse duration that is not zero is given, set it\n",
    "    #     if pulse_width is not None:\n",
    "    #         dbs_pop.duration = pulse_width\n",
    "\n",
    "        # just to check, add some annarchy monitors -> delete later    \n",
    "        m1 = annarchy_instance.Monitor(dbs_pop, \"r\")\n",
    "        m2 = annarchy_instance.Monitor(target_pop, [\"g_dbs\", \"spike\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure simulator, simulate, gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:18.879872Z",
     "start_time": "2019-07-12T20:36:11.148945Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "ann_network.configure()  # ann_network.annarchy_instance.compile()\n",
    "print(\"\\nCompiled in %g secs!\" % (time.time() - t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ann_network.print_summary_info_details(recursive=2, connectivity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # -----------------------------------5. Simulate and gather results-------------------------------------------------\n",
    "# simulation_length = 1500.0\n",
    "# transient = 500.0 # simulation_length/11\n",
    "# ...and simulate!\n",
    "t_start = time.time()\n",
    "\n",
    "if simulation_mode == \"rs\":\n",
    "    simulation_length1 = simulation_length\n",
    "else:\n",
    "    simulation_length1 = start_stimulus\n",
    "\n",
    "ann_network.Run(simulation_length1)  # ann_network.annarchy_instance.simulate(simulation_length1, measure_time=measure_time)\n",
    "\n",
    "if simulation_mode != \"rs\":\n",
    "    \n",
    "    if simulation_mode.find(\"simpl\") > -1:\n",
    "         # for stimulus application:\n",
    "        if stim_target.find(\"STN\") > -1:\n",
    "            pop = \"E\" \n",
    "        else:\n",
    "            pop = \"I\" \n",
    "        ann_network.brain_regions[stim_target][pop].Set(\n",
    "            {\"I\": stim_ampl + ann_network.brain_regions[stim_target][pop].Get(\"I\")[\"I\"]})\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # for stimulus application:\n",
    "        dbs_pop.amplitude = stim_ampl\n",
    "        \n",
    "    ann_network.Run(simulation_length=(simulation_length-simulation_length1)) \n",
    "    \n",
    "print(\"\\nSimulated in %f secs!\" % (time.time() - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot results and write them to HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False for faster plotting of only mean field variables and dates, apart from spikes\" rasters:\n",
    "plot_per_neuron = False  \n",
    "MAX_VARS_IN_COLS = 3\n",
    "MAX_REGIONS_IN_ROWS = 10\n",
    "MIN_REGIONS_FOR_RASTER_PLOT = 9\n",
    "# from examples.plot_write_results import plot_write_results\n",
    "# populations = []\n",
    "# populations_sizes = []\n",
    "# for pop in ann_model_builder.populations:\n",
    "#     populations.append(pop[\"label\"])\n",
    "#     populations_sizes.append(int(np.round(pop[\"scale\"] * ann_model_builder.population_order)))\n",
    "# plot_write_results(results, simulator, populations=populations, populations_sizes=populations_sizes, \n",
    "#                    transient=transient, tvb_state_variable_type_label=\"State Variables\", \n",
    "#                    tvb_state_variables_labels=simulator.model.variables_of_interest, \n",
    "#                    plot_per_neuron=plot_per_neuron, plotter=plotter, config=config)\n",
    "\n",
    "# If you want to see what the function above does, take the steps, one by one\n",
    "try:\n",
    "    # We need framework_tvb for writing and reading from HDF5 files\n",
    "    from tvb_multiscale.core.io.h5_writer import H5Writer\n",
    "    from examples.plot_write_results import write_RegionTimeSeriesXarray_to_h5\n",
    "    writer = H5Writer()\n",
    "except:\n",
    "    writer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiking Network plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb_multiscale.core.data_analysis.spiking_network_analyser import SpikingNetworkAnalyser\n",
    "# Create a SpikingNetworkAnalyzer:\n",
    "spikeNet_analyzer = \\\n",
    "    SpikingNetworkAnalyser(spikeNet=ann_network,\n",
    "                           start_time=period, end_time=simulation_length, \n",
    "                           period=period, transient=transient,\n",
    "                           time_series_output_type=\"TVB\", return_data=True,\n",
    "                           # elephant_mean_firing_rate=False,\n",
    "                           force_homogeneous_results=True, connectivity=simulator.connectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spikes' raster and mean spike rates and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spikes rates and correlations per Population and Region\n",
    "spikes_res = \\\n",
    "    spikeNet_analyzer.\\\n",
    "        compute_spikeNet_spikes_rates_and_correlations(\n",
    "            populations_devices=None, regions=None,\n",
    "            rates_methods=[], rates_kwargs=[{}],rate_results_names=[],\n",
    "            corrs_methods=[], corrs_kwargs=[{}], corrs_results_names=[], bin_kwargs={},\n",
    "            data_method=spikeNet_analyzer.get_spikes_from_device, data_kwargs={},\n",
    "            return_devices=False\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(spikes_res[\"mean_rate\"])\n",
    "    print(spikes_res[\"spikes_correlation_coefficient\"])\n",
    "    # Plot spikes' rasters together with mean population's spikes' rates' time series\n",
    "    if plotter:\n",
    "        plotter.config.FONTSIZE = 14 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "        plotter.plot_spike_events(spikes_res[\"spikes\"], time_series=spikes_res[\"mean_rate_time_series\"], \n",
    "                                  mean_results=spikes_res[\"mean_rate\"], #\n",
    "                                  stimulus=[start_stimulus] if simulation_mode != \"rs\" else None,\n",
    "                                  mean_results_units=\"Hz\", stimulus_linewidth=5.0,\n",
    "                                  spikes_markersize=1.0, figsize=(20, 40), \n",
    "                                  n_time_ticks=3, show_time_axis=True, \n",
    "                                  time_axis_min=0.0, time_axis_max=simulation_length\n",
    "                                 ) # \n",
    "        from tvb_multiscale.core.plot.correlations_plot import plot_correlations\n",
    "        plot_correlations(spikes_res[\"spikes_correlation_coefficient\"], plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean spike rates:\")\n",
    "for pop in spikes_res[\"mean_rate\"].coords[\"Population\"]:\n",
    "    for reg in spikes_res[\"mean_rate\"].coords[\"Region\"]:\n",
    "        if not np.isnan(spikes_res[\"mean_rate\"].loc[pop, reg]):\n",
    "            print(\"%s - %s: %0.1f\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                   spikes_res[\"mean_rate\"].loc[pop, reg].values.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeNet_analyzer.resample = True\n",
    "spikes_sync = \\\n",
    "    spikeNet_analyzer.compute_spikeNet_synchronization(populations_devices=None, regions=None,\n",
    "                                                       comp_methods=[spikeNet_analyzer.compute_spikes_sync, \n",
    "                                                                     spikeNet_analyzer.compute_spikes_sync_time_series],\n",
    "                                                       computations_kwargs=[{}], data_kwargs={},\n",
    "                                                       return_spikes_trains=False, return_devices=False)\n",
    "# print(spikes_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                          time_series=spikes_sync[\"spikes_sync_time_series\"], mean_results=spikes_sync[\"spikes_sync\"], \n",
    "                          stimulus=[start_stimulus] if simulation_mode != \"rs\" else None,\n",
    "                          plot_spikes=True, spikes_alpha=0.25,\n",
    "                          spikes_markersize=1.0, stimulus_linewidth=5.0, time_series_marker=\"*\", \n",
    "                          figsize=(20, 40), n_y_ticks=3, n_time_ticks=4, show_time_axis=True,\n",
    "                          time_axis_min=0.0, time_axis_max=simulation_length\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Spike synchronization:\")\n",
    "for pop in spikes_sync[\"spikes_sync\"].coords[\"Population\"]:\n",
    "    for reg in spikes_sync[\"spikes_sync\"].coords[\"Region\"]:\n",
    "        if not np.isnan(spikes_sync[\"spikes_sync\"].loc[pop, reg]):\n",
    "            print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                   spikes_sync[\"spikes_sync\"].loc[pop, reg].values.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_res and writer:\n",
    "    writer.write_object(spikes_res[\"spikes\"].to_dict(), \n",
    "                        path=os.path.join(config.out.FOLDER_RES,  \"Spikes\") + \".h5\");\n",
    "    writer.write_object(spikes_res[\"mean_rate\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"mean_rate\"].name) + \".h5\");\n",
    "    write_RegionTimeSeriesXarray_to_h5(spikes_res[\"mean_rate_time_series\"], writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES, \n",
    "                                                    spikes_res[\"mean_rate_time_series\"].title) + \".h5\",\n",
    "                                       recursive=False);\n",
    "    writer.write_object(spikes_res[\"spikes_correlation_coefficient\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"spikes_correlation_coefficient\"].name) + \".h5\");\n",
    "    \n",
    "    if spikes_sync is not None:\n",
    "        writer.write_object(spikes_sync[\"spikes_sync\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_sync[\"spikes_sync\"].name) + \".h5\");\n",
    "        write_RegionTimeSeriesXarray_to_h5(spikes_sync[\"spikes_sync_time_series\"], writer,\n",
    "                                           os.path.join(config.out.FOLDER_RES,\n",
    "                                                        spikes_sync[\"spikes_sync_time_series\"].title) + \".h5\",\n",
    "                                           recursive=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  SpikingNetwork mean field variable time series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Continuous time variables' data of spiking neurons\n",
    "\n",
    "if plot_per_neuron:\n",
    "    spikeNet_analyzer.return_data = True\n",
    "else:\n",
    "    spikeNet_analyzer.return_data = False\n",
    "spikeNet_ts = \\\n",
    "    spikeNet_analyzer. \\\n",
    "         compute_spikeNet_mean_field_time_series(populations_devices=None, regions=None, variables=None,\n",
    "                                                 computations_kwargs={}, data_kwargs={}, return_devices=False)\n",
    "if spikeNet_ts:\n",
    "    if plot_per_neuron:\n",
    "        mean_field_ts = spikeNet_ts[\"mean_field_time_series\"]  # mean field\n",
    "        spikeNet_ts = spikeNet_ts[\"data_by_neuron\"]  # per neuron data\n",
    "    else:\n",
    "        mean_field_ts = spikeNet_ts\n",
    "    if mean_field_ts and mean_field_ts.size > 0:\n",
    "        mean_field_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                                      per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS)\n",
    "        if mean_field_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "            mean_field_ts.plot_raster(plotter_config=plotter.config, \n",
    "                                      per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "                                      linestyle=\"--\", alpha=0.5, linewidth=0.5)\n",
    "else:\n",
    "    mean_field_ts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to file:\n",
    "if mean_field_ts and writer:\n",
    "    write_RegionTimeSeriesXarray_to_h5(mean_field_ts, writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES, mean_field_ts.title) + \".h5\", \n",
    "                                       recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute per neuron spikes' rates times series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_res and plot_per_neuron:\n",
    "    from tvb.simulator.plot.base_plotter import pyplot\n",
    "    spikeNet_analyzer.return_data = False\n",
    "    rates_ts_per_neuron = \\\n",
    "        spikeNet_analyzer. \\\n",
    "            compute_spikeNet_rates_time_series(populations_devices=None, regions=None,\n",
    "                                               computations_kwargs={}, data_kwargs={},\n",
    "                                               return_spikes_trains=False, return_devices=False);\n",
    "    if rates_ts_per_neuron is not None and rates_ts_per_neuron.size:\n",
    "        # Regions in rows\n",
    "        row = rates_ts_per_neuron.dims[2] if rates_ts_per_neuron.shape[2] > 1 else None\n",
    "        if row is None:\n",
    "            # Populations in rows\n",
    "            row = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "            col = None\n",
    "        else:\n",
    "            # Populations in columns\n",
    "            col = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "        pyplot.figure()\n",
    "        rates_ts_per_neuron.plot(y=rates_ts_per_neuron.dims[3], row=row, col=col, cmap=\"jet\")\n",
    "        plotter.base._save_figure(figure_name=\"Spike rates per neuron\")\n",
    "        # del rates_ts_per_neuron # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot per neuron SpikingNetwork time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regions in rows\n",
    "if plot_per_neuron and spikeNet_ts.size:\n",
    "    row = spikeNet_ts.dims[2] if spikeNet_ts.shape[2] > 1 else None\n",
    "    if row is None:\n",
    "        # Populations in rows\n",
    "        row = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "        col = None\n",
    "    else:\n",
    "        # Populations in cols\n",
    "         col = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "    for var in spikeNet_ts.coords[spikeNet_ts.dims[1]]:\n",
    "        this_var_ts = spikeNet_ts.loc[:, var, :, :, :]\n",
    "        this_var_ts.name = var.item()\n",
    "        pyplot.figure()\n",
    "        this_var_ts.plot(y=spikeNet_ts.dims[4], row=row, col=col, cmap=\"jet\", figsize=FIGSIZE)\n",
    "        plotter.base._save_figure(\n",
    "            figure_name=\"Spiking Network variables' time series per neuron: %s\" % this_var_ts.name)\n",
    "    del spikeNet_ts # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# References\n",
    "\n",
    "1 Sanz Leon P, Knock SA, Woodman MM, Domide L, <br>\n",
    "  Mersmann J, McIntosh AR, Jirsa VK (2013) <br>\n",
    "  The Virtual Brain: a simulator of primate brain network dynamics. <br>\n",
    "  Frontiers in Neuroinformatics 7:10. doi: 10.3389/fninf.2013.00010 <br>\n",
    "  https://www.thevirtualbrain.org/tvb/zwei <br>\n",
    "  https://github.com/the-virtual-brain <br>\n",
    "\n",
    "2 Ritter P, Schirner M, McIntosh AR, Jirsa VK (2013).  <br>\n",
    "  The Virtual Brain integrates computational modeling  <br>\n",
    "  and multimodal neuroimaging. Brain Connectivity 3:121â145. <br>\n",
    "\n",
    "3 Vitay J, Dinkelbach HÃ and Hamker FH (2015). <br>\n",
    "  ANNarchy: a code generation approach to neural simulations on parallel hardware. <br>\n",
    "  Frontiers in Neuroinformatics 9:19. doi:10.3389/fninf.2015.00019 <br>\n",
    "  For more details see https://annarchy.readthedocs.io/en/latest/ <br>\n",
    "\n",
    "4 Baladron, J., Nambu, A., & Hamker, F. H. (2019). <br>\n",
    "  The subthalamic nucleusâexternal globus pallidus loop biases <br>\n",
    "  exploratory decisions towards known alternatives: A neuroâcomputational study. <br>\n",
    "  European Journal of Neuroscience, 49:754â767. https://doi.org/10.1111/ejn.13666 <br>\n",
    "  \n",
    "5 Maith O, Villagrasa Escudero F, Ãlo Dinkelbach H, Baladron J, <br>\n",
    "  Horn, A, Irmen F, KÃ¼hn AA, Hamker FH (2020).<br>\n",
    "  A computational modelâbased analysis of basal ganglia pathway changes <br>\n",
    "  in Parkinsonâs disease inferred from restingâstate fMRI <br>\n",
    "  European Journal of Neuroscience, 00:1â18. https://doi.org/10.1111/ejn.14868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_model_builder.populations\n",
    "names = [\"GPe\", \"GPi\", \"STN\", \"dSN\", \"iSN\", \"Thal\", \"CtxE\"]\n",
    "for iP, (name, pop) in enumerate(zip(names, ann_network.annarchy_instance.Global._network[0][\"populations\"])):\n",
    "    print(\"\\n%s - %s (size = %d): params =\\n%s\" % (pop.name, name, pop.size, pop.init) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reg in ann_network.brain_regions:\n",
    "#     for pop in reg:\n",
    "#         conns = pop.GetFromConnections(\"w\")\n",
    "#         print(\"%s-%s:\" % (reg.label, pop.label))\n",
    "#         for conn in conns:\n",
    "#             print(\"%s\" % str(conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Configured connections:\")\n",
    "\n",
    "print(\"\\nWithin node's connections:\")\n",
    "ncons = 0\n",
    "for pop in ann_model_builder.populations_connections:\n",
    "    ncons += 1\n",
    "    if hasattr(pop[\"weight\"], \"__call__\"):\n",
    "        weight = pop[\"weight\"](pop[\"nodes\"])\n",
    "    else:\n",
    "        weight = pop[\"weight\"]\n",
    "    try:\n",
    "        p = pop[\"conn_spec\"][\"probability\"]\n",
    "    except:\n",
    "        p = 1.0\n",
    "    w_conn = assert_loadedParams[np.abs(weight)]\n",
    "    conn = w_conn.split(\"_weights\")[0]\n",
    "    p_conn = loadedParams[\"%s_probs\" % conn]\n",
    "    w_conn = loadedParams[w_conn]\n",
    "    print(\"%d. %s -> %s (%s) = %g (p=%g): %s (%g, %g)\" \n",
    "          % (ncons, pop[\"source\"], pop[\"target\"], pop[\"receptor_type\"], weight, p,\n",
    "             conn, w_conn, p_conn))\n",
    "    \n",
    "print(\"\\nAmong node's connections:\")\n",
    "for pop in ann_model_builder.nodes_connections:\n",
    "    ncons += 1 \n",
    "    if hasattr(pop[\"weight\"], \"__call__\"):\n",
    "        weight = pop[\"weight\"](pop[\"source_nodes\"], pop[\"target_nodes\"])\n",
    "    else:\n",
    "        weight = pop[\"weight\"]\n",
    "    try:\n",
    "        p = pop[\"conn_spec\"][\"probability\"]\n",
    "    except:\n",
    "        p = 1.0\n",
    "    w_conn = assert_loadedParams[np.abs(weight)]\n",
    "    conn = w_conn.split(\"_weights\")[0]\n",
    "    p_conn = loadedParams[\"%s_probs\" % conn]\n",
    "    w_conn = loadedParams[w_conn]\n",
    "    print(\"%d. %s -> %s (%s) = %g (p=%g): %s (%g, %g)\" \n",
    "          % (ncons, pop[\"source\"], pop[\"target\"], pop[\"receptor_type\"], weight, p,\n",
    "             conn, w_conn, p_conn))\n",
    "    \n",
    "print(\"\\nEffective connections:\")\n",
    "conns = [\"GPeGPe\", \"GPiGPi\", \"dSNdSN\", \"iSNiSN\",\n",
    "         \"dSNGPi\" , \"iSNGPe\", \"GPeGPi\", \"GPiThal\", \"GPeSTN\", \"ThaldSN\", \"ThaliSN\", \n",
    "         \"STNGPe\", \"STNGPi\", \"CtxThal\", \"CtxSTN\", \"CtxdSN\", \"CtxiSN\"]\n",
    "for iC, (name, proj) in enumerate(zip(conns, \n",
    "                                      ann_network.annarchy_instance.Global._network[0][\"projections\"])):\n",
    "    meanNconns = np.mean([len(d.pre_ranks) for d in proj.dendrites])\n",
    "    p = meanNconns / proj.pre.size\n",
    "    print(\"%d. %s: %s w = %g (%g) (%s), effective_probability = %g (%g)\" % \n",
    "          (iC+1, proj.name, name, proj.w, loadedParams[\"%s_weights\" % name], proj.target,\n",
    "            p, loadedParams[\"%s_probs\" % name]))  # meanNconns = %g,  meanNconns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if simulation_mode == \"stim\":\n",
    "    ann= ann_model_builder.annarchy_instance\n",
    "    data = m1.get() #the dbs stimulus\n",
    "    t = np.arange(0, simulation_length, ann.dt())\n",
    "    if stim_mode.find(\"bi\") > -1:\n",
    "        stim_slice = slice(int(399.0/ann.dt()), int(407.0/ann.dt()))\n",
    "        plt.plot(t[stim_slice] - t[stim_slice][0], data['r'][:][stim_slice, 0], \"k\")\n",
    "        plt.xlabel(\"Time (ms)\")\n",
    "        plt.ylabel(\"Biphasic stimulus\")\n",
    "        plt.show()\n",
    "    elif stim_mode.find(\"mono\") > -1:\n",
    "        stim_slice = slice(int(400.0/ann.dt()), int(412.0/ann.dt()))\n",
    "        plt.plot(t[stim_slice] - t[stim_slice][0], data['r'][:][stim_slice, 0], \"k\")\n",
    "        plt.xlabel(\"Time (ms)\")\n",
    "        plt.ylabel(\"Monophasic stimulus\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "psd_target = 'STN_Left'\n",
    "lfp_result = np.array(mean_field_ts._data.loc[:,'v',psd_target,'E_ts'])\n",
    "\n",
    "n_window = 256 # This can be increased for longer simulations\n",
    "f1, Pxx_spec1 = signal.welch(lfp_result,1000,'flattop',n_window,scaling='density')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'{psd_target}, stimulus: {stim_mode}', fontsize=14)\n",
    "plt.xlabel('Frequency (Hz)', fontsize=10)\n",
    "plt.ylabel('PSD [a.u./âHz]', fontsize=10) \n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.semilogy(f1, np.sqrt(Pxx_spec1), color=\"blue\", label=f\"{stim_ampl} mA\")\n",
    "plt.axvspan(14, 30, color='grey', alpha=0.5, label = \"Î²\")\n",
    "plt.legend(loc='lower left', fontsize=10)\n",
    "plt.xlim(0,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_target = 'Thal_Left'\n",
    "lfp_result = np.array(mean_field_ts._data.loc[:,'v',psd_target,'E_ts'])\n",
    "\n",
    "n_window = 256 # This can be increased for longer simulations\n",
    "f1, Pxx_spec1 = signal.welch(lfp_result,1000,'flattop',n_window,scaling='density')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'{psd_target}, stimulus: {stim_mode}', fontsize=14)\n",
    "plt.xlabel('Frequency (Hz)', fontsize=10)\n",
    "plt.ylabel('PSD [a.u./âHz]', fontsize=10) \n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.semilogy(f1, np.sqrt(Pxx_spec1), color=\"blue\", label=f\"{stim_ampl} mA\")\n",
    "plt.axvspan(14, 30, color='grey', alpha=0.5, label = \"Î²\")\n",
    "plt.legend(loc='lower left', fontsize=10)\n",
    "plt.xlim(0,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "psd_target = 'Cortex Exc'\n",
    "mean_rate_result = spikes_res[\"mean_rate_time_series\"][:, \"E\", 'Cortex'].data.squeeze()\n",
    "\n",
    "n_window = 256 # This can be increased for longer simulations\n",
    "f1, Pxx_spec1 = signal.welch(mean_rate_result,1000,'flattop',n_window,scaling='density')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'{psd_target}, stimulus: {stim_mode}', fontsize=14)\n",
    "plt.xlabel('Frequency (Hz)', fontsize=10)\n",
    "plt.ylabel('PSD [a.u./âHz]', fontsize=10) \n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.semilogy(f1, np.sqrt(Pxx_spec1), color=\"blue\", label=f\"{stim_ampl}\")\n",
    "plt.axvspan(14, 30, color='grey', alpha=0.5, label = \"Î²\")\n",
    "plt.legend(loc='lower left', fontsize=10)\n",
    "plt.xlim(0,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
