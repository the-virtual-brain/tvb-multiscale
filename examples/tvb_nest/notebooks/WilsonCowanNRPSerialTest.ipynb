{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVB-NEST: Bridging multiscale activity by co-simulation\n",
    "\n",
    "## Step-by-step learn how to perform a co-simulation embedding spiking neural networks into large-scale brain networks using TVB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='pics/ConceptGraph1.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='pics/ConceptGraph2.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tvb-multiscale toolbox:\n",
    "\n",
    "### https://github.com/the-virtual-brain/tvb-multiscale\n",
    "\n",
    "For questions use the git issue tracker, or write an e-mail to me: dionysios.perdikis@charite.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T13:37:40.905578Z",
     "start_time": "2019-07-11T13:37:40.894958Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TVB - NEST co-simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilson - Cowan TVB mean field model\n",
    "\n",
    "For every region node $n\\prime$ modelled as a mean-field node in TVB:\n",
    "\n",
    "Population activity dynamics (1 excitatory and 1 inhibitory population):\n",
    "\n",
    " $\\dot{E}_k = \\dfrac{1}{\\tau_e} (-E_k  + (k_e - r_e E_k) \\mathcal{S}_e (\\alpha_e \\left( c_{ee} E_k - c_{ei} I_k  + P_k - \\theta_e + \\mathbf{\\Gamma}(E_k, E_j, u_{kj}) + W_{\\zeta}\\cdot E_j + W_{\\zeta}\\cdot I_j\\right) )) $\n",
    " \n",
    "$\n",
    "            \\dot{I}_k = \\dfrac{1}{\\tau_i} (-I_k  + (k_i - r_i I_k) \\mathcal{S}_i (\\alpha_i \\left( c_{ie} E_k - c_{ee} I_k  + Q_k - \\theta_i + \\mathbf{\\Gamma}(E_k, E_j, u_{kj}) + W_{\\zeta}\\cdot E_j + W_{\\zeta}\\cdot I_j\\right) ))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking network model in NEST\n",
    "\n",
    "using \"iaf_cond_alpha\" spiking neuronal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVB to NEST coupling\n",
    "TVB couples to NEST via instantaneous spike rate $ w_{TVB->NEST} * E(t) $, \n",
    "\n",
    "Inhomogeneous spike generator NEST devices are used as TVB \"proxy\" nodes and generate independent Poisson-random spike trains \n",
    "\n",
    "$ \\left[ \\sum_k \\delta(t-\\tau_{n\\prime n}-{t_j}^k) \\right]_{j \\in n\\prime} $\n",
    "\n",
    "Alternatively, the spike trains are generated outside NEST using the Elephant software and inserted to NEST via spike generator devices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEST to TVB update\n",
    "\n",
    "A NEST spike detector device is used to count spike for each time step, and convert it to an instantaneous population mean rate that overrides\n",
    "\n",
    "$ {E_{_{n}}}(t) =  \\frac{\\sum_j\\left[ \\sum_k \\delta(t-\\tau_n-{t_j}^k) \\right]_{j \\in E_n}}{N_E * dt} $ \n",
    "\n",
    "$ {I_{_{n}}}(t) =  \\frac{\\sum_j\\left[ \\sum_k \\delta(t-\\tau_n-{t_j}^k) \\right]_{j \\in I_n}}{N_I * dt} $\n",
    "\n",
    "in  spikes/sec.\n",
    "\n",
    "This update process concerns only the TVB region nodes that are simulated exclusively in NEST, as spiking networks. All the rest of TVB nodes will follow the equations of the mean field model described above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator loop\n",
    "\n",
    "### Simulating several (i.e., minimally 2) NEST time steps for every 1 TVB time step for stable integration\n",
    "\n",
    "### Synchronizaion every minimum delay time between the two simulators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:57.561354Z",
     "start_time": "2019-07-12T20:35:52.475653Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from tvb.basic.profile import TvbProfile\n",
    "TvbProfile.set_profile(TvbProfile.LIBRARY_PROFILE)\n",
    "\n",
    "from tvb_multiscale.tvb_nest.config import Config\n",
    "from examples.parallel.wilson_cowan.config import configure\n",
    "\n",
    "config = configure(config_class=Config)\n",
    "\n",
    "# Select here which kind of test Co-Simulation to perform,\n",
    "# - with Tsync = min_tvb_delay, or\n",
    "# - with Tsync = min_tvb_delay / 2:\n",
    "config.TVB_MIN_IDELAY_TO_SYNC_N_STEP_RATIO = 1\n",
    "# config.INTERFACE_COUPLING_MODE = \"spikeNet\"\n",
    "\n",
    "# For interactive plotting:\n",
    "# %matplotlib notebook  \n",
    "\n",
    "# Otherwise:\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## BACKEND: 1. Load structural data <br> (minimally a TVB connectivity)  <br> & prepare TVB simulator  <br> (region mean field model, integrator, monitors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:59.690799Z",
     "start_time": "2019-07-12T20:35:57.571529Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This would run on TVB only before creating any multiscale cosimulation interface connections.\n",
    "from examples.parallel.tvb_nest.wilson_cowan.tvb_config import build_tvb_simulator\n",
    "\n",
    "simulator = build_tvb_simulator(config=config, config_class=Config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKEND: 2. Build and connect the NEST network model <br> (networks of spiking neural populations for fine-scale <br>regions, stimulation devices, spike detectors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:10.862262Z",
     "start_time": "2019-07-12T20:36:10.000332Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This would run on NEST only before creating any multiscale cosimulation interface connections.\n",
    "# Here it is assumed that the TVB simulator is already created and we can get some of its attributes, \n",
    "# either by directly accessing it, or via serialization.\n",
    "\n",
    "from examples.parallel.tvb_nest.wilson_cowan.nest_config import build_nest_network\n",
    "\n",
    "\n",
    "# nest_network = build_nest_network(config=config, config_class=Config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:19:09.725185Z",
     "start_time": "2019-07-11T10:19:09.721072Z"
    }
   },
   "source": [
    "## FRONTEND: 3. Build the TVB-NEST interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# options for a nonopinionated builder:\n",
    "from tvb_multiscale.core.interfaces.transformers.models.models import Transformers\n",
    "from tvb_multiscale.core.interfaces.transformers.builders import \\\n",
    "        DefaultTVBtoSpikeNetTransformers, DefaultSpikeNetToTVBTransformers, \\\n",
    "        DefaultTVBtoSpikeNetModels, DefaultSpikeNetToTVBModels\n",
    "from tvb_multiscale.tvb_nest.interfaces.builders import \\\n",
    "        TVBtoNESTModels, NESTInputProxyModels, DefaultTVBtoNESTModels, \\\n",
    "        NESTtoTVBModels, NESTOutputProxyModels, DefaultNESTtoTVBModels\n",
    "\n",
    "    \n",
    "    \n",
    "def print_enum(enum):\n",
    "    print(\"\\n\", enum)\n",
    "    for name, member in enum.__members__.items():\n",
    "        print(name,\"= \", member.value)\n",
    "    \n",
    "    \n",
    "print(\"Available input (NEST->TVB update) / output (TVB->NEST coupling) interface models:\")\n",
    "print_enum(TVBtoNESTModels)\n",
    "print_enum(NESTtoTVBModels)\n",
    "    \n",
    "    \n",
    "print(\"\\n\\nAvailable input (spikeNet->TVB update) / output (TVB->spikeNet coupling) transformer models:\")\n",
    "\n",
    "print_enum(DefaultTVBtoSpikeNetModels)\n",
    "print_enum(DefaultTVBtoSpikeNetTransformers)\n",
    "    \n",
    "print_enum(DefaultSpikeNetToTVBModels)\n",
    "print_enum(DefaultSpikeNetToTVBTransformers)    \n",
    "    \n",
    "    \n",
    "print(\"\\n\\nAvailable input (NEST->TVB update) / output (TVB->NEST coupling) proxy models:\")\n",
    "\n",
    "print_enum(DefaultTVBtoNESTModels)\n",
    "print_enum(NESTInputProxyModels)\n",
    "    \n",
    "print_enum(NESTOutputProxyModels)\n",
    "print_enum(DefaultNESTtoTVBModels)\n",
    "    \n",
    "print(\"\\n\\nAll basic transformer models:\")\n",
    "print_enum(Transformers)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:11.137992Z",
     "start_time": "2019-07-12T20:36:10.880947Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from examples.parallel.tvb_nest.wilson_cowan.tvb_interface_config import configure_TVB_interfaces\n",
    "from examples.parallel.tvb_nest.wilson_cowan.nest_interface_config import configure_NEST_interfaces\n",
    "from examples.parallel.tvb_nest.wilson_cowan.transformers_config import \\\n",
    "    configure_TVBtoNEST_transformer_interfaces, configure_NESTtoTVB_transformer_interfaces\n",
    "\n",
    "tvb_interface_builder = configure_TVB_interfaces(simulator=simulator, config=config, config_class=Config)\n",
    "\n",
    "nest_interface_builder = configure_NEST_interfaces(config=config, config_class=Config)\n",
    "\n",
    "tvb_to_nest_interface_builder = configure_TVBtoNEST_transformer_interfaces(config=config, config_class=Config)\n",
    "\n",
    "nest_to_tvb_interface_builder = configure_NESTtoTVB_transformer_interfaces(config=config, config_class=Config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKEND:\n",
    "### - Build TVB and Spiking Network models and simulators\n",
    "### - Build interfaces\n",
    "### - Configure co-simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tvb_multiscale.core.nrp.init.tvb import tvb_init\n",
    "\n",
    "\n",
    "tvb_app = tvb_init(config, tvb_cosimulator_builder=build_tvb_simulator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tvb_multiscale.core.nrp.init.spikeNet import nest_init\n",
    "\n",
    "spikeNet_app = nest_init(config, spiking_network_builder=build_nest_network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb_multiscale.core.nrp.init.transformers import tvb_to_spikeNet_transformer_init, spikeNet_to_tvb_transformer_init\n",
    "\n",
    "\n",
    "tvb_to_spikeNet_app = tvb_to_spikeNet_transformer_init(config)\n",
    "\n",
    "spikeNet_to_tvb_app = spikeNet_to_tvb_transformer_init(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulate, gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:18.879872Z",
     "start_time": "2019-07-12T20:36:11.148945Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tvb_multiscale.core.nrp.run import *\n",
    "\n",
    "\n",
    "def run_for_synchronization_time_sync_min_delay(\n",
    "    tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app,\n",
    "    tvb_to_trans_cosim_updates=None, trans_to_spikeNet_cosim_updates=None,\n",
    "    spikeNet_to_trans_cosim_updates=None,  trans_to_tvb_cosim_updates=None):\n",
    "    \"\"\"Function for cosimulating for one loop of synchronization time.\n",
    "       It could be the highest level possible ENTRYPOINT for a parallel cosimulation.\n",
    "       In that case, the cosimulation manager would be completely agnostic\n",
    "       - of what the Apps of the different processed do,\n",
    "       - including the transformation function they employ.\n",
    "       The ENTRYPOINT here is just the cosimulation updates' data,\n",
    "       which are \"thrown over the wall\" for the necessary data exchanges.\n",
    "       Co-Simulator and bidirectional Transformers have to alternate between them, \n",
    "       and can be parallelized within (CoSimulator and Transformers respectively).\n",
    "    \"\"\"\n",
    "    # Transform TVB -> spikeNet couplings of times [t, t + Tsync] = [t, t + min_tvb_delay]...\n",
    "    # ...or TVB -> spikeNet state of times [t - Tsync, t]=[t - min_tvb_delay, t]\n",
    "    if tvb_to_trans_cosim_updates is not None:\n",
    "        # ...if any:\n",
    "        trans_to_spikeNet_cosim_updates = run_transformer(tvb_to_spikeNet_app, tvb_to_trans_cosim_updates)\n",
    "    else:\n",
    "        trans_to_spikeNet_cosim_updates = None\n",
    "    # Transform SpikeNet -> TVB updates of times [t - Tsync, t] = [t - min_tvb_delay, t]...\n",
    "    if spikeNet_to_trans_cosim_updates is not None:\n",
    "        # ...if any:\n",
    "        trans_to_tvb_cosim_updates = run_transformer(spikeNet_to_tvb_app, spikeNet_to_trans_cosim_updates)\n",
    "    else:\n",
    "        trans_to_tvb_cosim_updates = None\n",
    "    # TVB t -> t + Tsync\n",
    "    # Simulate TVB for times [t, t + Tsync] = [t, t + min_tvb_delay]\n",
    "    # with or without spikeNet update inputs of times [t - Tsync, t] = [t - min_tvb_delay, t]\n",
    "    tvb_to_trans_cosim_updates = run_tvb(tvb_app, trans_to_tvb_cosim_updates)\n",
    "    # SpikeNet t -> t + Tsync\n",
    "    # Simulate spikeNet for times [t, t + Tsync] = [t, t + min_tvb_delay]\n",
    "    # with or without TVB coupling inputs of times [t, t + min_tvb_delay]\n",
    "    # or TVB state inputs of times [t - min_tvb_delay/2, t]\n",
    "    spikeNet_to_trans_cosim_updates = run_spikeNet(spikeNet_app, trans_to_spikeNet_cosim_updates)\n",
    "    return tvb_to_trans_cosim_updates, trans_to_spikeNet_cosim_updates, \\\n",
    "           spikeNet_to_trans_cosim_updates, trans_to_tvb_cosim_updates\n",
    "\n",
    "\n",
    "def run_for_synchronization_time_sync_min_delay2(\n",
    "    tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app,\n",
    "    input_tvb_to_trans_cosim_updates=None, input_trans_to_spikeNet_cosim_updates=None,\n",
    "    input_spikeNet_to_trans_cosim_updates=None,  input_trans_to_tvb_cosim_updates=None):\n",
    "    \"\"\"Function for cosimulating for one loop of synchronization time.\n",
    "       It could be the highest level possible ENTRYPOINT for a parallel cosimulation.\n",
    "       In that case, the cosimulation manager would be completely agnostic\n",
    "       - of what the Apps of the different processed do,\n",
    "       - including the transformation function they employ.\n",
    "       The ENTRYPOINT here is just the cosimulation updates' data,\n",
    "       which are \"thrown over the wall\" for the necessary data exchanges.\n",
    "       All processes can work in parallel, \n",
    "       since the transformers work on time intervals than those simulated by the cosimulators.\n",
    "    \"\"\"\n",
    "    # Transform TVB -> SpikeNet couplings of times [t + Tsync, t + 2*Tsync]=[t + min_tvb_delay/2, t + min_tvb_delay]...\n",
    "    # ...or TVB -> spikeNet state of times [t - Tsync, t]=[t - min_tvb_delay/2, t]\n",
    "    if input_tvb_to_trans_cosim_updates is not None:\n",
    "        # ...if any:\n",
    "        trans_to_spikeNet_cosim_updates = run_transformer(tvb_to_spikeNet_app, input_tvb_to_trans_cosim_updates)\n",
    "    else:\n",
    "        trans_to_spikeNet_cosim_updates = None\n",
    "    # Transform SpikeNet -> TVB updates of times [t - Tsync, t]=[t - min_tvb_delay/2, t]...\n",
    "    if input_spikeNet_to_trans_cosim_updates is not None:\n",
    "        # ...if any:\n",
    "        trans_to_tvb_cosim_updates = run_transformer(spikeNet_to_tvb_app, input_spikeNet_to_trans_cosim_updates)\n",
    "    else:\n",
    "        trans_to_tvb_cosim_updates = None\n",
    "    # TVB t -> t + Tsync\n",
    "    # Simulate TVB for times [t, t + Tsync] = [t, t + min_tvb_delay/2]\n",
    "    # with or without SpikeNet update inputs of times [t - 2*Tsync, t - Tsync] = [t - min_tvb_delay/, t - min_tvb_delay/2]\n",
    "    tvb_to_trans_cosim_updates = run_tvb(tvb_app, input_trans_to_tvb_cosim_updates)\n",
    "    # SpikeNet t -> t + Tsync\n",
    "    # Simulate SpikeNet for times [t, t + Tsync] = [t, t + min_tvb_delay/2]\n",
    "    # with or without TVB coupling inputs of times [t, t + min_tvb_delay/2]\n",
    "    # or TVB state inputs of times [t - min_tvb_delay, t - min_tvb_delay/2]\n",
    "    spikeNet_to_trans_cosim_updates = run_spikeNet(spikeNet_app, input_trans_to_spikeNet_cosim_updates)\n",
    "    return tvb_to_trans_cosim_updates, trans_to_spikeNet_cosim_updates, \\\n",
    "           spikeNet_to_trans_cosim_updates, trans_to_tvb_cosim_updates\n",
    "\n",
    "\n",
    "\n",
    "def run_cosimulation(tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app,\n",
    "                     advance_simulation_for_delayed_monitors_output=True):\n",
    "    \"\"\"Function for running the whole cosimulation, assuming all Apps are built and configured.\n",
    "       This function shows the necessary initialization of the cosimulation.\n",
    "    \"\"\"\n",
    "\n",
    "    import time\n",
    "    import numpy as np\n",
    "\n",
    "    # Keep the following cosimulation attributes safe and easy to access:\n",
    "    simulation_length = tvb_app.cosimulator.simulation_length \n",
    "    synchronization_time = tvb_app.cosimulator.synchronization_time\n",
    "    synchronization_n_step = tvb_app.cosimulator.synchronization_n_step  # store the configured value\n",
    "    if advance_simulation_for_delayed_monitors_output:\n",
    "        simulation_length += synchronization_time\n",
    "    dt = tvb_app.cosimulator.integrator.dt\n",
    "    \n",
    "    # Initial conditions of co-simulation:\n",
    "    \n",
    "    tvb_app.cosimulator.relative_output_interfaces_time_steps = 0\n",
    "    tvb_app.cosimulator.relative_output_time_steps = 0\n",
    "    \n",
    "    # TVB initial condition cosimulation data towards spikeNet \n",
    "    # - of TVB coupling for [0, Tsync] if INTERFACE_COUPLING_MODE == \"TVB\"\n",
    "    # - of TVB state for [-Tsync, 0] if INTERFACE_COUPLING_MODE == \"spikeNet\"\n",
    "    tvb_to_trans_cosim_updates = tvb_app.get_tvb_init_cosim_coupling(relative_output_interfaces_time_steps=0)\n",
    "    # SpikeNet initial condition update towards TVB:\n",
    "    spikeNet_to_trans_cosim_updates = None\n",
    "    # Transformer to TVB initial condition:\n",
    "    trans_to_tvb_cosim_updates = None\n",
    "    # Transformer to SpikeNet initial condition:\n",
    "    trans_to_spikeNet_cosim_updates = None\n",
    "    if tvb_app.cosimulator.min_idelay_sync_n_step_ratio == 2:\n",
    "        run_for_synchronization_time = run_for_synchronization_time_sync_min_delay2\n",
    "        tvb_app.cosimulator.relative_output_time_steps = tvb_app.cosimulator.synchronization_n_step\n",
    "        if advance_simulation_for_delayed_monitors_output:\n",
    "            simulation_length += tvb_app.cosimulator.relative_output_time_steps * tvb_app.cosimulator.integrator.dt\n",
    "        if tvb_app.config.INTERFACE_COUPLING_MODE == \"TVB\":\n",
    "        # If this is a TVB coupling interface,\n",
    "            # ...transform the initial condition for [0, Tsync] = [0 min_tvb_delay/2] from TVB to SpikeNet:\n",
    "            if tvb_to_trans_cosim_updates is not None:\n",
    "                # ...if any:\n",
    "                trans_to_spikeNet_cosim_updates = tvb_to_spikeNet_app.run_for_synchronization_time(tvb_to_trans_cosim_updates)\n",
    "            # ...and advance the data sent from TVB towards the transformer,\n",
    "            # by Tsync = min_tvb_delay / 2\n",
    "            # TVB initial condition cosimulation coupling towards SpikeNet \n",
    "            # for [Tsync, 2*Tsync] = [min_tvb_delay/2, min_tvb_delay]\n",
    "            tvb_to_trans_cosim_updates = tvb_app.get_tvb_init_cosim_coupling(\n",
    "                relative_output_interfaces_time_steps=tvb_app.cosimulator.synchronization_n_step) \n",
    "            # Keep this advancement in time for the simulation to follow:\n",
    "            tvb_app.cosimulator.relative_output_interfaces_time_steps = tvb_app.cosimulator.synchronization_n_step\n",
    "        else:\n",
    "            # If this is a spikeNet coupling interface,\n",
    "            # ...get the past state from TVB towards the transformer,\n",
    "            # by Tsync = -min_tvb_delay / 2\n",
    "            # TVB initial condition cosimulation state towards SpikeNet \n",
    "            # for [-2*Tsync, Tsync] = [-min_tvb_delay, -min_tvb_delay/2]\n",
    "            tvb_to_trans_cosim_updates_past = tvb_app.get_tvb_init_cosim_coupling(\n",
    "                relative_output_interfaces_time_steps=-tvb_app.cosimulator.synchronization_n_step)\n",
    "            # ...and transform it:\n",
    "            trans_to_spikeNet_cosim_updates = tvb_to_spikeNet_app.run_for_synchronization_time(tvb_to_trans_cosim_updates_past)\n",
    "    else:\n",
    "        run_for_synchronization_time = run_for_synchronization_time_sync_min_delay\n",
    "    \n",
    "    # Steps left to simulate:\n",
    "    remaining_steps = int(np.round(simulation_length / dt))\n",
    "    # Steps already simulated:\n",
    "    simulated_steps = 0\n",
    "    \n",
    "    # Loop for steps_to_simulate in steps of synchronization_time:\n",
    "    tvb_app.cosimulator._tic = time.time()\n",
    "    while remaining_steps > 0:\n",
    "        # Set the remaining steps as simulation time, \n",
    "        # if it is less than the original synchronization time:\n",
    "        tvb_app.cosimulator.synchronization_n_step = np.minimum(remaining_steps, synchronization_n_step)\n",
    "        time_to_simulate = dt * tvb_app.cosimulator.synchronization_n_step\n",
    "        tvb_app.cosimulator.synchronization_time = time_to_simulate\n",
    "        spikeNet_app.synchronization_time = time_to_simulate\n",
    "        tvb_to_trans_cosim_updates, trans_to_spikeNet_cosim_updates, \\\n",
    "        spikeNet_to_trans_cosim_updates, trans_to_tvb_cosim_updates = \\\n",
    "            run_for_synchronization_time(tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app,\n",
    "                                         tvb_to_trans_cosim_updates, trans_to_spikeNet_cosim_updates, \n",
    "                                         spikeNet_to_trans_cosim_updates, trans_to_tvb_cosim_updates)\n",
    "        simulated_steps += tvb_app.cosimulator.n_tvb_steps_ran_since_last_synch\n",
    "        tvb_app.cosimulator._log_print_progress_message(simulated_steps, simulation_length)\n",
    "        remaining_steps -= tvb_app.cosimulator.n_tvb_steps_ran_since_last_synch\n",
    "\n",
    "    # Update the simulation length of the TVB cosimulator:\n",
    "    tvb_app.cosimulator.simulation_length = simulated_steps * dt  # update the configured value\n",
    "    # Restore the original synchronization_time\n",
    "    tvb_app.cosimulator.synchronization_n_step = synchronization_n_step\n",
    "    tvb_app.cosimulator.synchronization_time = synchronization_time\n",
    "    spikeNet_app.synchronization_time = synchronization_time\n",
    "            \n",
    "    return tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app, \\\n",
    "           tvb_to_trans_cosim_updates, trans_to_spikeNet_cosim_updates, \\\n",
    "           spikeNet_to_trans_cosim_updates, trans_to_tvb_cosim_updates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app, \\\n",
    "tvb_to_trans_cosim_updates, trans_to_spikeNet_cosim_updates, \\\n",
    "           spikeNet_to_trans_cosim_updates, trans_to_tvb_cosim_updates = \\\n",
    "    run_cosimulation(tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app, \n",
    "                     advance_simulation_for_delayed_monitors_output=True)\n",
    "\n",
    "results = tvb_app.return_tvb_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot results and write them to HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "from tvb_multiscale.core.plot.plotter import Plotter\n",
    "\n",
    "\n",
    "# set to False for faster plotting of only mean field variables and dates, apart from spikes\" rasters:\n",
    "plot_per_neuron = False  \n",
    "MAX_VARS_IN_COLS = 3\n",
    "MAX_REGIONS_IN_ROWS = 10\n",
    "MIN_REGIONS_FOR_RASTER_PLOT = 9\n",
    "\n",
    "# Set the transient time to be optionally removed from results:\n",
    "simulation_length = tvb_app.cosimulator.simulation_length\n",
    "transient = getattr(config, \"TRANSIENT\", 0.1*simulation_length)\n",
    "\n",
    "simulator = tvb_app.cosimulator\n",
    "nest_network = spikeNet_app.spiking_network\n",
    "nest_nodes_inds = tvb_app.cosimulator.proxy_inds\n",
    "\n",
    "config.figures.SHOW_FLAG = True \n",
    "config.figures.SAVE_FLAG = True\n",
    "config.figures.FIG_FORMAT = 'png'\n",
    "config.figures.DEFAULT_SIZE= config.figures.NOTEBOOK_SIZE\n",
    "FIGSIZE = config.figures.DEFAULT_SIZE\n",
    "\n",
    "plotter = Plotter(config.figures)\n",
    "\n",
    "try:\n",
    "    # We need framework_tvb for writing and reading from HDF5 files\n",
    "    from tvb_multiscale.core.tvb.io.h5_writer import H5Writer\n",
    "    from examples.plot_write_results import write_RegionTimeSeriesXarray_to_h5\n",
    "    writer = H5Writer()\n",
    "    \n",
    "except:\n",
    "    writer = False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVB plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tvb_app.plot(transient=transient, plotter=plotter, writer=writer)\n",
    "\n",
    "# If you want to see what the function above does, take the steps, one by one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the results in a Timeseries instance\n",
    "from tvb.contrib.scripts.datatypes.time_series_xarray import TimeSeriesRegion as TimeSeriesXarray\n",
    "\n",
    "source_ts = None\n",
    "t = simulation_length * simulator.integrator.dt\n",
    "if results is not None:\n",
    "    # Substitute with TimeSeriesRegion fot TVB like functionality:\n",
    "    # from tvb.contrib.scripts.datatypes.time_series import TimeSeriesRegion\n",
    "    source_ts = TimeSeriesXarray(  \n",
    "            data=results[0][1], time=results[0][0],\n",
    "            connectivity=simulator.connectivity,\n",
    "            labels_ordering=[\"Time\", \"State Variable\", \"Region\", \"Neurons\"],\n",
    "            labels_dimensions={\"State Variable\": list(simulator.model.variables_of_interest),\n",
    "                               \"Region\": simulator.connectivity.region_labels.tolist()},\n",
    "            sample_period=simulator.integrator.dt)\n",
    "    source_ts.configure()\n",
    "\n",
    "    t = source_ts.time\n",
    "\n",
    "    # Write to file\n",
    "    if writer:\n",
    "        write_RegionTimeSeriesXarray_to_h5(source_ts, writer,\n",
    "                                           os.path.join(config.out.FOLDER_RES, source_ts.title)+\".h5\")\n",
    "    source_ts   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot TVB time series\n",
    "if source_ts is not None:\n",
    "    source_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                          hue=\"Region\" if source_ts.shape[2] > MAX_REGIONS_IN_ROWS else None, \n",
    "                          per_variable=source_ts.shape[1] > MAX_VARS_IN_COLS, \n",
    "                          figsize=FIGSIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: raster plot\n",
    "if source_ts is not None and source_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "    source_ts.plot_raster(plotter_config=plotter.config, \n",
    "                          per_variable=source_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "                          figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series Raster\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: \n",
    "n_spiking_nodes = len(nest_nodes_inds)\n",
    "if source_ts is not None and n_spiking_nodes:\n",
    "    source_ts_nest = source_ts[:, :, nest_nodes_inds]\n",
    "    source_ts_nest.plot_timeseries(plotter_config=plotter.config, \n",
    "                                   hue=\"Region\" if source_ts_nest.shape[2] > MAX_REGIONS_IN_ROWS else None, \n",
    "                                   per_variable=source_ts_nest.shape[1] > MAX_VARS_IN_COLS, \n",
    "                                   figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: raster plot\n",
    "if source_ts is not None and n_spiking_nodes: # and source_ts_nest.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "    source_ts_nest.plot_raster(plotter_config=plotter.config, \n",
    "                               per_variable=source_ts_nest.shape[1] > MAX_VARS_IN_COLS,\n",
    "                               figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series Raster\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ...interactively as well\n",
    "# # For interactive plotting:\n",
    "# %matplotlib notebook \n",
    "# plotter.plot_timeseries_interactive(source_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiking Network plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# spikeNet_app.plot(time=t, transient=transient,\n",
    "#                   plot_per_neuron=plot_per_neuron, plotter=plotter, writer=writer)\n",
    "\n",
    "# If you want to see what the function above does, take the steps, one by one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeNet_analyzer = None\n",
    "if nest_network is not None:\n",
    "    from tvb_multiscale.core.data_analysis.spiking_network_analyser import SpikingNetworkAnalyser\n",
    "    # Create a SpikingNetworkAnalyzer:\n",
    "    spikeNet_analyzer = \\\n",
    "        SpikingNetworkAnalyser(spikeNet=nest_network,\n",
    "                               start_time=0.0, end_time=simulation_length, \n",
    "                               transient=transient, time_series_output_type=\"TVB\", \n",
    "                               return_data=True, force_homogeneous_results=True, \n",
    "                               period=simulator.monitors[0].period, connectivity=simulator.connectivity\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spikes' raster and mean spike rates and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spikes_res = None\n",
    "if spikeNet_analyzer is not None:\n",
    "    # Spikes rates and correlations per Population and Region\n",
    "    spikes_res = \\\n",
    "        spikeNet_analyzer.\\\n",
    "            compute_spikeNet_spikes_rates_and_correlations(\n",
    "                populations_devices=None, regions=None,\n",
    "                rates_methods=[], rates_kwargs=[{}],rate_results_names=[],\n",
    "                corrs_methods=[], corrs_kwargs=[{}], corrs_results_names=[], bin_kwargs={},\n",
    "                data_method=spikeNet_analyzer.get_spikes_from_device, data_kwargs={},\n",
    "                return_devices=False\n",
    "            );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(spikes_res[\"mean_rate\"])\n",
    "    print(spikes_res[\"spikes_correlation_coefficient\"])\n",
    "    # Plot spikes' rasters together with mean population's spikes' rates' time series\n",
    "    if plotter:\n",
    "        plotter.plot_spike_events(spikes_res[\"spikes\"], mean_results=spikes_res[\"mean_rate\"], # time_series=spikes_res[\"mean_rate_time_series\"], \n",
    "                                  figsize=(20, 22),  \n",
    "                                  stimulus=None,\n",
    "                                  stimulus_linewidth=5.0,\n",
    "                                  spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                                  n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                                  time_axis_min=0.0, time_axis_max=simulation_length)\n",
    "        from tvb_multiscale.core.plot.correlations_plot import plot_correlations\n",
    "        plot_correlations(spikes_res[\"spikes_correlation_coefficient\"], plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(\"Mean spike rates:\")\n",
    "    for pop in spikes_res[\"mean_rate\"].coords[\"Population\"]:\n",
    "        for reg in spikes_res[\"mean_rate\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_res[\"mean_rate\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_res[\"mean_rate\"].loc[pop, reg].values.item()))\n",
    "\n",
    "    # savemat(os.path.join(config.out.FOLDER_RES, \"spikes_mean_rates.mat\"), spikes_res[\"mean_rate\"].to_dict())\n",
    "\n",
    "    \n",
    "#--------------- INTERFACE_COUPLING_MODE = \"TVB\" --------------\n",
    "\n",
    "# Mean spike rates:\n",
    "# def_min_delay = 0.1ms, w_TVB_to_NEST = 5000.0, synchronization_time = min_tvb_delay\n",
    "# E - bankssts_L: 28.85\n",
    "# E - bankssts_R: 27.8552\n",
    "# I - bankssts_L: 28.85\n",
    "# I - bankssts_R: 27.8552\n",
    "\n",
    "\n",
    "# def_min_delay = 1.0 ms, w_TVB_to_NEST = 2500.0:\n",
    "\n",
    "# Mean spike rates, with synchronization_time = min_tvb_delay:\n",
    "# E - bankssts_L: 28.3725\n",
    "# E - bankssts_R: 30.1632\n",
    "# I - bankssts_L: 30.8396\n",
    "# I - bankssts_R: 39.7931\n",
    "# completed in 77.6139 sec!\n",
    "\n",
    "# Mean spike rates, with synchronization_time = min_tvb_delay / 2:\n",
    "# E - bankssts_L: 29.2579\n",
    "# E - bankssts_R: 28.5515\n",
    "# I - bankssts_L: 31.8345\n",
    "# I - bankssts_R: 31.8345\n",
    "# completed in 99.6736 sec!\n",
    "\n",
    "\n",
    "#--------------- INTERFACE_COUPLING_MODE = \"spikeNet\" --------------\n",
    "# with min_nest_delay = 1.0ms and wTVB_to_NEST = 2500.0:\n",
    "\n",
    "# Mean spike rates, with synchronization_time = min_tvb_delay:\n",
    "# E - bankssts_L: 25.9451\n",
    "# E - bankssts_R: 23.0004\n",
    "# I - bankssts_L: 27.8552\n",
    "# I - bankssts_R: 24.8707\n",
    "# ...100.000% completed in ?? sec!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spikes_sync = None\n",
    "\n",
    "if spikeNet_analyzer is not None:\n",
    "\n",
    "    spikeNet_analyzer.resample = True\n",
    "    spikes_sync = \\\n",
    "        spikeNet_analyzer.compute_spikeNet_synchronization(populations_devices=None, regions=None,\n",
    "                                                           comp_methods=[spikeNet_analyzer.compute_spikes_sync, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_sync_time_series, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_distance, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_distance_time_series,\n",
    "                                                                         spikeNet_analyzer.compute_spikes_isi_distance, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_isi_distance_time_series],\n",
    "                                                           computations_kwargs=[{}], data_kwargs={},\n",
    "                                                           return_spikes_trains=False, return_devices=False)\n",
    "# print(spikes_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_sync_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_sync\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_distance_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_distance\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_isi_distance_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_isi_distance\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike synchronization:\")\n",
    "    for pop in spikes_sync[\"spikes_sync\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_sync\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_sync\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_sync\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_sync.mat\"), spikes_sync[\"spikes_sync\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_sync_time_series.mat\"), spikes_sync[\"spikes_sync_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike distance:\")\n",
    "    for pop in spikes_sync[\"spikes_distance\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_distance\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_distance\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_distance\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_distance.mat\"), spikes_sync[\"spikes_distance\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_distance_time_series.mat\"), spikes_sync[\"spikes_distance_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike ISI distance:\")\n",
    "    for pop in spikes_sync[\"spikes_isi_distance\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_isi_distance\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_isi_distance\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_isi_distance\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_isi_distance.mat\"), spikes_sync[\"spikes_isi_distance\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_isi_distance_time_series.mat\"), spikes_sync[\"spikes_isi_distance_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_res and writer:\n",
    "    writer.write_object(spikes_res[\"spikes\"].to_dict(), \n",
    "                        path=os.path.join(config.out.FOLDER_RES,  \"Spikes\") + \".h5\");\n",
    "    writer.write_object(spikes_res[\"mean_rate\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"mean_rate\"].name) + \".h5\");\n",
    "    write_RegionTimeSeriesXarray_to_h5(spikes_res[\"mean_rate_time_series\"], writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES,\n",
    "                                                    spikes_res[\"mean_rate_time_series\"].title + \".h5\"),\n",
    "                                       recursive=False);\n",
    "    writer.write_object(spikes_res[\"spikes_correlation_coefficient\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"spikes_correlation_coefficient\"].name) + \".h5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  SpikingNetwork mean field variable time series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Continuous time variables' data of spiking neurons\n",
    "spikeNet_ts = None\n",
    "mean_field_ts = None\n",
    "if spikeNet_analyzer:\n",
    "    if plot_per_neuron:\n",
    "        spikeNet_analyzer.return_data = True\n",
    "    else:\n",
    "        spikeNet_analyzer.return_data = False\n",
    "    spikeNet_ts = \\\n",
    "        spikeNet_analyzer. \\\n",
    "             compute_spikeNet_mean_field_time_series(populations_devices=None, regions=None, variables=None,\n",
    "                                                     computations_kwargs={}, data_kwargs={}, return_devices=False)\n",
    "    if spikeNet_ts:\n",
    "        if plot_per_neuron:\n",
    "            mean_field_ts = spikeNet_ts[\"mean_field_time_series\"]  # mean field\n",
    "            spikeNet_ts = spikeNet_ts[\"data_by_neuron\"]  # per neuron data\n",
    "        else:\n",
    "            mean_field_ts = spikeNet_ts\n",
    "            spikeNet_ts = None\n",
    "        if mean_field_ts and mean_field_ts.size > 0:\n",
    "            mean_field_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                                          per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS)\n",
    "            if mean_field_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "                mean_field_ts.plot_raster(plotter_config=plotter.config, \n",
    "                                          per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "                                          linestyle=\"--\", alpha=0.5, linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to file:\n",
    "if mean_field_ts and writer:\n",
    "    write_RegionTimeSeriesXarray_to_h5(mean_field_ts, writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES, mean_field_ts.title + \".h5\"), \n",
    "                                       recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute per neuron spikes' rates times series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if spikes_res and plot_per_neuron:\n",
    "    from tvb.simulator.plot.base_plotter import pyplot\n",
    "    spikeNet_analyzer.return_data = False\n",
    "    rates_ts_per_neuron = \\\n",
    "        spikeNet_analyzer. \\\n",
    "            compute_spikeNet_rates_time_series(populations_devices=None, regions=None,\n",
    "                                               computations_kwargs={}, data_kwargs={},\n",
    "                                               return_spikes_trains=False, return_devices=False);\n",
    "    if rates_ts_per_neuron is not None and rates_ts_per_neuron.size:\n",
    "        # Regions in rows\n",
    "        row = rates_ts_per_neuron.dims[2] if rates_ts_per_neuron.shape[2] > 1 else None\n",
    "        if row is None:\n",
    "            # Populations in rows\n",
    "            row = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "            col = None\n",
    "        else:\n",
    "            # Populations in columns\n",
    "            col = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "        pyplot.figure()\n",
    "        rates_ts_per_neuron.plot(y=rates_ts_per_neuron.dims[3], row=row, col=col, cmap=\"jet\")\n",
    "        plotter.base._save_figure(figure_name=\"Spike rates per neuron\")\n",
    "        # del rates_ts_per_neuron # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot per neuron SpikingNetwork time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regions in rows\n",
    "if spikeNet_ts is not None and spikeNet_ts.size:\n",
    "    row = spikeNet_ts.dims[2] if spikeNet_ts.shape[2] > 1 else None\n",
    "    if row is None:\n",
    "        # Populations in rows\n",
    "        row = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "        col = None\n",
    "    else:\n",
    "        # Populations in cols\n",
    "         col = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "    for var in spikeNet_ts.coords[spikeNet_ts.dims[1]]:\n",
    "        this_var_ts = spikeNet_ts.loc[:, var, :, :, :]\n",
    "        this_var_ts.name = var.item()\n",
    "        pyplot.figure()\n",
    "        this_var_ts.plot(y=spikeNet_ts.dims[4], row=row, col=col, cmap=\"jet\", figsize=FIGSIZE)\n",
    "        plotter.base._save_figure(\n",
    "            figure_name=\"Spiking Network variables' time series per neuron: %s\" % this_var_ts.name)\n",
    "    del spikeNet_ts # to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from tvb_multiscale.core.nrp.final import *\n",
    "\n",
    "\n",
    "spikeNet_app = final_spikeNet(spikeNet_app, plot=True)\n",
    "tvb_to_spikeNet_app = final_transformer(tvb_to_spikeNet_app)\n",
    "spikeNet_to_tvb_app = final_transformer(spikeNet_to_tvb_app)\n",
    "tvb_app = final_tvb(tvb_app, plot=True)\n",
    "\n",
    "del tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# References\n",
    "\n",
    "1 Paula Sanz Leon, Stuart A. Knock, M. Marmaduke Woodman, Lia Domide, <br>\n",
    "  Jochen Mersmann, Anthony R. McIntosh, Viktor Jirsa (2013) <br>\n",
    "  The Virtual Brain: a simulator of primate brain network dynamics. <br>\n",
    "  Frontiers in Neuroinformatics (7:10. doi: 10.3389/fninf.2013.00010) <br>\n",
    "  https://www.thevirtualbrain.org/tvb/zwei <br>\n",
    "  https://github.com/the-virtual-brain <br>\n",
    "\n",
    "2 Ritter P, Schirner M, McIntosh AR, Jirsa VK. 2013.  <br>\n",
    "  The Virtual Brain integrates computational modeling  <br>\n",
    "  and multimodal neuroimaging. Brain Connectivity 3:121–145. <br>\n",
    "\n",
    "3 Jordan, Jakob; Mørk, Håkon; Vennemo, Stine Brekke;   Terhorst, Dennis; Peyser, <br>\n",
    "  Alexander; Ippen, Tammo; Deepu, Rajalekshmi;   Eppler, Jochen Martin; <br>\n",
    "  van Meegen, Alexander;   Kunkel, Susanne; Sinha, Ankur; Fardet, Tanguy; Diaz, <br>\n",
    "  Sandra; Morrison, Abigail; Schenck, Wolfram; Dahmen, David;   Pronold, Jari; <br>\n",
    "  Stapmanns, Jonas;   Trensch, Guido; Spreizer, Sebastian;   Mitchell, Jessica; <br>\n",
    "  Graber, Steffen; Senk, Johanna; Linssen, Charl; Hahne, Jan; Serenko, Alexey; <br>\n",
    "  Naoumenko, Daniel; Thomson, Eric;   Kitayama, Itaru; Berns, Sebastian;   <br>\n",
    "  Plesser, Hans Ekkehard <br>\n",
    "  NEST is a simulator for spiking neural network models that focuses <br>\n",
    "  on the dynamics, size and structure of neural systems rather than on <br>\n",
    "  the exact morphology of individual neurons. <br>\n",
    "  For further information, visit http://www.nest-simulator.org. <br>\n",
    "  The release notes for this release are available at  <br>\n",
    "  https://github.com/nest/nest-simulator/releases/tag/v2.18.0 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
