{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVB-NEST: Bridging multiscale activity by co-simulation\n",
    "\n",
    "## Step-by-step learn how to perform a co-simulation embedding spiking neural networks into large-scale brain networks using TVB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import Image, display\n",
    "display(Image(filename='pics/ConceptGraph1.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tvb-multiscale toolbox:\n",
    "\n",
    "### https://github.com/the-virtual-brain/tvb-multiscale\n",
    "\n",
    "For questions use the git issue tracker, or write an e-mail to me: dionysios.perdikis@charite.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T13:37:40.905578Z",
     "start_time": "2019-07-11T13:37:40.894958Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TVB - NEST co-simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Wong-Wang TVB mean field model\n",
    "\n",
    "For every region node $n\\prime$ modelled as a mean-field node in TVB:\n",
    "\n",
    "(Post)Synaptic gating dynamics (i.e., proportion of synapse channels open at any given time):\n",
    "\n",
    "$\\dot{S_{n\\prime}} = - \\frac{1}{\\tau}{S_{n\\prime}}(t) + (1-{S_{n\\prime}}(t))\\gamma {R_{n\\prime}}(t)$\n",
    "\n",
    "and $ {R_{n\\prime}}(t) $ is the postsynaptic firing rate given by:\n",
    "\n",
    "$ {R_{n\\prime}}(t) = H({I_{syn_{n\\prime}}}(t), a, b, d) $\n",
    "\n",
    "where\n",
    "\n",
    "$ H({I_{syn_{n\\prime}}}(t),  a, b, d) = \\frac{aI_{syn_{n\\prime}}(t)-b}{1-e^{-d(a{I_{syn_{n\\prime}}}(t)-b)}}$ \n",
    "\n",
    "is a sigmoidal activation function of the input presynaptic current.\n",
    "\n",
    "The total input presynaptic current to excitatory populations is given by: \n",
    "\n",
    "$ {I_{syn_{n\\prime}}}(t) = I_o + w_+J_{N}{S_{n\\prime}}(t) + GJ_{N}\\sum_{{m\\prime}\\neq {n\\prime}}C_{{m\\prime}{n\\prime}}S_{m\\prime}(t-\\tau_{{m\\prime}{n\\prime}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Wong-Wang mean field model\n",
    "\n",
    "### Parameters following Deco et al 2013:\n",
    "\n",
    "- structural TVB connectivity weights $C_{{m\\prime}{n\\prime}}$ (${m\\prime}->{n\\prime}$)\n",
    "- structural TVB connectivity delays $\\tau_{{m\\prime}{n\\prime}}$  (${m\\prime}->{n\\prime}$)\n",
    "- global structural brain connectivity coupling constant $G$\n",
    "- overall effective external input current $I_o = 0.3nA$ \n",
    "- excitatory synaptic coupling $J_{N} = 0.2609nA$ \n",
    "- local excitatory recurrence $w_+ = 0.9$\n",
    "- excitatory kinetic parameter $\\gamma = 0.641 s$\n",
    "- excitatory sigmoidal functions parameters $a = 2710nC^{-1}$, $b = 108Hz$, $d = 0.154s$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Izhikevich Spiking network model in NEST\n",
    "\n",
    "For every neuron $i$ in region node $n$ modelled in NEST as a spiking network:\n",
    "\n",
    "Membrane potential:\n",
    "\n",
    "$ \\dot{V}_m = n_2V_m^2 + n_1V_m + n_0140 - U_m/C - g_{AMPA}(V_m-E_{AMPA}) - g_{GABA}(V_m-E_{GABA}) - g_{BASE}V_m + I_e$\n",
    "\n",
    "where the conductances follow the equations:\n",
    "\n",
    "$ \\dot{g}_{AMPA} = - g_{AMPA} / \\tau_{AMPA} + \\left[\\sum_k \\delta(t-t_k) \\right]_{Exc}$\n",
    "\n",
    "$ \\dot{g}_{GABA} = - g_{GABA} / \\tau_{GABA} + \\left[\\sum_k \\delta(t-t_k) \\right]_{Inh}$\n",
    "\n",
    "$ \\dot{g}_{BASE} = - g_{BASE} / \\tau_{BASE} + \\left[\\sum_k \\delta(t-t_k) \\right]_{BASE}$\n",
    "\n",
    "and recovery variable:\n",
    "\n",
    "$ \\dot{U}_m = a(bV_m - U_m)$\n",
    "\n",
    "\n",
    "When $ V_m > V_{th} $ , $ V_m $ is set to $ c $, and $ U_m $ is incremented by $ d $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVB to NEST coupling\n",
    "TVB couples to NEST via instantaneous spike rate $ interface_{weight} * R(t) $, \n",
    "\n",
    "Spike generator NEST devices are used as TVB \"proxy\" nodes and generate spike trains \n",
    "\n",
    "$ \\left[ \\sum_k \\delta(t-\\tau_{n\\prime n}-{t_j}^k) \\right]_{j \\in n\\prime} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(Image(filename='pics/Rate_BG.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEST to TVB update\n",
    "\n",
    "A NEST spike detector device is used to count spike for each time step, and convert it to an instantaneous population mean rate that overrides an auxiliary TVB state variables $R_{in}(t)$, which drives a linear integration equation of another auxiliary TVB state variable $R_{int}(t)$, which,in its turn, acts as a smoothing low pass filter:\n",
    "\n",
    "$ \\dot{R}_{int_{n}}  = -\\frac{1}{\\tau_{rin_{n}}}(R_{int_{n}}(t) - {R_{in_{n}}}(t)) $\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "$ {R_{in_{n}}}(t) =  \\frac{\\sum_j\\left[ \\sum_k \\delta(t-\\tau_n-{t_j}^k) \\right]_{j \\in R_n}}{nNeurons * dt} $ in  spikes/sec.\n",
    "\n",
    "Finally, $ {R_{int_{n}}}(t) $ overwrites the variable ${R_{n}}(t)$ via a user defined transform function:\n",
    "\n",
    "${R_{n}}(t) = f_{NEST->TVB}({R_{int_{n}}}(t)) $\n",
    "\n",
    "This update process concerns only the TVB region nodes that are simulated exclusively in NEST, as spiking networks. All the rest of TVB nodes will follow the equations of the mean field model described above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='pics/NESTtoTVB_BG.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:57.561354Z",
     "start_time": "2019-07-12T20:35:52.475653Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from tvb.basic.profile import TvbProfile\n",
    "TvbProfile.set_profile(TvbProfile.LIBRARY_PROFILE)\n",
    "\n",
    "INTERFACE_COUPLING_MODE = \"spikeNet\" # \"TVB\"  or \"spikeNet\"\n",
    "data_mode = \"patient\" # \"control\", or \"patient\"\n",
    "\n",
    "from tvb_multiscale.tvb_nest.config import *\n",
    "\n",
    "work_path = os.getcwd()\n",
    "outputs_path = os.path.join(work_path, \"outputs/Izhikevich\")\n",
    "sim_mode_path = os.path.join(outputs_path, \"TVBcortex_no_opt\")\n",
    "config = Config(output_base=sim_mode_path)\n",
    "\n",
    "config.figures.SHOW_FLAG = True \n",
    "config.figures.SAVE_FLAG = True\n",
    "config.figures.FIG_FORMAT = 'png'\n",
    "config.figures.DEFAULT_SIZE= config.figures.NOTEBOOK_SIZE\n",
    "FIGSIZE = config.figures.DEFAULT_SIZE\n",
    "\n",
    "data_path = os.path.join(config.DATA_PATH, 'basal_ganglia')\n",
    "fit_data_path = os.path.join(data_path, \"ANNarchyFittedModels/dataFits_2020_02_05/databestfits\", )\n",
    "control_data = os.path.join(fit_data_path, \"controlleft/OutputSim_Patient08.mat\")\n",
    "patient_data = os.path.join(fit_data_path, \"patientleft/OutputSim_Patient09.mat\")\n",
    "\n",
    "if data_mode == \"patient\":\n",
    "    subject_data = patient_data\n",
    "    if INTERFACE_COUPLING_MODE == \"TVB\":\n",
    "        STN_factor = 20.5 * 1e-2  # 0.205 \n",
    "        dSN_factor = 22.2 * 1e-2  # 0.222 \n",
    "        iSN_factor = 20.2 * 1e-2\n",
    "    else:\n",
    "        STN_factor = 30.05 * 1e-2\n",
    "        dSN_factor = 17.64 * 1e-2\n",
    "        iSN_factor = 20.24 * 1e-2\n",
    "else:\n",
    "    subject_data = control_data\n",
    "    if INTERFACE_COUPLING_MODE == \"TVB\":\n",
    "        STN_factor = 20.2 * 1e-2  # 0.202 \n",
    "        dSN_factor = 23.4 * 1e-2  # 0.2340 \n",
    "        iSN_factor = 21.1 * 1e-2  # 0.211 \n",
    "    else:\n",
    "        STN_factor = 24.92 * 1e-2\n",
    "        dSN_factor = 14.9 * 1e-2\n",
    "        iSN_factor = 18.53 * 1e-2\n",
    "\n",
    "simulation_length = 500.0\n",
    "transient = 10.0\n",
    "init_cond_jitter = 0.0\n",
    "\n",
    "SPIKING_NODES_DELAYS = False\n",
    "\n",
    "from tvb_multiscale.core.plot.plotter import Plotter\n",
    "plotter = Plotter(config.figures)\n",
    "\n",
    "# For interactive plotting:\n",
    "# %matplotlib notebook  \n",
    "\n",
    "# Otherwise:\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Load structural data <br> (minimally a TVB connectivity)  <br> & prepare TVB simulator  <br> (region mean field model, integrator, monitors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb_multiscale.core.tvb.cosimulator.models.reduced_wong_wang_exc_io import ReducedWongWangExcIO\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----Uncomment below to modify the simulator by changing the default options:--------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "from tvb.datatypes.connectivity import Connectivity\n",
    "from tvb.simulator.integrators import HeunStochastic\n",
    "from tvb.simulator.monitors import Raw  # , Bold, EEG\n",
    "    \n",
    "\n",
    "# 0. GPe_Left, 1. GPi_Left, 2. STN_Left, 3. Striatum_Left, 4. Thal_Left\n",
    "BG_opt_matrix_weights = np.zeros((5, 5))\n",
    "conn_mode = \"subject\" # subject\" or \"average\"\n",
    "if conn_mode == \"average\":\n",
    "    weights_maith = np.array([1.93, 3.56, 1.46, 4.51, 3.52, 2.30, 2.34, 3.78, 1.98, \n",
    "                             1.30, 1.82, 3.56, 3.02, 1.78, 1.36, 2.27, 4.13, 2.74, 3.27])*1e-3  # controls\n",
    "#     weights_maith = np.array([3.27, 3.80, 2.65, 3.66, 3.06, 3.06, 3.25, 4.02, 3.32, \n",
    "#                             2.98, 3.45, 3.64, 2.50, 2.12, 2.86, 2.79, 3.96, 3.69, 3.87])*1e-3   # patients\n",
    "    # probs_maith = ????\n",
    "else:\n",
    "    import scipy.io as sio\n",
    "    weights=sio.loadmat(subject_data)    # weights start from index 19\n",
    "    weights_maith = weights[\"X\"][0, 19:] # these are indices 19 till 37\n",
    "    probs_maith = weights[\"X\"][0, :19]   # these are indices 0 till 18\n",
    "\n",
    "wdSNGPi = BG_opt_matrix_weights[3, 1] = weights_maith[0].item()\n",
    "wiSNGPe = BG_opt_matrix_weights[3, 0] = weights_maith[1].item()\n",
    "wGPeSTN = BG_opt_matrix_weights[0, 2] = weights_maith[2].item()\n",
    "wSTNGPe = BG_opt_matrix_weights[2, 0] = weights_maith[3].item()\n",
    "wSTNGPi = BG_opt_matrix_weights[2, 1] = weights_maith[4].item()\n",
    "wGPeGPi = BG_opt_matrix_weights[0, 1] = weights_maith[5].item()  \n",
    "wGPiTh = BG_opt_matrix_weights[1, 4] = weights_maith[8].item()\n",
    "wThdSN = BG_opt_matrix_weights[4, 3] = weights_maith[10].item() # Th -> dSN\n",
    "    \n",
    "sliceBGnet = slice(0,5)\n",
    "\n",
    "wGPeGPe = weights_maith[6].item()   # \"GPe\" -> \"GPe\" \n",
    "wGPiGPi = weights_maith[7].item()   # \"GPi\" -> \"GPi\" \n",
    "wThiSN = weights_maith[9].item()    # \"Eth\" -> \"IiSN\" \n",
    "\n",
    "wdSNdSN = weights_maith[11].item()  # \"IdSN\" -> \"IdSN\" \n",
    "wiSNiSN = weights_maith[12].item()  # \"IiSN\" -> \"IiSN\" \n",
    "wCtxdSN = weights_maith[13].item()  # \"CxE\" -> \"IdSN\" \n",
    "wCtxiSN = weights_maith[14].item()  # \"CxE\" -> \"IiSN\" \n",
    "wCtxSTN = weights_maith[15].item()  # \"CxE\" -> \"Estn\"\n",
    "wCtxEtoI = weights_maith[16].item() # \"CxE\" -> \"CxI\"\n",
    "wCtxItoE = weights_maith[17].item() # \"CxI\" -> \"CxE\"\n",
    "wCtxItoI = weights_maith[18].item() # \"CxI\" -> \"CxI\"\n",
    "\n",
    "pdSNGPi = probs_maith[0].item()\n",
    "piSNGPe = probs_maith[1].item()\n",
    "pGPeSTN = probs_maith[2].item()\n",
    "pSTNGPe = probs_maith[3].item()\n",
    "pSTNGPi = probs_maith[4].item()\n",
    "pGPeGPi = probs_maith[5].item()\n",
    "pGPeGPe = probs_maith[6].item()     # \"GPe\" -> \"GPe\" \n",
    "pGPiGPi = probs_maith[7].item()     # \"GPi\" -> \"GPi\" \n",
    "pGPiTh = probs_maith[8].item()\n",
    "pThiSN =  probs_maith[9].item()     # \"Eth\" -> \"IiSN\n",
    "pThdSN = probs_maith[10].item()     # Th --> dSN\n",
    "pdSNdSN = probs_maith[11].item()    # \"IdSN\" -> \"IdSN\" \n",
    "piSNiSN = probs_maith[12].item()    # \"IiSN\" -> \"IiSN\" \n",
    "pCtxdSN = probs_maith[13].item()    # \"CxE\" -> \"IdSN\" \n",
    "pCtxiSN = probs_maith[14].item()    # \"CxE\" -> \"IiSN\" \n",
    "pCtxSTN = probs_maith[15].item()    # \"CxE\" -> \"Estn\"\n",
    "pCtxEtoI = probs_maith[16].item()   # \"CxE\" -> \"CxI\"\n",
    "pCtxItoE = probs_maith[17].item()   # \"CxI\" -> \"CxE\"\n",
    "pCtxItoI = probs_maith[18].item()   # \"CxI\" -> \"CxI\"\n",
    "pCtxCtx = probs_maith[16:19].mean() # \"Ctx\" -> \"Ctx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='pics/Connectome.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full TVB connectome connectivity\n",
    "\n",
    "conn_path = os.path.join(data_path, \"conn\")\n",
    "\n",
    "#Load AAL atlas normative connectome including the Basal Ganglia regions from Petersen et al. atlas\n",
    "wTVB = np.loadtxt(os.path.join(conn_path, \"conn_denis_weights.txt\"))\n",
    "cTVB = np.loadtxt(os.path.join(conn_path, \"aal_plus_BG_centers.txt\"),usecols=range(1,4))\n",
    "rlTVB = np.loadtxt(os.path.join(conn_path, \"aal_plus_BG_centers.txt\"),dtype=\"str\", usecols=(0,))\n",
    "tlTVB = np.loadtxt(os.path.join(conn_path, \"BGplusAAL_tract_lengths.txt\"))\n",
    "\n",
    "# Remove the second Thalamus, Pallidum (GPe/i), Putamen and Caudate (Striatum):\n",
    "inds_Th = (rlTVB.tolist().index(\"Thalamus_L\"), rlTVB.tolist().index(\"Thalamus_R\"))\n",
    "inds_Pall = (rlTVB.tolist().index(\"Pallidum_L\"), rlTVB.tolist().index(\"Pallidum_R\"))\n",
    "inds_Put = (rlTVB.tolist().index(\"Putamen_L\"), rlTVB.tolist().index(\"Putamen_R\"))\n",
    "inds_Caud = (rlTVB.tolist().index(\"Caudate_L\"), rlTVB.tolist().index(\"Caudate_R\"))\n",
    "inds_rm = inds_Th + inds_Pall + inds_Put + inds_Caud\n",
    "print(\"Connections of Thalami, Pallidum (GPe/i), Putamen and Caudate (Striatum) removed!:\\n\", \n",
    "      wTVB[inds_rm, :][:, inds_rm])\n",
    "wTVB = np.delete(wTVB, inds_rm, axis=0)\n",
    "wTVB = np.delete(wTVB, inds_rm, axis=1)\n",
    "tlTVB = np.delete(tlTVB, inds_rm, axis=0)\n",
    "tlTVB = np.delete(tlTVB, inds_rm, axis=1)\n",
    "rlTVB = np.delete(rlTVB, inds_rm, axis=0)\n",
    "cTVB = np.delete(cTVB, inds_rm, axis=0)\n",
    "\n",
    "number_of_regions = len(rlTVB)\n",
    "speed = np.array([4.0])\n",
    "min_tt = speed.item() * 0.1\n",
    "sliceBG = [0, 1, 2, 3, 6, 7]\n",
    "sliceCortex = slice(10, number_of_regions)\n",
    "\n",
    "# Remove BG -> Cortex connections\n",
    "print(\"Removing BG -> Cortex connections with max:\")\n",
    "print(wTVB[sliceCortex, :][:, sliceBG].max())\n",
    "wTVB[sliceCortex, sliceBG] = 0.0\n",
    "tlTVB[sliceCortex, sliceBG] = min_tt\n",
    "\n",
    "# Remove Cortex -> Thalamus connections\n",
    "sliceThal = [8, 9]\n",
    "print(\"Removing Cortex -> Thalamus connections with summed weight:\")\n",
    "print(wTVB[sliceThal, sliceCortex].sum())\n",
    "wTVB[sliceThal, sliceCortex] = 0.0\n",
    "tlTVB[sliceThal, sliceCortex] = min_tt\n",
    "\n",
    "# Remove Cortex -> GPe/i connections\n",
    "sliceGP = [0, 1, 2, 3]\n",
    "print(\"Removing Cortex -> GPe/i connections with max:\")\n",
    "print(wTVB[sliceGP, sliceCortex].max())\n",
    "wTVB[sliceGP,  sliceCortex] = 0.0\n",
    "tlTVB[sliceGP, sliceCortex] = min_tt\n",
    "\n",
    "# # Minimize all delays for the optimized network\n",
    "# tlTVB[:7][:, :7] = min_tt\n",
    "\n",
    "connTVB = Connectivity(region_labels=rlTVB, weights=wTVB, centres=cTVB, tract_lengths=tlTVB, speed=speed)\n",
    "\n",
    "# Normalize connectivity weights\n",
    "connTVB.weights = connTVB.scaled_weights(mode=\"region\")\n",
    "connTVB.weights /= np.percentile(connTVB.weights, 99)\n",
    "\n",
    "# Keep only left hemisphere and remove Vermis:\n",
    "sliceLeft = slice(0, connTVB.number_of_regions -8, 2)\n",
    "\n",
    "connLeft = Connectivity(region_labels=connTVB.region_labels[sliceLeft], \n",
    "                        centres=connTVB.centres[sliceLeft],\n",
    "                        weights=connTVB.weights[sliceLeft][:, sliceLeft],\n",
    "                        tract_lengths=connTVB.tract_lengths[sliceLeft][:, sliceLeft], \n",
    "                        speed=connTVB.speed)\n",
    "connLeft.configure()\n",
    "\n",
    "print(\"\\nLeft cortex connectome, after removing direct BG -> Cortex and intehemispheric BG <-> BG connections:\")\n",
    "plotter.plot_tvb_connectivity(connLeft);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliceBGnet = slice(0,5)\n",
    "connTVBleftBG = Connectivity(region_labels=connLeft.region_labels[sliceBGnet], \n",
    "                             centres=connLeft.centres[sliceBGnet],\n",
    "                             weights=connLeft.weights[sliceBGnet][:, sliceBGnet],\n",
    "                             tract_lengths=connLeft.tract_lengths[sliceBGnet][:, sliceBGnet], \n",
    "                            speed=connLeft.speed)\n",
    "connTVBleftBG.configure()\n",
    "\n",
    "print(\"\\nLeft BG TVB network:\")\n",
    "plotter.plot_tvb_connectivity(connTVBleftBG);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleBGoptTOtvb = np.percentile(BG_opt_matrix_weights, 95) /\\\n",
    "                  np.percentile(connTVBleftBG.weights, 95)\n",
    "                  \n",
    "print(\"Scaling factor of TVB BG network connectome to optimal one = %g\" % scaleBGoptTOtvb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the final connectivity to use for simulation:\n",
    "# Rescale the \n",
    "ww = scaleBGoptTOtvb * np.array(connLeft.weights)\n",
    "ww[sliceBGnet, sliceBGnet] = BG_opt_matrix_weights.T  # !!!NOTE TVB indices convention Wi<-j!!!\n",
    "\n",
    "connectivity = Connectivity(region_labels=connLeft.region_labels, \n",
    "                            centres=connLeft.centres,\n",
    "                            weights=ww, tract_lengths=connLeft.tract_lengths, \n",
    "                            speed=connLeft.speed)\n",
    "connectivity.configure()\n",
    "\n",
    "# Construct only the optimized BG connectivity only for plotting:\n",
    "connBGopt = Connectivity(region_labels=connectivity.region_labels[sliceBGnet], \n",
    "                         centres=connectivity.centres[sliceBGnet],\n",
    "                         weights=connectivity.weights[sliceBGnet][:, sliceBGnet],\n",
    "                         tract_lengths=connectivity.tract_lengths[sliceBGnet][:, sliceBGnet], \n",
    "                         speed=connectivity.speed)\n",
    "connBGopt.configure()\n",
    "\n",
    "print(\"\\nLeft BG optimized network:\")\n",
    "plotter.plot_tvb_connectivity(connBGopt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb_multiscale.core.tvb.cosimulator.cosimulator_serial import CoSimulatorSerial as CoSimulator\n",
    "\n",
    "#white_matter_coupling = coupling.Linear(a=0.014)\n",
    "# Create a TVB simulator and set all desired inputs\n",
    "# (connectivity, model, surface, stimuli etc)\n",
    "# We choose all defaults in this example\n",
    "simulator = CoSimulator()\n",
    "#simulator.use_numba = False\n",
    "model_params = {\"G\": np.array([15.0/scaleBGoptTOtvb])}\n",
    "simulator.model = ReducedWongWangExcIO(**model_params)\n",
    "\n",
    "simulator.connectivity = connectivity\n",
    "\n",
    "simulator.integrator = HeunStochastic()\n",
    "simulator.integrator.dt = 0.1\n",
    "simulator.integrator.noise.nsig = np.array([1e-4])  # 1e-5\n",
    "\n",
    "mon_raw = Raw(period=1.0)  # ms\n",
    "simulator.monitors = (mon_raw, )\n",
    "\n",
    "init_cond_filepath = os.path.join(data_path, \"tvb_init_cond_left.npy\")\n",
    "init_cond = np.load(init_cond_filepath)   # \n",
    "init_cond = np.abs(init_cond *(1 + init_cond_jitter * np.random.normal(size=init_cond.shape)))\n",
    "simulator.connectivity.set_idelays(simulator.integrator.dt)\n",
    "simulator.initial_conditions = init_cond * np.ones((simulator.connectivity.idelays.max(),\n",
    "                                                    simulator.model.nvar,\n",
    "                                                    simulator.connectivity.number_of_regions,\n",
    "                                                    simulator.model.number_of_modes))\n",
    "\n",
    "simulator.configure()\n",
    "\n",
    "\n",
    "print(\"\\nConnectome used for simulations:\")\n",
    "plotter.plot_tvb_connectivity(simulator.connectivity);\n",
    "\n",
    "\n",
    "# # Serializing TVB cosimulator is necessary for parallel cosimulation:\n",
    "# from tvb_multiscale.core.utils.file_utils import dump_pickled_dict\n",
    "# from tvb_multiscale.core.tvb.cosimulator.cosimulator_serialization import serialize_tvb_cosimulator\n",
    "# sim_serial_filepath = os.path.join(config.out.FOLDER_RES, \"tvb_serial_cosimulator.pkl\")\n",
    "# sim_serial = serialize_tvb_cosimulator(simulator)\n",
    "# display(sim_serial)\n",
    "\n",
    "# # Dumping the serialized TVB cosimulator to a file will be necessary for parallel cosimulation.\n",
    "# dump_pickled_dict(sim_serial, sim_serial_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(Image(filename='pics/Network.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build and connect the NEST network model <br> (networks of spiking neural populations for fine-scale <br>regions, stimulation devices, spike detectors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:10.862262Z",
     "start_time": "2019-07-12T20:36:10.000332Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tvb_multiscale.tvb_nest.nest_models.models.basal_ganglia_izhikevich import BasalGangliaIzhikevichBuilder\n",
    "\n",
    "# Build a NEST network model with the corresponding builder\n",
    "from tvb_multiscale.tvb_nest.nest_models.builders.nest_factory import load_nest, configure_nest_kernel\n",
    "\n",
    "# Load NEST and use defaults to configure its kernel:\n",
    "nest = configure_nest_kernel(load_nest(config=config), config)\n",
    "\n",
    "# Select the regions for the fine scale modeling with NEST spiking networks\n",
    "number_of_regions = simulator.connectivity.region_labels.shape[0]\n",
    "#including cortex node:\n",
    "nest_nodes_ids = [0, 1, 2, 3, 4]  #, 5 the indices of fine scale regions modeled with NEST\n",
    "\n",
    "# Build a NEST network model with the corresponding builder\n",
    "nest_model_builder = BasalGangliaIzhikevichBuilder(tvb_simulator=simulator,\n",
    "                                                    spiking_nodes_inds=nest_nodes_ids,\n",
    "                                                    spiking_simulator=nest,\n",
    "                                                    config=config\n",
    "                                                  )\n",
    "\n",
    "# Using all default parameters for this example\n",
    "# nest_model_builder.set_defaults()\n",
    "\n",
    "# or modify the builder by changing the default options:--------------------------------------\n",
    "\n",
    "population_neuron_model = \"izhikevich_hamker\"\n",
    "\n",
    "nest_model_builder.population_order = 200 # reduce for speed\n",
    "\n",
    "# When any of the properties model, params and scale below depends on regions,\n",
    "# set a handle to a function with\n",
    "# arguments (region_index=None) returning the corresponding property\n",
    "\n",
    "from copy import deepcopy\n",
    "nest_model_builder.params_common = \\\n",
    "    {\"V_m\": -70.0, \"U_m\": -18.55, \"E_rev_AMPA\": 0.0, \"E_rev_GABA_A\": -90.0, \"V_th\": 30.0, \"V_r\": 0.0, \"c\": -65.0,\n",
    "     \"C_m\": 1.0, \"I_e\": 0.0, \"current_stimulus_scale\": -200, \"current_stimulus_mode\": 2,\n",
    "     \"tau_rise\": 1.0, # doesn't seem to have any effect\n",
    "     \"tau_rise_AMPA\": 10.0, \"tau_rise_GABA_A\": 10.0,\n",
    "     \"n0\": 140.0, \"n1\": 5.0, \"n2\": 0.04}\n",
    "\n",
    "nest_model_builder._paramsI = deepcopy(nest_model_builder.params_common)\n",
    "nest_model_builder._paramsI.update({\"a\": 0.005, \"b\": 0.585, \"d\": 4.0})\n",
    "nest_model_builder._paramsE = deepcopy(nest_model_builder.params_common)\n",
    "nest_model_builder.paramsStr = deepcopy(nest_model_builder.params_common)\n",
    "nest_model_builder.paramsStr.update({\"V_th\": 40.0, \"C_m\": 50.0, \"V_r\": -80.0,\n",
    "                                     \"n0\": 61.65119, \"n1\": 2.594639, \"n2\": 0.022799, \n",
    "                                     \"a\": 0.05, \"b\": -20.0, \"c\": -55.0, \"d\": 377.0})\n",
    "\n",
    "nest_model_builder.Igpe_nodes_ids = [0]\n",
    "nest_model_builder.Igpi_nodes_ids = [1]\n",
    "nest_model_builder.Estn_nodes_ids = [2]\n",
    "nest_model_builder.Eth_nodes_ids = [4]\n",
    "nest_model_builder.Istr_nodes_ids = [3]\n",
    "\n",
    "I_nodes_ids = nest_model_builder.Igpe_nodes_ids + nest_model_builder.Igpi_nodes_ids \n",
    "E_nodes_ids = nest_model_builder.Estn_nodes_ids + nest_model_builder.Eth_nodes_ids \n",
    "\n",
    "\n",
    "def paramsE_fun(node_id):\n",
    "    paramsE = deepcopy(nest_model_builder._paramsE)\n",
    "    if node_id in nest_model_builder.Estn_nodes_ids:\n",
    "        paramsE.update({\"a\": 0.005, \"b\": 0.265, \"d\": 2.0, \"I_e\": 3.0})  # dictionary of params for Estn\n",
    "    elif node_id in nest_model_builder.Eth_nodes_ids:\n",
    "        paramsE.update({\"a\": 0.02, \"b\": 0.25, \"d\": 0.05, \"I_e\": 3.5}) # dictionary of params for Eth\n",
    "    return paramsE\n",
    "    \n",
    "def paramsI_fun(node_id):\n",
    "    # For the moment they are identical, unless you differentiate the noise parameters\n",
    "    paramsI = deepcopy(nest_model_builder._paramsI)\n",
    "    if node_id in nest_model_builder.Igpe_nodes_ids:\n",
    "        paramsI.update({\"I_e\": 12.0})  # 12.0\n",
    "    elif node_id in nest_model_builder.Igpi_nodes_ids:\n",
    "        paramsI.update({\"I_e\": 30.0})  # 30.0\n",
    "    return paramsI\n",
    "    \n",
    "# Populations' configurations\n",
    "# When any of the properties model, params and scale below depends on regions,\n",
    "# set a handle to a function with\n",
    "# arguments (region_index=None) returning the corresponding property\n",
    "nest_model_builder.populations = [\n",
    "    {\"label\": \"E\", \"model\": population_neuron_model,  \n",
    "     \"params\":  paramsE_fun, \n",
    "     \"nodes\": E_nodes_ids,  # Estn in [2], Eth in [4], Cortex in [5]\n",
    "     \"scale\": 1.0}, # lambda node_id: 3.0 if node_id in nest_model_builder.Crtx_nodes_ids else \n",
    "    {\"label\": \"I\", \"model\": population_neuron_model,  \n",
    "     \"params\": paramsI_fun, \n",
    "     \"nodes\": I_nodes_ids,  # Igpe in [0], Igpi in [1], Cortex in [5]\n",
    "     \"scale\": 1.0}, # lambda node_id: 0.75 if node_id in nest_model_builder.Crtx_nodes_ids else \n",
    "    {\"label\": \"IdSN\", \"model\": population_neuron_model,   \n",
    "     \"params\": nest_model_builder.paramsStr, \n",
    "     \"nodes\": nest_model_builder.Istr_nodes_ids,  # IdSN in [3]\n",
    "     \"scale\": 1.0},\n",
    "    {\"label\": \"IiSN\", \"model\": population_neuron_model,   # IiSN in [3]\n",
    "     \"params\": nest_model_builder.paramsStr, \n",
    "     \"nodes\": nest_model_builder.Istr_nodes_ids,  # None means \"all\"\n",
    "     \"scale\": 1.0}\n",
    "]\n",
    "\n",
    "# Within region-node connections\n",
    "# When any of the properties model, conn_spec, weight, delay, receptor_type below\n",
    "# set a handle to a function with\n",
    "# arguments (region_index=None) returning the corresponding property\n",
    "\n",
    "synapse_model = \"static_synapse\"\n",
    "conn_spec = {\"allow_autapses\": True, \"allow_multapses\": True, \"rule\": \"all_to_all\"}\n",
    "\n",
    "def conn_spec_fixed_prob(prob=None):\n",
    "    output = conn_spec.copy()\n",
    "    if prob is not None:\n",
    "        output[\"rule\"] = \"fixed_total_number\"\n",
    "        output[\"p\"] = prob\n",
    "    return output\n",
    "\n",
    "within_node_delay = 1.0\n",
    "\n",
    "# for each connection, we have a different probability\n",
    "nest_model_builder.populations_connections = [\n",
    "     #        source   ->   target\n",
    "    {\"source\": \"I\", \"target\": \"I\",  # I -> I This is a self-connection for population \"Igpe\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pGPeGPe),  # conn_spec\n",
    "     \"weight\": -np.abs(wGPeGPe).item(), \"delay\": within_node_delay,\n",
    "     \"nodes\": nest_model_builder.Igpe_nodes_ids},  # None means apply to all\n",
    "    {\"source\": \"I\", \"target\": \"I\",  # I -> I This is a self-connection for population \"Igpi\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pGPiGPi),  # conn_spec\n",
    "     \"weight\": -np.abs(wGPiGPi).item(), \"delay\": within_node_delay,\n",
    "     \"nodes\": nest_model_builder.Igpi_nodes_ids},  # None means apply to all\n",
    "    {\"source\": \"IdSN\", \"target\": \"IdSN\",  # IdSN -> IdSN This is a self-connection for population \"IdSN\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(pdSNdSN),  # conn_spec\n",
    "     \"weight\": -np.abs(wdSNdSN).item(), \"delay\": within_node_delay,\n",
    "       \"nodes\": nest_model_builder.Istr_nodes_ids},\n",
    "    {\"source\": \"IiSN\", \"target\": \"IiSN\",  # IiSN -> IiSN This is a self-connection for population \"IiSN\"\n",
    "     \"synapse_model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(piSNiSN),  # conn_spec\n",
    "     \"weight\": -np.abs(wiSNiSN).item(), \"delay\": within_node_delay,\n",
    "     \"nodes\": nest_model_builder.Istr_nodes_ids},\n",
    "    ]\n",
    "\n",
    "\n",
    "# Among/Between region-node connections\n",
    "# Given that only the AMPA population of one region-node couples to\n",
    "# all populations of another region-node,\n",
    "# we need only one connection type\n",
    "        \n",
    "# When any of the properties model, conn_spec, weight, delay, receptor_type below\n",
    "# depends on regions, set a handle to a function with\n",
    "# arguments (source_region_index=None, target_region_index=None)\n",
    "\n",
    "from tvb_multiscale.core.spiking_models.builders.templates import scale_tvb_weight, tvb_delay\n",
    "\n",
    "# We set global coupling scaling to 1.0,\n",
    "# because we need the Maith et al optimized weights without any scaling:\n",
    "nest_model_builder.global_coupling_scaling = 1.0\n",
    "        \n",
    "# Function that will return the TVB weight with optional scaling:\n",
    "class TVBWeightFun(object):\n",
    "    tvb_weights = nest_model_builder.tvb_weights\n",
    "    global_coupling_scaling = nest_model_builder.global_coupling_scaling\n",
    "    sign = 1\n",
    "\n",
    "    def __init__(self, sign=1, scale=nest_model_builder.global_coupling_scaling):\n",
    "        self.sign = sign\n",
    "        self.global_coupling_scaling = scale * self.sign\n",
    "        \n",
    "    def __call__(self, source_node, target_node):\n",
    "        return scale_tvb_weight(source_node, target_node, self.tvb_weights,\n",
    "                                scale=self.global_coupling_scaling)\n",
    "    \n",
    "# Function that will return the TVB delay unless SPIKING_NODES_DELAYS == False:\n",
    "tvb_delay_fun = \\\n",
    "    lambda source_node, target_node: \\\n",
    "        np.maximum(nest_model_builder.tvb_dt, \n",
    "                   tvb_delay(source_node, target_node, nest_model_builder.tvb_delays)) \\\n",
    "            if SPIKING_NODES_DELAYS else within_node_delay\n",
    "\n",
    "def nodes_conn(src_pop, trg_pop, src_nodes, trg_nodes, sign, prob, weight=None):\n",
    "    if weight is None:\n",
    "        weight = TVBWeightFun(sign)\n",
    "    else:\n",
    "        weight *= sign\n",
    "\n",
    "    return {\n",
    "        \"source\": src_pop, \"target\": trg_pop,\n",
    "        \"model\": synapse_model, \"conn_spec\": conn_spec_fixed_prob(prob),  # conn_spec\n",
    "        \"weight\": weight,\n",
    "        \"delay\": lambda source_node, target_node: tvb_delay_fun(source_node, target_node),\n",
    "        \"source_nodes\": src_nodes,\n",
    "        \"target_nodes\": trg_nodes}\n",
    "\n",
    "Istr_nodes = nest_model_builder.Istr_nodes_ids\n",
    "Igpi_nodes = nest_model_builder.Igpi_nodes_ids\n",
    "Igpe_nodes = nest_model_builder.Igpe_nodes_ids\n",
    "Eth_nodes = nest_model_builder.Eth_nodes_ids\n",
    "Estn_nodes = nest_model_builder.Estn_nodes_ids\n",
    "\n",
    "ampa = 1\n",
    "gaba = -1\n",
    "\n",
    "nest_model_builder.nodes_connections = [\n",
    "    nodes_conn(\"IdSN\", \"I\",             # \"IdSN\" -> \"Igpi\"\n",
    "               Istr_nodes, Igpi_nodes,\n",
    "               gaba, pdSNGPi),\n",
    "    nodes_conn(\"IiSN\", \"I\",             # \"IiSN\" -> \"Igpe\"\n",
    "               Istr_nodes, Igpe_nodes,\n",
    "               gaba, piSNGPe),\n",
    "    nodes_conn(\"I\", \"I\",                # \"Igpe\" -> \"Igpi\"\n",
    "               Igpe_nodes, Igpi_nodes,\n",
    "               gaba, pGPeGPi),\n",
    "    nodes_conn(\"I\", \"E\",                # \"Igpi\" -> \"Eth\"\n",
    "               Igpi_nodes, Eth_nodes,\n",
    "               gaba, pGPiTh),\n",
    "    nodes_conn(\"I\", \"E\",                # \"Igpe\" -> \"Estn\"\n",
    "               Igpe_nodes, Estn_nodes,\n",
    "               gaba, pGPeSTN),\n",
    "    nodes_conn(\"E\", \"IdSN\",             # \"Eth\" -> \"IdSN\"\n",
    "               Eth_nodes, Istr_nodes,\n",
    "               ampa, pThdSN, wThdSN),\n",
    "    nodes_conn(\"E\", \"IiSN\",             # \"Eth\" -> \"IiSN\"\n",
    "               Eth_nodes, Istr_nodes,\n",
    "               ampa, pThiSN, wThiSN),\n",
    "    nodes_conn(\"E\", \"I\",                # \"Estn\" -> \"Igpe\"\n",
    "               Estn_nodes, Igpe_nodes,\n",
    "               ampa, pSTNGPe),\n",
    "    nodes_conn(\"E\", \"I\",                # \"Estn\" -> \"Igpi\"\n",
    "               Estn_nodes, Igpi_nodes,\n",
    "               ampa, pSTNGPi),\n",
    "]\n",
    "\n",
    "\n",
    "# Creating  devices to be able to observe NEST activity:\n",
    "\n",
    "nest_model_builder.output_devices = []\n",
    "\n",
    "#          label <- target population\n",
    "for pop in nest_model_builder.populations:\n",
    "    connections = OrderedDict({})\n",
    "    connections[pop[\"label\"] + \"_spikes\"] = pop[\"label\"]\n",
    "    nest_model_builder.output_devices.append(\n",
    "        {\"model\": \"spike_recorder\", \"params\": {\"record_to\": \"memory\"},\n",
    "         \"connections\": connections, \"nodes\": pop[\"nodes\"]})  # None means apply to \"all\"\n",
    "\n",
    "# Labels have to be different\n",
    "\n",
    "connections = OrderedDict({})\n",
    "#               label    <- target population\n",
    "params = {\"interval\": 1.0, \"record_to\": \"memory\",\n",
    "          'record_from': [\"V_m\", \"U_m\", \"I\", \"I_syn\", \"I_syn_ex\", \"I_syn_in\", \"g_AMPA\", \"g_GABA_A\", \"g_L\"]}\n",
    "for pop in nest_model_builder.populations:\n",
    "    connections = OrderedDict({})\n",
    "    connections[pop[\"label\"]] = pop[\"label\"]\n",
    "    nest_model_builder.output_devices.append(\n",
    "        {\"model\": \"multimeter\", \"params\": params,\n",
    "         \"connections\": connections, \"nodes\": pop[\"nodes\"]})  # None means apply to all\n",
    "    \n",
    "    \n",
    "\n",
    "#Create a spike stimulus input device\n",
    "# #including cortex node: we do not need any other external stimulation\n",
    "# nest_model_builder.Estn_stim = {\"rate\": 500.0, \"weight\": 0.009}\n",
    "# nest_model_builder.Igpe_stim = {\"rate\": 100.0, \"weight\": 0.015}\n",
    "# nest_model_builder.Igpi_stim = {\"rate\": 700.0, \"weight\": 0.02}\n",
    "nest_model_builder.input_devices = [\n",
    "#     {\"model\": \"poisson_generator\",\n",
    "#      \"params\": {\"rate\": nest_model_builder.Estn_stim[\"rate\"], \"origin\": 0.0, \"start\": 0.1},\n",
    "#      \"connections\": {\"BaselineEstn\": [\"E\"]},  # \"Estn\"\n",
    "#      \"nodes\": nest_model_builder.Estn_nodes_ids,  # \"Estn\"\n",
    "#      \"weights\": nest_model_builder.Estn_stim[\"weight\"], \"delays\": 0.0, \"receptor_type\": 1},\n",
    "#     {\"model\": \"poisson_generator\",\n",
    "#      \"params\": {\"rate\": nest_model_builder.Igpe_stim[\"rate\"], \"origin\": 0.0, \"start\": 0.1},\n",
    "#      \"connections\": {\"BaselineIgpe\": [\"I\"]},  # \"Igpe\"\n",
    "#      \"nodes\": nest_model_builder.Igpe_nodes_ids,  # \"Igpe\"\n",
    "#      \"weights\": nest_model_builder.Igpe_stim[\"weight\"], \"delays\": 0.0, \"receptor_type\": 1},\n",
    "#     {\"model\": \"poisson_generator\",\n",
    "#      \"params\": {\"rate\": nest_model_builder.Igpi_stim[\"rate\"], \"origin\": 0.0, \"start\": 0.1},\n",
    "#      \"connections\": {\"BaselineIgpi\": [\"I\"]},  # \"Igpi\"\n",
    "#      \"nodes\": nest_model_builder.Igpi_nodes_ids,  ## \"Igpi\"\n",
    "#      \"weights\": nest_model_builder.Igpi_stim[\"weight\"], \"delays\": 0.0, \"receptor_type\": 1},\n",
    "#      {\"model\": \"dc_generator\",\n",
    "#      \"params\": { \"amplitude\": 1.0, #\"frequency\": 20.0, \"phase\": 0.0,\"offset\": 0.0,\n",
    "#                 \"start\": 35.0, \"stop\": 85.0 },  # \"stop\": 100.0  \"origin\": 0.0, \n",
    "#      \"connections\": {\"DBS_GPi\": [\"I\"]}, # \"GPi\"\n",
    "#      \"nodes\": nest_model_builder.Igpi_nodes_ids, # \"GPi\"\n",
    "#      \"weights\": 1.0, \"delays\": 0.0}\n",
    "#     {\"model\": \"dc_generator\",\n",
    "#      \"params\": { \"amplitude\": 1.0, #\"frequency\": 20.0, \"phase\": 0.0,\"offset\": 0.0,\n",
    "#                 \"start\": 35.0, \"stop\": 85.0 },  # \"stop\": 100.0  \"origin\": 0.0, \n",
    "#      \"connections\": {\"DBS_STN\": [\"E\"]}, # \"STN\"\n",
    "#      \"nodes\": nest_model_builder.Estn_nodes_ids, # \"STN\"\n",
    "#      \"weights\": 1.0, \"delays\": 0.0}\n",
    "       ]  #\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "nest_model_builder.configure()\n",
    "nest_network = nest_model_builder.build(set_defaults=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "populations_sizes = []\n",
    "print(\"Population sizes: \")\n",
    "for pop in nest_model_builder.populations:\n",
    "    populations_sizes.append(int(np.round(pop[\"scale\"] * nest_model_builder.population_order)))\n",
    "    print(\"%s: %d\" % (pop[\"label\"], populations_sizes[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:19:09.725185Z",
     "start_time": "2019-07-11T10:19:09.721072Z"
    }
   },
   "source": [
    "## 3. Build the TVB-NEST interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:11.137992Z",
     "start_time": "2019-07-12T20:36:10.880947Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tvb_multiscale.tvb_nest.interfaces.models.basal_ganglia_izhikevich import BasalGangliaIzhikevichTVBNESTInterfaceBuilder\n",
    "from tvb_multiscale.tvb_nest.interfaces.builders import NESTInputProxyModels\n",
    "\n",
    "\n",
    "# Build a TVB-NEST interface with all the appropriate connections between the\n",
    "# TVB and NEST modelled regions\n",
    "tvb_nest_builder = BasalGangliaIzhikevichTVBNESTInterfaceBuilder()\n",
    "# (simulator, nest_network, nest_nodes_ids, exclusive_nodes=True,populations_sizes=populations_sizes)\n",
    "\n",
    "tvb_nest_builder.config = config\n",
    "tvb_nest_builder.tvb_cosimulator = simulator\n",
    "tvb_nest_builder.spiking_network = nest_network\n",
    "\n",
    "\n",
    "STN_proxy_inds = np.array(nest_model_builder.Estn_nodes_ids)\n",
    "Striatum_proxy_inds = np.array(nest_model_builder.Istr_nodes_ids)\n",
    "\n",
    "# Set exclusive_nodes = True (Default) if the spiking regions substitute for the TVB ones:\n",
    "tvb_nest_builder.exclusive_nodes = True \n",
    "\n",
    "\n",
    "tvb_to_nest_mode = \"rate\"\n",
    "nest_to_tvb = True\n",
    "\n",
    "# If default_coupling_mode = \"TVB\", large scale coupling towards spiking regions is computed in TVB\n",
    "# and then applied with no time delay via a single \"TVB proxy node\" / NEST device for each spiking region,\n",
    "# \"1-to-1\" TVB->NEST coupling.\n",
    "# If any other value, we need 1 \"TVB proxy node\" / NEST device for each TVB sender region node, and\n",
    "# large-scale coupling for spiking regions is computed in NEST, \n",
    "# taking into consideration the TVB connectome weights and delays, \n",
    "# in this \"1-to-many\" TVB->NEST coupling.\n",
    "tvb_nest_builder.default_coupling_mode = INTERFACE_COUPLING_MODE # \"spikeNet\" # \"TVB\"\n",
    "\n",
    "tvb_nest_builder.proxy_inds = np.array(nest_nodes_ids)\n",
    "tvb_nest_builder.N_E = nest_model_builder.population_order\n",
    "\n",
    "# TVB applies a global coupling scaling of coupling.a * model.G\n",
    "tvb_nest_builder.global_coupling_scaling = \\\n",
    "    tvb_nest_builder.tvb_cosimulator.coupling.a[0].item() * tvb_nest_builder.G\n",
    "print(\"global_coupling_scaling = %g\" % tvb_nest_builder.global_coupling_scaling)\n",
    "\n",
    "# Optionally adjust interface scale factors here \n",
    "# to have the same result counter act possible changes to G and coupling.a:\n",
    "STN_factor /= tvb_nest_builder.global_coupling_scaling\n",
    "dSN_factor /= tvb_nest_builder.global_coupling_scaling\n",
    "iSN_factor /= tvb_nest_builder.global_coupling_scaling\n",
    "\n",
    "# Total TVB indegree weight to STN:\n",
    "wTVBSTNs = simulator.connectivity.weights[nest_model_builder.Estn_nodes_ids, 5:].squeeze()\n",
    "wTVBSTN = wTVBSTNs.sum().item()\n",
    "print(\"wTVBSTN = %g\" % wTVBSTN)\n",
    "CTXtoSTNinds = 5 + np.where(wTVBSTNs > 0.0)[0] # indices of TVB regions coupling to STN\n",
    "\n",
    "# Total TVB indegree weight to Striatum:\n",
    "wTVBSNs = simulator.connectivity.weights[nest_model_builder.Istr_nodes_ids, 5:].squeeze()\n",
    "wTVBSN = wTVBSNs.sum().item()\n",
    "print(\"wTVBSN = %g\" % wTVBSN)\n",
    "CTXtoSNinds = 5 + np.where(wTVBSNs > 0.0)[0]  # indices of TVB regions coupling to Striatum\n",
    "\n",
    "# Using all default parameters for this example\n",
    "\n",
    "# or...\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----Uncomment below to modify the builder by changing the default options:--------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------For spike transmission from TVB to NEST devices acting as TVB proxy nodes with TVB delays:--------\n",
    "\n",
    "\n",
    "# TVB -> NEST\n",
    "\n",
    "\n",
    "if tvb_nest_builder.default_coupling_mode == \"spikeNet\":\n",
    "    \n",
    "    # If coupling is computing in NEST, we need as many TVB proxies \n",
    "    # as TVB regions coupling to STN and Striatum\n",
    "    proxy_inds = np.unique(np.concatenate([CTXtoSTNinds, CTXtoSNinds]))\n",
    "    \n",
    "    # This is the TVB coupling weight function that will determine the connections' weights \n",
    "    # from TVB proxies to the target STN and dSN/iSN populations:\n",
    "    class TVBWeightFunInterface(object):\n",
    "    \n",
    "        def __init__(self, scaling):\n",
    "            self.scaling = float(scaling)\n",
    "\n",
    "        def __call__(self, source_node, target_node, tvb_weights):\n",
    "            return (scale_tvb_weight(source_node, target_node, tvb_weights, scale=self.scaling))\n",
    "\n",
    "tvb_nest_builder.output_interfaces = []\n",
    "if tvb_to_nest_mode == \"rate\":\n",
    "    # Mean spike rates are applied in parallel to all target neurons\n",
    "    for trg_pop, target_nodes, conn_scaling, this_conn_spec, scale_factor in \\\n",
    "                                    zip([\"E\", \"IdSN\", \"IiSN\"], # NEST target populations,\n",
    "                                     [STN_proxy_inds, Striatum_proxy_inds, Striatum_proxy_inds],\n",
    "                                     [wCtxSTN, wCtxdSN, wCtxiSN], # ...weights\n",
    "                                     # ...and probabilities for CTX -> STN/Striatum connections\n",
    "                                     [conn_spec_fixed_prob(prob=pCtxSTN),  # pCtxSTN  \n",
    "                                      conn_spec_fixed_prob(prob=pCtxdSN),  # pCtxdSN\n",
    "                                      conn_spec_fixed_prob(prob=pCtxiSN)], # pCtxiSN\n",
    "                                     # Interface scaling factors scaled by TVB weights' indegree to STN/Striatum:\n",
    "                                     [STN_factor/wTVBSTN, dSN_factor/wTVBSN, iSN_factor/wTVBSN]\n",
    "                                     ): # Indices of target region modelled in NEST:\n",
    "        tvb_nest_builder.output_interfaces.append(\n",
    "            {\"voi\": np.array([\"R\"]), #  Source TVB state variable\n",
    "             \"populations\": np.array([trg_pop]), # NEST target population\n",
    "             \"model\": \"RATE\",\n",
    "             \"spiking_proxy_inds\": target_nodes, # Target region indices in NEST\n",
    "             \"proxy_model\": NESTInputProxyModels.RATE,\n",
    "             \"proxy_params\": {\n",
    "                \"allow_offgrid_times\": False\n",
    "             },\n",
    "             \"conn_spec\": this_conn_spec,\n",
    "             \"coupling_mode\": tvb_nest_builder.default_coupling_mode\n",
    "        })\n",
    "\n",
    "        # For both coupling modes, we scale the TVB rate already at the TVB -> NEST transformer\n",
    "        # with the interface scale factor (normalized by TVB indegree to STN/Striatum)\n",
    "        # and the global coupling scaling.\n",
    "        this_interface = tvb_nest_builder.output_interfaces[-1]\n",
    "        if this_interface[\"coupling_mode\"] == \"spikeNet\":\n",
    "            this_interface[\"proxy_inds\"] = proxy_inds\n",
    "            # In this case connections from each TVB proxy to STN/Striatum \n",
    "            # are scaled additionally with the Maith et al. optimized weights\n",
    "            this_interface[\"weights\"] = TVBWeightFunInterface(conn_scaling)\n",
    "            this_interface[\"transformer_params\"] = \\\n",
    "                {\"scale_factor\": scale_factor * tvb_nest_builder.global_coupling_scaling}\n",
    "            # In total:\n",
    "            # From each TVB proxy node we get a rate scaled as (\n",
    "            # (coupling.a * G * STN_factor/wTVBSTN) * R_i, (i for all TVB regions)\n",
    "            # Then, spikes generated from each TVB proxy are transferred via connections \n",
    "            # with weights TVB_w_ji * wCtxSTN or wCtxiSN or wCtxdSN (j for STN or Striatum) \n",
    "            # and probabilities pCtxSTN or pCtxiSN or pCtxdSN, respectively\n",
    "        else:\n",
    "            # In this case connections from each TVB proxy to STN/Striatum \n",
    "            # are equal to the Maith et al. optimized weights\n",
    "            this_interface[\"weights\"] = conn_scaling\n",
    "            # In this case coupling.a is already applied during computing TVB coupling.\n",
    "            # Therefore we scale only with model.G\n",
    "            this_interface[\"transformer_params\"] = \\\n",
    "                {\"scale_factor\": scale_factor * tvb_nest_builder.G}\n",
    "            # In total:\n",
    "            # From each TVB proxy node we get a total coupling rate scaled \n",
    "            # as (coupling.a * G STN_factor/wTVBSTN) * R_j, (j for STN or Striatum)\n",
    "            # Then, spikes generated from each TVB proxy are transferred via connections \n",
    "            # with weights wCtxSTN or wCtxiSN or wCtxdSN and \n",
    "            # probabilities pCtxSTN or pCtxiSN or pCtxdSN, respectively\n",
    "\n",
    "if nest_to_tvb:\n",
    "    tvb_nest_builder.input_interfaces = []\n",
    "    # TVB <-- NEST:\n",
    "\n",
    "    from tvb_multiscale.core.interfaces.transformers.models.red_wong_wang import ElephantSpikesRateRedWongWangExc\n",
    "\n",
    "    for src_pop, nodes, in zip(\n",
    "                    # Source populations in NEST:\n",
    "                    [np.array([\"I\"]),  np.array([\"E\"]), np.array([\"IdSN\", \"IiSN\"])],\n",
    "                    # Source regions indices in NEST:\n",
    "                    [I_nodes_ids,          # GPe and GPi\n",
    "                    E_nodes_ids,          # STN and Thalamus\n",
    "                    Striatum_proxy_inds]): # Striatum\n",
    "            #            TVB <- NEST\n",
    "            tvb_nest_builder.input_interfaces.append(\n",
    "                {\"voi\": np.array([\"S\", \"R\"]),  # Target state variables in TVB\n",
    "                \"populations\": src_pop,  # Source populations in NEST\n",
    "                # This transformer not only converts spike counts to rates for state variable R,\n",
    "                # but also integrates the dS/dt to compute the respective S!:\n",
    "                \"transformer\": ElephantSpikesRateRedWongWangExc,\n",
    "                \"transformer_params\": \n",
    "                    # Spike counts are converted to rates via:\n",
    "                    # number_of_spikes / number_of_neurons_per_population / number_of_populations\n",
    "                    # (mind that there are 2 populations in Striatum)\n",
    "                    {\"scale_factor\": np.array([1.0]) / tvb_nest_builder.N_E / len(src_pop),\n",
    "                    # The integrator used to integrate dS/dt\n",
    "                    \"integrator\":CONFIGURED.DEFAULT_TRANSFORMER_INTEGRATOR_MODEL(\n",
    "                                        dt=simulator.integrator.dt),\n",
    "                        \"state\": np.zeros((2, len(nodes))), # initial condition\n",
    "                        # Parameters of the dS/dt differential equation:\n",
    "                        \"tau_s\": simulator.model.tau_s, # time constant of integrating S\n",
    "                        \"tau_r\": np.array([10.0]),      # time constant of integrating R to low pass filter it\n",
    "                        \"gamma\": simulator.model.gamma}, \n",
    "                \"proxy_inds\": np.array(nodes)})  # None means all here\n",
    "\n",
    "tvb_nest_builder.w_tvb_to_spike_rate = 1.0\n",
    "# We return from a NEST spike_recorder the ratio number_of_population_spikes / number_of_population_neurons\n",
    "# for every TVB time step, which is already a quantity in the range [0.0, 1.0],\n",
    "# as long as a neuron cannot fire twice during a TVB time step, i.e.,\n",
    "# as long as the TVB time step (usually 0.001 to 0.1 ms)\n",
    "# is smaller than the neurons' refractory time, t_ref (usually 1-2 ms)\n",
    "tvb_nest_builder.w_spikes_to_tvb = 1000.0\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# Configure and build:\n",
    "tvb_nest_builder.configure()\n",
    "\n",
    "simulator = tvb_nest_builder.build()\n",
    "\n",
    "simulator.simulate_spiking_simulator = nest_network.nest_instance.Run  # set the method to run NEST\n",
    "\n",
    "print(\"\\n\\noutput (TVB->NEST coupling) interfaces:\\n\")\n",
    "simulator.output_interfaces.print_summary_info_details(recursive=2)\n",
    "\n",
    "print(\"\\n\\ninput (NEST->TVB update) interfaces:\\n\")\n",
    "simulator.input_interfaces.print_summary_info_details(recursive=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tvb_nest_model.print_str(detailed_output=True, connectivity=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure simulator, simulate, gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:18.879872Z",
     "start_time": "2019-07-12T20:36:11.148945Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Configure the simulator with the TVB-NEST interface...\n",
    "\n",
    "# ...and simulate!\n",
    "t = time.time()\n",
    "\n",
    "simulator.simulation_length = simulation_length\n",
    "\n",
    "print(\"Simulating TVB-NEST...\")\n",
    "nest_network.nest_instance.Prepare()\n",
    "simulator.configure()\n",
    "# Adjust simulation length to be an integer multiple of synchronization_time:\n",
    "simulator.simulation_length = \\\n",
    "    np.ceil(simulator.simulation_length / simulator.synchronization_time) * simulator.synchronization_time\n",
    "results = simulator.run()\n",
    "nest_network.nest_instance.Run(nest_network.nest_instance.GetKernelStatus(\"resolution\"))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nSimulated in %f secs!\" % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up NEST simulation\n",
    "nest_network.nest_instance.Cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot results and write them to HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False for faster plotting of only mean field variables and dates, apart from spikes\" rasters:\n",
    "plot_per_neuron = False  \n",
    "MAX_VARS_IN_COLS = 3\n",
    "MAX_REGIONS_IN_ROWS = 10\n",
    "MIN_REGIONS_FOR_RASTER_PLOT = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:18.997574Z",
     "start_time": "2019-07-12T20:36:18.885020Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If you want to see what the function above does, take the steps, one by one\n",
    "try:\n",
    "    # We need framework_tvb for writing and reading from HDF5 files\n",
    "    from tvb_multiscale.core.tvb.io.h5_writer import H5Writer\n",
    "    from examples.plot_write_results import write_RegionTimeSeriesXarray_to_h5\n",
    "    writer = H5Writer()\n",
    "except:\n",
    "    writer = False\n",
    "    \n",
    "from tvb.contrib.scripts.datatypes.time_series import TimeSeriesRegion\n",
    "from tvb.contrib.scripts.datatypes.time_series_xarray import TimeSeriesRegion as TimeSeriesXarray\n",
    "\n",
    "# Put the results in a Timeseries instance\n",
    "from tvb.contrib.scripts.datatypes.time_series import TimeSeriesRegion\n",
    "\n",
    "source_ts = TimeSeriesXarray(  # substitute with TimeSeriesRegion fot TVB like functionality\n",
    "        data=results[0][1], time=results[0][0] - results[0][0][0],\n",
    "        connectivity=simulator.connectivity,\n",
    "        labels_ordering=[\"Time\", \"State Variable\", \"Region\", \"Neurons\"],\n",
    "        labels_dimensions={\"State Variable\": list(simulator.model.variables_of_interest),\n",
    "                           \"Region\": simulator.connectivity.region_labels.tolist()},\n",
    "        sample_period=simulator.integrator.dt)\n",
    "source_ts.configure()\n",
    "\n",
    "t = source_ts.time\n",
    "    \n",
    "# Write to file\n",
    "if writer:\n",
    "    write_RegionTimeSeriesXarray_to_h5(source_ts, writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES, source_ts.title)+\".h5\")\n",
    "source_ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot TVB time series\n",
    "source_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                          hue=\"Region\" if source_ts.shape[2] > MAX_REGIONS_IN_ROWS else None, \n",
    "                          per_variable=source_ts.shape[1] > MAX_VARS_IN_COLS, \n",
    "                          figsize=FIGSIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # TVB time series raster plot:\n",
    "# if source_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "#     source_ts.plot_raster(plotter_config=plotter.config, \n",
    "#                           per_variable=source_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "#                           figsize=FIGSIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: \n",
    "n_spiking_nodes = len(nest_nodes_ids)\n",
    "source_ts_nest = source_ts[:, :, nest_nodes_ids]\n",
    "source_ts_nest.plot_timeseries(plotter_config=plotter.config, \n",
    "                               hue=\"Region\" if source_ts_nest.shape[2] > MAX_REGIONS_IN_ROWS else None, \n",
    "                               per_variable=source_ts_nest.shape[1] > MAX_VARS_IN_COLS, \n",
    "                               figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Focus on the nodes modelled in NEST: raster plot\n",
    "# if source_ts_nest.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "#     source_ts_nest.plot_raster(plotter_config=plotter.config, \n",
    "#                                per_variable=source_ts_nest.shape[1] > MAX_VARS_IN_COLS,\n",
    "#                                figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series Raster\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ...interactively as well\n",
    "# # For interactive plotting:\n",
    "# %matplotlib notebook \n",
    "# plotter.plot_timeseries_interactive(TimeSeriesRegion().from_xarray_DataArray(source_ts._data,\n",
    "#                                                                              connectivity=source_ts.connectivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiking Network plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb_multiscale.core.data_analysis.spiking_network_analyser import SpikingNetworkAnalyser\n",
    "# Create a SpikingNetworkAnalyzer:\n",
    "spikeNet_analyzer = \\\n",
    "    SpikingNetworkAnalyser(spikeNet=nest_network,\n",
    "                           start_time=t[0], end_time=t[-1], \n",
    "                           period=simulator.monitors[0].period, transient=transient,\n",
    "                           time_series_output_type=\"TVB\", return_data=True, \n",
    "                           force_homogeneous_results=True, connectivity=simulator.connectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spikes' raster and mean spike rates and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spikes rates and correlations per Population and Region\n",
    "spikes_res = \\\n",
    "    spikeNet_analyzer.\\\n",
    "        compute_spikeNet_spikes_rates_and_correlations(\n",
    "            populations_devices=None, regions=None,\n",
    "            rates_methods=[], rates_kwargs=[{}],rate_results_names=[],\n",
    "            corrs_methods=[], corrs_kwargs=[{}], corrs_results_names=[], bin_kwargs={},\n",
    "            data_method=spikeNet_analyzer.get_spikes_from_device, data_kwargs={},\n",
    "            return_devices=False\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(spikes_res[\"mean_rate\"])\n",
    "    print(spikes_res[\"spikes_correlation_coefficient\"])\n",
    "    # Plot spikes' rasters together with mean population's spikes' rates' time series\n",
    "    if plotter:\n",
    "        plotter.plot_spike_events(spikes_res[\"spikes\"], rates=spikes_res[\"mean_rate_time_series\"], figsize=FIGSIZE) # \n",
    "        from tvb_multiscale.core.plot.correlations_plot import plot_correlations\n",
    "        plot_correlations(spikes_res[\"spikes_correlation_coefficient\"], plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean spike rates:\")\n",
    "for pop in spikes_res[\"mean_rate\"].coords[\"Population\"]:\n",
    "    for reg in spikes_res[\"mean_rate\"].coords[\"Region\"]:\n",
    "        if not np.isnan(spikes_res[\"mean_rate\"].loc[pop, reg]):\n",
    "            print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                   spikes_res[\"mean_rate\"].loc[pop, reg].values.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_res and writer:\n",
    "    writer.write_object(spikes_res[\"spikes\"].to_dict(), \n",
    "                        path=os.path.join(config.out.FOLDER_RES,  \"Spikes\") + \".h5\");\n",
    "    writer.write_object(spikes_res[\"mean_rate\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"mean_rate\"].name) + \".h5\");\n",
    "    write_RegionTimeSeriesXarray_to_h5(spikes_res[\"mean_rate_time_series\"], writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES,\n",
    "                                                    spikes_res[\"mean_rate_time_series\"].title) + \".h5\",\n",
    "                                       recursive=False);\n",
    "    writer.write_object(spikes_res[\"spikes_correlation_coefficient\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"spikes_correlation_coefficient\"].name) + \".h5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  SpikingNetwork mean field variable time series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Continuous time variables' data of spiking neurons\n",
    "if plot_per_neuron:\n",
    "    spikeNet_analyzer.return_data = True\n",
    "else:\n",
    "    spikeNet_analyzer.return_data = False\n",
    "spikeNet_ts = \\\n",
    "    spikeNet_analyzer. \\\n",
    "         compute_spikeNet_mean_field_time_series(populations_devices=None, regions=None, variables=None,\n",
    "                                                 computations_kwargs={}, data_kwargs={}, return_devices=False)\n",
    "if spikeNet_ts:\n",
    "    if plot_per_neuron:\n",
    "        mean_field_ts = spikeNet_ts[\"mean_field_time_series\"]  # mean field\n",
    "        spikeNet_ts = spikeNet_ts[\"data_by_neuron\"]  # per neuron data\n",
    "    else:\n",
    "        mean_field_ts = spikeNet_ts\n",
    "    if mean_field_ts and mean_field_ts.size > 0:\n",
    "        mean_field_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                                      per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS)\n",
    "        if mean_field_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "            mean_field_ts.plot_raster(plotter_config=plotter.config, \n",
    "                                      per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "                                      linestyle=\"--\", alpha=0.5, linewidth=0.5)\n",
    "else:\n",
    "    mean_field_ts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to file:\n",
    "if mean_field_ts and writer:\n",
    "    write_RegionTimeSeriesXarray_to_h5(mean_field_ts, writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES, mean_field_ts.title) + \".h5\", \n",
    "                                       recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute per neuron spikes' rates times series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if spikes_res and plot_per_neuron:\n",
    "    from tvb.simulator.plot.base_plotter import pyplot\n",
    "    spikeNet_analyzer.return_data = False\n",
    "    rates_ts_per_neuron = \\\n",
    "        spikeNet_analyzer. \\\n",
    "            compute_spikeNet_rates_time_series(populations_devices=None, regions=None,\n",
    "                                               computations_kwargs={}, data_kwargs={},\n",
    "                                               return_spikes_trains=False, return_devices=False);\n",
    "    if rates_ts_per_neuron is not None and rates_ts_per_neuron.size:\n",
    "        # Regions in rows\n",
    "        row = rates_ts_per_neuron.dims[2] if rates_ts_per_neuron.shape[2] > 1 else None\n",
    "        if row is None:\n",
    "            # Populations in rows\n",
    "            row = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "            col = None\n",
    "        else:\n",
    "            # Populations in columns\n",
    "            col = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "        pyplot.figure()\n",
    "        rates_ts_per_neuron.plot(y=rates_ts_per_neuron.dims[3], row=row, col=col, cmap=\"jet\")\n",
    "        plotter.base._save_figure(figure_name=\"Spike rates per neuron\")\n",
    "        # del rates_ts_per_neuron # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot per neuron SpikingNetwork time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regions in rows\n",
    "if plot_per_neuron and spikeNet_ts.size:\n",
    "    row = spikeNet_ts.dims[2] if spikeNet_ts.shape[2] > 1 else None\n",
    "    if row is None:\n",
    "        # Populations in rows\n",
    "        row = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "        col = None\n",
    "    else:\n",
    "        # Populations in cols\n",
    "         col = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "    for var in spikeNet_ts.coords[spikeNet_ts.dims[1]]:\n",
    "        this_var_ts = spikeNet_ts.loc[:, var, :, :, :]\n",
    "        this_var_ts.name = var.item()\n",
    "        pyplot.figure()\n",
    "        this_var_ts.plot(y=spikeNet_ts.dims[4], row=row, col=col, cmap=\"jet\", figsize=FIGSIZE)\n",
    "        plotter.base._save_figure(\n",
    "            figure_name=\"Spiking Network variables' time series per neuron: %s\" % this_var_ts.name)\n",
    "    del spikeNet_ts # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# References\n",
    "\n",
    "1 Sanz Leon P, Knock SA, Woodman MM, Domide L, <br>\n",
    "  Mersmann J, McIntosh AR, Jirsa VK (2013) <br>\n",
    "  The Virtual Brain: a simulator of primate brain network dynamics. <br>\n",
    "  Frontiers in Neuroinformatics 7:10. doi: 10.3389/fninf.2013.00010 <br>\n",
    "  https://www.thevirtualbrain.org/tvb/zwei <br>\n",
    "  https://github.com/the-virtual-brain <br>\n",
    "\n",
    "2 Ritter P, Schirner M, McIntosh AR, Jirsa VK (2013).  <br>\n",
    "  The Virtual Brain integrates computational modeling  <br>\n",
    "  and multimodal neuroimaging. Brain Connectivity 3:121145. <br>\n",
    "\n",
    "3 Jordan, Jakob; Mrk, Hkon; Vennemo, Stine Brekke;   Terhorst, Dennis; Peyser, <br>\n",
    "  Alexander; Ippen, Tammo; Deepu, Rajalekshmi;   Eppler, Jochen Martin; <br>\n",
    "  van Meegen, Alexander;   Kunkel, Susanne; Sinha, Ankur; Fardet, Tanguy; Diaz, <br>\n",
    "  Sandra; Morrison, Abigail; Schenck, Wolfram; Dahmen, David;   Pronold, Jari; <br>\n",
    "  Stapmanns, Jonas;   Trensch, Guido; Spreizer, Sebastian;   Mitchell, Jessica; <br>\n",
    "  Graber, Steffen; Senk, Johanna; Linssen, Charl; Hahne, Jan; Serenko, Alexey; <br>\n",
    "  Naoumenko, Daniel; Thomson, Eric;   Kitayama, Itaru; Berns, Sebastian;   <br>\n",
    "  Plesser, Hans Ekkehard <br>\n",
    "  NEST is a simulator for spiking neural network models that focuses <br>\n",
    "  on the dynamics, size and structure of neural systems rather than on <br>\n",
    "  the exact morphology of individual neurons. <br>\n",
    "  For further information, visit http://www.nest-simulator.org. <br>\n",
    "  The release notes for this release are available at  <br>\n",
    "  https://github.com/nest/nest-simulator/releases/tag/v2.18.0 <br>\n",
    "\n",
    "4 Baladron, J., Nambu, A., & Hamker, F. H. (2019). <br>\n",
    "  The subthalamic nucleusexternal globus pallidus loop biases <br>\n",
    "  exploratory decisions towards known alternatives: A neurocomputational study. <br>\n",
    "  European Journal of Neuroscience, 49:754767. https://doi.org/10.1111/ejn.13666 <br>\n",
    "  \n",
    "5 Maith O, Villagrasa Escudero F, lo Dinkelbach H, Baladron J, <br>\n",
    "  Horn, A, Irmen F, Khn AA, Hamker FH (2020).<br>\n",
    "  A computational modelbased analysis of basal ganglia pathway changes <br>\n",
    "  in Parkinsons disease inferred from restingstate fMRI <br>\n",
    "  European Journal of Neuroscience, 00:118. https://doi.org/10.1111/ejn.14868\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
