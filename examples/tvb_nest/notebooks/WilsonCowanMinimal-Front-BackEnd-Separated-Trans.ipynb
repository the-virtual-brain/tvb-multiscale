{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVB-NEST: Bridging multiscale activity by co-simulation\n",
    "\n",
    "## Step-by-step learn how to perform a co-simulation embedding spiking neural networks into large-scale brain networks using TVB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='pics/ConceptGraph1.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='pics/ConceptGraph2.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tvb-multiscale toolbox:\n",
    "\n",
    "### https://github.com/the-virtual-brain/tvb-multiscale\n",
    "\n",
    "For questions use the git issue tracker, or write an e-mail to me: dionysios.perdikis@charite.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T13:37:40.905578Z",
     "start_time": "2019-07-11T13:37:40.894958Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TVB - NEST co-simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilson - Cowan TVB mean field model\n",
    "\n",
    "For every region node $n\\prime$ modelled as a mean-field node in TVB:\n",
    "\n",
    "Population activity dynamics (1 excitatory and 1 inhibitory population):\n",
    "\n",
    " $\\dot{E}_k = \\dfrac{1}{\\tau_e} (-E_k  + (k_e - r_e E_k) \\mathcal{S}_e (\\alpha_e \\left( c_{ee} E_k - c_{ei} I_k  + P_k - \\theta_e + \\mathbf{\\Gamma}(E_k, E_j, u_{kj}) + W_{\\zeta}\\cdot E_j + W_{\\zeta}\\cdot I_j\\right) )) $\n",
    " \n",
    "$\n",
    "            \\dot{I}_k = \\dfrac{1}{\\tau_i} (-I_k  + (k_i - r_i I_k) \\mathcal{S}_i (\\alpha_i \\left( c_{ie} E_k - c_{ee} I_k  + Q_k - \\theta_i + \\mathbf{\\Gamma}(E_k, E_j, u_{kj}) + W_{\\zeta}\\cdot E_j + W_{\\zeta}\\cdot I_j\\right) ))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking network model in NEST\n",
    "\n",
    "using \"iaf_cond_alpha\" spiking neuronal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVB to NEST coupling\n",
    "TVB couples to NEST via instantaneous spike rate $ w_{TVB->NEST} * E(t) $, \n",
    "\n",
    "Inhomogeneous spike generator NEST devices are used as TVB \"proxy\" nodes and generate independent Poisson-random spike trains \n",
    "\n",
    "$ \\left[ \\sum_k \\delta(t-\\tau_{n\\prime n}-{t_j}^k) \\right]_{j \\in n\\prime} $\n",
    "\n",
    "Alternatively, the spike trains are generated outside NEST using the Elephant software and inserted to NEST via spike generator devices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEST to TVB update\n",
    "\n",
    "A NEST spike detector device is used to count spike for each time step, and convert it to an instantaneous population mean rate that overrides\n",
    "\n",
    "$ {E_{_{n}}}(t) =  \\frac{\\sum_j\\left[ \\sum_k \\delta(t-\\tau_n-{t_j}^k) \\right]_{j \\in E_n}}{N_E * dt} $ \n",
    "\n",
    "$ {I_{_{n}}}(t) =  \\frac{\\sum_j\\left[ \\sum_k \\delta(t-\\tau_n-{t_j}^k) \\right]_{j \\in I_n}}{N_I * dt} $\n",
    "\n",
    "in  spikes/sec.\n",
    "\n",
    "This update process concerns only the TVB region nodes that are simulated exclusively in NEST, as spiking networks. All the rest of TVB nodes will follow the equations of the mean field model described above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator loop\n",
    "\n",
    "### Simulating several (i.e., minimally 2) NEST time steps for every 1 TVB time step for stable integration\n",
    "\n",
    "### Synchronizaion every minimum delay time between the two simulators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:57.561354Z",
     "start_time": "2019-07-12T20:35:52.475653Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def configure():\n",
    "    \n",
    "    # Set up the environment\n",
    "    from tvb.basic.profile import TvbProfile\n",
    "    TvbProfile.set_profile(TvbProfile.LIBRARY_PROFILE)\n",
    "\n",
    "    from tvb_multiscale.tvb_nest.config import Config\n",
    "\n",
    "    # ----------- Simulation options ----------------\n",
    "    SIM_MODE = \"tvb-nest\"  # \"tvb-nest\"  for multiscale cosimulation, \"tvb\" (\"nest\") for only TVB (NEST) simulation, respectively\n",
    "    NEST_MODEL_BUILDERS = None # only None will work!, \"opinionated\", \"nonopinionated\", None\n",
    "\n",
    "    # For a minimal example, select:\n",
    "    n_regions = 4 # total TVB brain regions\n",
    "    nest_nodes_inds = np.array([0, 1])  # the brain region nodes to place spiking networks from [0, n_regions-1] interval\n",
    "    n_neurons = 10 # number of neurons per spiking population\n",
    "    # -----------------------------------------------\n",
    "\n",
    "    # Base paths\n",
    "    work_path = os.getcwd()\n",
    "    outputs_path = os.path.join(work_path, \"outputs/WilsonCowanMin/Front_Back_End_Separated_Trans\")\n",
    "    if NEST_MODEL_BUILDERS is None:\n",
    "        outputs_path += \"NoNestBuilders\"\n",
    "    elif NEST_MODEL_BUILDERS == \"opinionated\":\n",
    "        outputs_path += \"OpinionBuilders\"\n",
    "    elif NEST_MODEL_BUILDERS == \"nonopinionated\":\n",
    "        outputs_path += \"NonOpinionBuilders\"\n",
    "\n",
    "    if SIM_MODE.lower() == \"nest\":\n",
    "        outputs_path += \"NESTonly\"\n",
    "    elif SIM_MODE.lower() == \"tvb\":\n",
    "        outputs_path += \"TVBonly\"\n",
    "\n",
    "    # Generate a configuration class instance\n",
    "    config = Config(output_base=outputs_path)\n",
    "    config.figures.SHOW_FLAG = True \n",
    "    config.figures.SAVE_FLAG = True\n",
    "    config.figures.FIG_FORMAT = 'png'\n",
    "    config.figures.DEFAULT_SIZE= config.figures.NOTEBOOK_SIZE\n",
    "    \n",
    "    return config, SIM_MODE, n_regions, NEST_MODEL_BUILDERS, nest_nodes_inds, n_neurons\n",
    "\n",
    "# For interactive plotting:\n",
    "# %matplotlib notebook  \n",
    "\n",
    "# Otherwise:\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## BACKEND: 1. Load structural data <br> (minimally a TVB connectivity)  <br> & prepare TVB simulator  <br> (region mean field model, integrator, monitors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:59.690799Z",
     "start_time": "2019-07-12T20:35:57.571529Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This would run on TVB only before creating any multiscale cosimulation interface connections.\n",
    "\n",
    "def build_tvb_simulator():\n",
    "    \n",
    "    config, SIM_MODE, n_regions = configure()[:3]\n",
    "    \n",
    "    from tvb_multiscale.core.tvb.cosimulator.models.wilson_cowan_constraint import WilsonCowan\n",
    "\n",
    "    # Create a TVB simulator and set all desired inputs\n",
    "    # (connectivity, model, surface, stimuli etc)\n",
    "    # We choose all defaults in this example\n",
    "    # -----------------------------------Wilson Cowan oscillatory regime--------------------------------\n",
    "    model_params = {\n",
    "            \"r_e\": np.array([0.0]),\n",
    "            \"r_i\": np.array([0.0]),\n",
    "            \"k_e\": np.array([1.0]),\n",
    "            \"k_i\": np.array([1.0]),\n",
    "            \"tau_e\": np.array([10.0]),\n",
    "            \"tau_i\": np.array([10.0]),\n",
    "            \"c_ee\": np.array([10.0]),\n",
    "            \"c_ei\": np.array([6.0]),\n",
    "            \"c_ie\": np.array([10.0]),\n",
    "            \"c_ii\": np.array([1.0]),\n",
    "            \"alpha_e\": np.array([1.2]),\n",
    "            \"alpha_i\": np.array([2.0]),\n",
    "            \"a_e\": np.array([1.0]),\n",
    "            \"a_i\": np.array([1.0]),\n",
    "            \"b_e\": np.array([0.0]),\n",
    "            \"b_i\": np.array([0.0]),\n",
    "            \"c_e\": np.array([1.0]),\n",
    "            \"c_i\": np.array([1.0]),\n",
    "            \"theta_e\": np.array([2.0]),\n",
    "            \"theta_i\": np.array([3.5]),\n",
    "            \"P\": np.array([0.5]),\n",
    "            \"Q\": np.array([0.0])\n",
    "        }\n",
    "\n",
    "\n",
    "    # -----------------------------------Build cosimunlator manually--------------------------------\n",
    "    from tvb_multiscale.core.tvb.cosimulator.cosimulator_serial import CoSimulator as CoSimulator\n",
    "    \n",
    "    class CoSimulatorSerial(CoSimulator):\n",
    "        \n",
    "        tvb_to_spikeNet_transform = None\n",
    "        spikeNet_to_tvb_transform = None\n",
    "        \n",
    "        def _run_for_synchronization_time(self, ts, xs, wall_time_start, cosimulation=True, **kwds):\n",
    "            \n",
    "            steps_performed = \\\n",
    "                super(CoSimulatorSerial, self)._run_for_synchronization_time(ts, xs, wall_time_start, cosimulation, **kwds)\n",
    "            \n",
    "            if self.simulate_spiking_simulator is not None:\n",
    "            \n",
    "                if self.tvb_to_spikeNet_transform is not None:\n",
    "                    self.tvb_to_spikeNet_transform()\n",
    "            \n",
    "                steps_to_run = np.where(self.n_tvb_steps_sent_to_cosimulator_at_last_synch,\n",
    "                                        self.n_tvb_steps_sent_to_cosimulator_at_last_synch,\n",
    "                                        steps_performed).item()\n",
    "                self.log.info(\"Simulating the spiking network for %d time steps...\", steps_to_run)\n",
    "                self.simulate_spiking_simulator(np.around(steps_to_run * self.integrator.dt,\n",
    "                                                          decimals=self._number_of_dt_decimals).item())\n",
    "                \n",
    "                if self.spikeNet_to_tvb_transform is not None:\n",
    "                    self.spikeNet_to_tvb_transform()\n",
    "\n",
    "            return steps_performed\n",
    "        \n",
    "\n",
    "    from tvb.datatypes.connectivity import Connectivity\n",
    "    from tvb.simulator.integrators import HeunStochastic\n",
    "    from tvb.simulator.monitors import Raw  # , Bold, EEG\n",
    "\n",
    "    simulator = CoSimulatorSerial()\n",
    "\n",
    "    simulator.model = WilsonCowan(**model_params)\n",
    "\n",
    "    simulator.integrator = HeunStochastic()\n",
    "    simulator.integrator.dt = 0.1\n",
    "    simulator.integrator.noise.nsig = np.array([config.DEFAULT_NSIG, config.DEFAULT_NSIG]) # 0.001\n",
    "\n",
    "\n",
    "    # Load connectivity\n",
    "    # config.DEFAULT_CONNECTIVITY_ZIP = \"/home/docker/packages/tvb_data/tvb_data/mouse/allen_2mm/ConnectivityAllen2mm.zip\"                                  \n",
    "    connectivity = Connectivity.from_file(config.DEFAULT_CONNECTIVITY_ZIP)\n",
    "\n",
    "\n",
    "    # -------------- Pick a minimal brain of only the first n_regions regions: ----------------\n",
    "    n_regions = 4\n",
    "    connectivity.number_of_regions = n_regions\n",
    "    connectivity.region_labels = connectivity.region_labels[:n_regions]\n",
    "    connectivity.centres = connectivity.centres[:n_regions]\n",
    "    connectivity.areas = connectivity.areas[:n_regions]\n",
    "    connectivity.orientations = connectivity.orientations[:n_regions]\n",
    "    connectivity.hemispheres = connectivity.hemispheres[:n_regions]\n",
    "    connectivity.cortical = connectivity.cortical[:n_regions]\n",
    "    connectivity.weights = connectivity.weights[:n_regions][:, :n_regions]\n",
    "    connectivity.tract_lengths = connectivity.tract_lengths[:n_regions][:, :n_regions]\n",
    "    # Remove diagonal self-connections:\n",
    "    np.fill_diagonal(connectivity.weights, 0.0)\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # Normalize connectivity weights\n",
    "    connectivity.weights = connectivity.scaled_weights(mode=\"region\")\n",
    "    connectivity.weights /= np.percentile(connectivity.weights, 99)\n",
    "    # connectivity.weights[connectivity.weights > 1.0] = 1.0\n",
    "\n",
    "    # connectivity.tract_lengths = np.maximum(connectivity.speed * simulator.integrator.dt, \n",
    "    #                                         connectivity.tract_lengths)\n",
    "\n",
    "    connectivity.configure()\n",
    "\n",
    "    simulator.connectivity = connectivity\n",
    "\n",
    "    simulator.initial_conditions = np.zeros((1, 2, connectivity.number_of_regions, 1))\n",
    "\n",
    "    mon_raw = Raw(period=1.0)  # ms\n",
    "    simulator.monitors = (mon_raw, )\n",
    "\n",
    "    simulator.configure()\n",
    "\n",
    "\n",
    "\n",
    "    # # -----------------------------------Or use the CoSimulator builder--------------------------------\n",
    "    # from tvb_multiscale.core.tvb.cosimulator.cosimulator_builder import CoSimulatorSerialBuilder\n",
    "\n",
    "    # simulator_builder = CoSimulatorSerialBuilder()\n",
    "    # simulator_builder.config = config\n",
    "    # simulator_builder.model = WilsonCowan()\n",
    "    # simulator_builder.model_params = model_params\n",
    "    # simulator_builder.initial_conditions = np.zeros((1, 1, 1, 1))\n",
    "\n",
    "    # # simulator_builder.configure()\n",
    "    # simulator_builder.print_summary_info_details(recursive=1)\n",
    "\n",
    "    # simulator = simulator_builder.build()\n",
    "\n",
    "\n",
    "\n",
    "    # simulator.print_summary_info_details(recursive=1)\n",
    "\n",
    "    # Serializing TVB cosimulator is necessary for parallel cosimulation:\n",
    "    from tvb_multiscale.core.utils.file_utils import dump_pickled_dict\n",
    "    from tvb_multiscale.core.tvb.cosimulator.cosimulator_serialization import serialize_tvb_cosimulator\n",
    "    sim_serial_filepath = os.path.join(config.out.FOLDER_RES, \"tvb_serial_cosimulator.pkl\")\n",
    "    simulator._preconfigure_synchronization_time()\n",
    "    sim_serial = serialize_tvb_cosimulator(simulator)\n",
    "    display(sim_serial)\n",
    "    \n",
    "    # Dumping the serialized TVB cosimulator to a file will be necessary for parallel cosimulation.\n",
    "    dump_pickled_dict(sim_serial, sim_serial_filepath)\n",
    "    \n",
    "    simulator.configure()\n",
    "    \n",
    "    return simulator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKEND: 2. Build and connect the NEST network model <br> (networks of spiking neural populations for fine-scale <br>regions, stimulation devices, spike detectors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:10.862262Z",
     "start_time": "2019-07-12T20:36:10.000332Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This would run on NEST only before creating any multiscale cosimulation interface connections.\n",
    "# Here it is assumed that the TVB simulator is already created and we can get some of its attributes, \n",
    "# either by directly accessing it, or via serialization.\n",
    "\n",
    "def build_nest_network():\n",
    "    \n",
    "    config, SIM_MODE, n_regions, NEST_MODEL_BUILDERS, nest_nodes_inds, n_neurons = configure()\n",
    "            \n",
    "    nest = None\n",
    "    nest_network = None\n",
    "\n",
    "    if \"nest\" in SIM_MODE.lower():\n",
    "\n",
    "        # Build a NEST network model with the corresponding builder\n",
    "        from tvb_multiscale.tvb_nest.nest_models.builders.nest_factory import load_nest, configure_nest_kernel\n",
    "\n",
    "        # Load serialized TVB simulator from a file...:        \n",
    "        from tvb_multiscale.core.utils.file_utils import load_pickled_dict\n",
    "        sim_serial_filepath = os.path.join(config.out.FOLDER_RES, \"tvb_serial_cosimulator.pkl\")\n",
    "        if not os.path.isfile(sim_serial_filepath):\n",
    "            # In order to be independent create a TVB simulator, serialize it and write it to file:\n",
    "            build_tvb_simulator();\n",
    "        sim_serial = load_pickled_dict(sim_serial_filepath)\n",
    "        \n",
    "        # Load NEST and use defaults to configure its kernel:\n",
    "        nest = configure_nest_kernel(load_nest(config=config), config)\n",
    "\n",
    "        # Local (i.e. within brain region) neuronal populations' connections' rescaling\n",
    "        # to account for the reduction (increase) to the number of neurons,\n",
    "        # with respect to the originally set 100 neurons per population.\n",
    "        w_n_neurons_factor = 100.0 / n_neurons\n",
    "\n",
    "        if NEST_MODEL_BUILDERS:\n",
    "\n",
    "            if NEST_MODEL_BUILDERS == \"opinionated\":\n",
    "\n",
    "                # ------------------- Instantiating an opinionated nest network builder for this model, ------------------- \n",
    "                # using all default parameters for this example\n",
    "\n",
    "                from tvb_multiscale.tvb_nest.nest_models.models.wilson_cowan import WilsonCowanBuilder\n",
    "\n",
    "                nest_model_builder = WilsonCowanBuilder(sim_serial,  # simulator, \n",
    "                                                        spiking_nodes_inds=nest_nodes_inds, nest_instance=nest, config=config)\n",
    "\n",
    "                # ... or modifying some of the builder's attributes:\n",
    "                nest_model_builder.w_ee = w_n_neurons_factor * sim_serial['model.c_ee'][0]  # simulator.model.c_ie[0]\n",
    "                nest_model_builder.w_ei = w_n_neurons_factor * sim_serial['model.c_ei'][0]  # simulator.model.c_ie[0]\n",
    "                nest_model_builder.w_ie = -w_n_neurons_factor * sim_serial['model.c_ie'][0] # simulator.model.c_ie[0]\n",
    "                nest_model_builder.w_ii = -w_n_neurons_factor * sim_serial['model.c_ii'][0] # simulator.model.c_ii[0]\n",
    "                nest_model_builder.output_devices_record_to = \"memory\"  # \"ascii\"\n",
    "                nest_model_builder.population_order = n_neurons\n",
    "                nest_model_builder.tvb_to_spiking_dt_ratio = 2 # 2 NEST integration steps for 1 TVB integration step\n",
    "                nest_model_builder.monitor_period = 1.0\n",
    "\n",
    "            else:\n",
    "\n",
    "                # ------ Alternatively, instantiating a non-opinionated nest network builder for this model, ----------------- \n",
    "                # ... and setting desired network description:\n",
    "\n",
    "                from tvb_multiscale.tvb_nest.nest_models.builders.base import NESTNetworkBuilder\n",
    "\n",
    "                nest_model_builder = NESTNetworkBuilder(sim_serial, # simulator, \n",
    "                                                        spiking_nodes_inds=nest_nodes_inds, nest_instance=nest, config=config)\n",
    "                nest_model_builder.output_devices_record_to = \"memory\"  # \"ascii\"\n",
    "                nest_model_builder.population_order = n_neurons\n",
    "                nest_model_builder.tvb_to_spiking_dt_ratio = 2 # 2 NEST integration steps for 1 TVB integration step\n",
    "                nest_model_builder.monitor_period = 1.0\n",
    "\n",
    "                # Set populations:\n",
    "                nest_model_builder.populations = []\n",
    "                for pop in [\"E\", \"I\"]:\n",
    "                    nest_model_builder.populations.append(\n",
    "                        {\"label\": pop, \n",
    "                         \"model\": config.DEFAULT_SPIKING_MODEL,  # \"iaf_cond_alpha\" by default\n",
    "                         # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                         \"params\": {},   # parameters for NEST neuronal model\n",
    "                         \"scale\": 1.0,   # nest_model_builder.multiply population_order for the exact populations' size\n",
    "                         # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                         \"nodes\": None}) # None means \"all\" -> building this population to all spiking_nodes_inds\n",
    "\n",
    "\n",
    "                # \"static_synapse\" by default:\n",
    "                synapse_model = config.DEFAULT_CONNECTION[\"synapse_model\"] \n",
    "                # Default conn_spec: {'rule': \"all_to_all\", \"allow_autapses\": True, 'allow_multapses': True}\n",
    "                conn_spec =  config.DEFAULT_CONNECTION[\"conn_spec\"]  \n",
    "\n",
    "                # Set populations' connections within brain region nodes\n",
    "                nest_model_builder.populations_connections = [\n",
    "                    {\"source\": \"E\", \"target\": \"E\",  # E -> E This is a self-connection for population \"E\"\n",
    "                     # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                     \"synapse_model\": synapse_model,  \n",
    "                     \"conn_spec\": conn_spec,\n",
    "                     \"weight\": w_n_neurons_factor * sim_serial['model.c_ee'][0], # simulator.model.c_ee[0], # default = 1.0\n",
    "                     \"delay\": 0.1, # by default = 1 TVB time step\n",
    "                     \"receptor_type\": 0, # default = 0\n",
    "                     # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                     \"nodes\": None}, # None means \"all\" -> performing this connection to all spiking_nodes_inds\n",
    "                    {\"source\": \"E\", \"target\": \"I\",  # E -> I\n",
    "                     \"synapse_model\": synapse_model,\n",
    "                     \"conn_spec\": conn_spec, \n",
    "                     \"weight\": w_n_neurons_factor * sim_serial['model.c_ei'][0], # simulator.model.c_ei[0],\n",
    "                     \"delay\": 0.1,\n",
    "                     \"receptor_type\": 0, \n",
    "                     \"nodes\": None},\n",
    "                    {\"source\": \"I\", \"target\": \"E\",  # I -> E\n",
    "                     \"synapse_model\": synapse_model,\n",
    "                     \"conn_spec\": conn_spec, \n",
    "                     \"weight\": -w_n_neurons_factor * sim_serial['model.c_ie'][0], # -simulator.model.c_ie[0],\n",
    "                     \"delay\": 0.1,\n",
    "                     \"receptor_type\": 0, \n",
    "                     \"nodes\": None},\n",
    "                    {\"source\": \"I\", \"target\": \"I\",  # I -> I, This is a self-connection for population \"I\"\n",
    "                     \"synapse_model\": synapse_model,\n",
    "                     \"conn_spec\": conn_spec, \n",
    "                     \"weight\": -w_n_neurons_factor * sim_serial['model.c_ii'][0], # -simulator.model.c_ii[0],\n",
    "                     \"delay\": 0.1,\n",
    "                     \"receptor_type\": 0, \n",
    "                     \"nodes\": None}\n",
    "                ]\n",
    "\n",
    "                # Set populations' connections among brain region node:\n",
    "                nest_model_builder.nodes_connections = [\n",
    "                    {\"source\": \"E\", \"target\": [\"E\", \"I\"],\n",
    "                     #--------- Possibly functions of (source_node_ind, target_node_ind, *args, **kwargs) -------------\n",
    "                     \"synapse_model\": synapse_model,\n",
    "                     \"conn_spec\": conn_spec,\n",
    "                     # ...using TVB connectome weights:\n",
    "                     \"weight\": \n",
    "                         lambda source_node_ind, target_node_ind: \n",
    "                             sim_serial['coupling.a'][0] * sim_serial['connectivity.weights'][target_node_ind, source_node_ind],\n",
    "                     # ...using TVB connectome delays\n",
    "                     \"delay\": \n",
    "                         lambda source_node_ind, target_node_ind: \n",
    "                             np.maximum(sim_serial['integrator.dt'], \n",
    "                                        sim_serial['connectivity.delays'][target_node_ind, source_node_ind]),  \n",
    "                     \"receptor_type\": 0, \n",
    "                     #--------- Possibly functions of (source_node_ind, target_node_ind, *args, **kwargs) -------------\n",
    "                     \"source_nodes\": None,  # None means \"all\" -> performing this connection from all spiking_nodes_inds\n",
    "                     \"target_nodes\": None}  # None means \"all\" -> performing this connection to all spiking_nodes_inds\n",
    "                ]\n",
    "\n",
    "                # Set output recorder devices:\n",
    "                params_spike_recorder = config.NEST_OUTPUT_DEVICES_PARAMS_DEF[\"spike_recorder\"].copy()\n",
    "                params_spike_recorder[\"record_to\"] = nest_model_builder.output_devices_record_to\n",
    "                params_multimeter = config.NEST_OUTPUT_DEVICES_PARAMS_DEF[\"multimeter\"].copy()\n",
    "                params_multimeter[\"record_to\"] = nest_model_builder.output_devices_record_to\n",
    "                params_multimeter[\"interval\"] = nest_model_builder.monitor_period\n",
    "                nest_model_builder.output_devices = [\n",
    "                    {\"model\": \"spike_recorder\", \n",
    "                     \"connections\": {\"E\": \"E\",   # Record spikes with label \"E\" from populations \"E\"\n",
    "                                     \"I\": \"I\"},  # Record spikes with label \"I\" from populations \"I\"\n",
    "                     # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                     \"params\": params_spike_recorder,\n",
    "                     # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                     \"nodes\": None},  # None means all here -> recording from all spiking_nodes_inds\n",
    "                    {\"model\": \"multimeter\", \n",
    "                     \"connections\": {\"Excitatory\": \"E\",   # Record time series with label \"E_ts\" from populations \"E\"\n",
    "                                     \"Inhibitory\": \"I\"},  # Record time series with label \"I_ts\" from populations \"I\"\n",
    "                     # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                     \"params\": params_multimeter,\n",
    "                     # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                     \"nodes\": None},  # None means all here -> recording from all spiking_nodes_inds\n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "                # Set input stimulation devices:\n",
    "                nest_model_builder.input_devices = [\n",
    "                    {\"model\": \"poisson_generator\",\n",
    "                    \"connections\": {\"Stimulus\": \"E\"}, # connect stimulus \"Stimulus\" to populations \"E\"\n",
    "                     # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                     \"params\": {\"rate\": 7000.0, \"origin\": 0.0, \"start\": nest_model_builder.spiking_dt}, \n",
    "                     \"weights\": 1.0,\n",
    "                     \"delays\": nest_model_builder.spiking_dt,\n",
    "                     \"receptor_type\": 0,\n",
    "                     # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                    \"nodes\": None  # None means all here -> stimulating all spiking_nodes_inds\n",
    "                    }\n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "            nest_model_builder.configure()\n",
    "\n",
    "            nest_network = nest_model_builder.build()\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            # ------------------- Construct the NEST network model manually ------------------- \n",
    "\n",
    "            from tvb_multiscale.tvb_nest.nest_models.network import NESTNetwork\n",
    "            from tvb_multiscale.tvb_nest.nest_models.brain import NESTBrain\n",
    "            from tvb_multiscale.tvb_nest.nest_models.region_node import NESTRegionNode\n",
    "            from tvb_multiscale.tvb_nest.nest_models.population import NESTPopulation\n",
    "            from tvb_multiscale.core.spiking_models.devices import DeviceSet, DeviceSets\n",
    "            from tvb_multiscale.tvb_nest.nest_models.devices import NESTSpikeRecorder, NESTMultimeter\n",
    "            from tvb_multiscale.tvb_nest.nest_models.devices import NESTPoissonGenerator\n",
    "\n",
    "\n",
    "            # First configure NEST kernel:\n",
    "            nest.SetKernelStatus({\"resolution\": 0.05})\n",
    "\n",
    "            print(\"Building NESTNetwork...\")\n",
    "\n",
    "            # Create NEST network...\n",
    "            nest_network = NESTNetwork(nest)\n",
    "\n",
    "\n",
    "            # ...starting from neuronal populations located at specific brain regions...\n",
    "            nest_network.brain_regions = NESTBrain()\n",
    "            for node_ind in nest_nodes_inds:\n",
    "                region_name = sim_serial['connectivity.region_labels'][node_ind]\n",
    "                # region_name = simulator.connectivity.region_labels[node_ind]\n",
    "                if region_name not in nest_network.brain_regions.keys():\n",
    "                    nest_network.brain_regions[region_name] = NESTRegionNode(label=region_name)\n",
    "                for pop in [\"E\", \"I\"]:\n",
    "                    nest_network.brain_regions[region_name][pop] = \\\n",
    "                               NESTPopulation(nest.Create(config.DEFAULT_SPIKING_MODEL, n_neurons), # possible NEST model params as well here\n",
    "                                              nest, label=pop, brain_region=region_name)\n",
    "                    print(\"\\n...created: %s...\" % nest_network.brain_regions[region_name][pop].summary_info())\n",
    "\n",
    "            # \"static_synapse\" by default:\n",
    "            synapse_model = config.DEFAULT_CONNECTION[\"synapse_model\"] \n",
    "            # Default \n",
    "            conn_spec = {'rule': \"all_to_all\", \"allow_autapses\": True, 'allow_multapses': True}\n",
    "\n",
    "\n",
    "            # Connecting populations...\n",
    "            for src_node_ind in nest_nodes_inds: \n",
    "                src_node_lbl = sim_serial['connectivity.region_labels'][src_node_ind]\n",
    "                # src_node_lbl = simulator.connectivity.region_labels[src_node_ind]\n",
    "                for trg_node_ind in nest_nodes_inds: \n",
    "                    trg_node_lbl = sim_serial['connectivity.region_labels'][trg_node_ind]\n",
    "                    # trg_node_lbl = simulator.connectivity.region_labels[trg_node_ind]\n",
    "                    if src_node_ind == trg_node_ind:\n",
    "                        # ...within brain regions...:\n",
    "                        for src_pop, trg_pop, w in zip([\"E\", \"E\", \"I\", \"I\"], \n",
    "                                                       [\"E\", \"I\", \"E\", \"I\"], \n",
    "                                                       [w_n_neurons_factor * sim_serial['model.c_ee'][0].item(),  # simulator.model.c_ee[0].item(), \n",
    "                                                        w_n_neurons_factor * sim_serial['model.c_ei'][0].item(),  # simulator.model.c_ei[0].item(), \n",
    "                                                        -w_n_neurons_factor * sim_serial['model.c_ie'][0].item(), # -simulator.model.c_ie[0].item(), \n",
    "                                                        -w_n_neurons_factor * sim_serial['model.c_ii'][0].item()  # -simulator.model.c_ii[0].item()\n",
    "                                                       ]):\n",
    "                            nest.Connect(nest_network.brain_regions[src_node_lbl][src_pop].nodes, \n",
    "                                         nest_network.brain_regions[src_node_lbl][trg_pop].nodes, \n",
    "                                         syn_spec={\"synapse_model\": synapse_model, \n",
    "                                                   \"weight\": w, \"delay\": 0.1, \"receptor_type\": 0}, \n",
    "                                         conn_spec=conn_spec)\n",
    "                            print(\"\\n...connected populations %s -> %s in brain region %s...\" \n",
    "                                  % (src_pop, trg_pop, src_node_lbl))\n",
    "                    else:\n",
    "\n",
    "                        # ...between brain regions...:\n",
    "                        nest.Connect(nest_network.brain_regions[src_node_lbl][\"E\"].nodes, \n",
    "                                     nest.NodeCollection(nest_network.brain_regions[trg_node_lbl][\"E\"].gids \n",
    "                                                         + nest_network.brain_regions[trg_node_lbl][\"I\"].gids), \n",
    "                                     syn_spec={\"synapse_model\": synapse_model, \n",
    "                                               \"weight\": \n",
    "                                                   sim_serial['coupling.a'][0].item() * \n",
    "                                                   sim_serial['connectivity.weights'][trg_node_ind, src_node_ind].item(),\n",
    "                                               \"delay\": \n",
    "                                                   np.maximum(0.1, \n",
    "                                                              sim_serial['connectivity.delays'][trg_node_ind, src_node_ind].item()),\n",
    "                                               \"receptor_type\": 0}, \n",
    "                                     conn_spec=conn_spec)\n",
    "                        print(\"\\n...connected populations E - %s -> [E, I] - %s...\" % (src_node_lbl, trg_node_lbl))\n",
    "\n",
    "\n",
    "            # Create output recorder devices:\n",
    "            params_spike_recorder = config.NEST_OUTPUT_DEVICES_PARAMS_DEF[\"spike_recorder\"].copy()\n",
    "            params_spike_recorder[\"record_to\"] = \"memory\"\n",
    "            params_multimeter = config.NEST_OUTPUT_DEVICES_PARAMS_DEF[\"multimeter\"].copy()\n",
    "            params_multimeter[\"record_to\"] = \"memory\"\n",
    "            params_multimeter[\"interval\"] = 1.0\n",
    "            for pop in [\"E\", \"I\"]:\n",
    "                nest_network.output_devices[pop] = DeviceSet(label=pop, model=\"spike_recorder\")\n",
    "                pop_lbl = np.where(pop == \"E\", \"Excitatory\", \"Inhibitory\").item()\n",
    "                nest_network.output_devices[pop_lbl] = DeviceSet(label=pop_lbl, model=\"multimeter\")\n",
    "                for node_ind in nest_nodes_inds:\n",
    "                    region_name = sim_serial['connectivity.region_labels'][node_ind]\n",
    "                    # region_name = simulator.connectivity.region_labels[node_ind]\n",
    "\n",
    "                    # Create and connect population spike recorder for this region:\n",
    "                    nest_network.output_devices[pop][region_name] = \\\n",
    "                        NESTSpikeRecorder(nest.Create(\"spike_recorder\", 1, params=params_spike_recorder), \n",
    "                                          nest, model=\"spike_recorder\", label=pop, brain_region=region_name)\n",
    "                    nest.Connect(nest_network.brain_regions[region_name][pop].nodes, \n",
    "                                 nest_network.output_devices[pop][region_name].device)\n",
    "                    nest_network.output_devices[pop].update() # update DeviceSet after the new NESTDevice entry\n",
    "                    print(\"\\n...created spike_recorder device for population %s in brain region %s...\" % (pop, region_name))\n",
    "\n",
    "                    # Create and connect population multimeter for this region:\n",
    "                    nest_network.output_devices[pop_lbl][region_name] = \\\n",
    "                        NESTMultimeter(nest.Create(\"multimeter\", 1, params=params_multimeter), \n",
    "                                       nest, model=\"multimeter\", label=pop_lbl, brain_region=region_name)\n",
    "                    nest.Connect(nest_network.output_devices[pop_lbl][region_name].device, \n",
    "                                 nest_network.brain_regions[region_name][pop].nodes)\n",
    "                    nest_network.output_devices[pop_lbl].update() # update DeviceSet after the new NESTDevice entry\n",
    "                    print(\"\\n...created multimeter device for population %s in brain region %s...\" % (pop, region_name))\n",
    "\n",
    "\n",
    "            # Create input stimulation devices:\n",
    "            nest_network.input_devices[\"Stimulus\"] = DeviceSet(label=\"Stimulus\", model=\"poisson_generator\")\n",
    "            nest_dt = nest.GetKernelStatus('resolution')\n",
    "            for node_ind in nest_nodes_inds:\n",
    "                    region_name = sim_serial['connectivity.region_labels'][node_ind]\n",
    "                    # region_name = simulator.connectivity.region_labels[node_ind]\n",
    "                    # Create and connect population spike recorder for this region:\n",
    "                    nest_network.input_devices[\"Stimulus\"][region_name] = \\\n",
    "                        NESTPoissonGenerator(nest.Create(\"poisson_generator\", 1, \n",
    "                                                         params={\"rate\": 7000.0, \"origin\": 0.0, \"start\": nest_dt}), \n",
    "                                             nest, model=\"poisson_generator\", label=\"Stimulus\", brain_region=region_name)\n",
    "                    nest.Connect(nest_network.input_devices[\"Stimulus\"][region_name].device,\n",
    "                                 nest_network.brain_regions[region_name][\"E\"].nodes, \n",
    "                                 syn_spec={\"weight\": 1.0, \"delay\": nest_dt})\n",
    "                    nest_network.input_devices[\"Stimulus\"].update()  # update DeviceSet after the new NESTDevice entry\n",
    "                    print(\"\\n...created poisson_generator device for population E in brain region %s...\" % region_name)   \n",
    "\n",
    "\n",
    "\n",
    "        # Configure NESTNetwork class:\n",
    "        nest_network.configure()\n",
    "        nest_network.print_summary_info_details(recursive=3, connectivity=True)\n",
    "\n",
    "    else:\n",
    "        nest_nodes_inds = np.array([])\n",
    "        \n",
    "    return nest_network, nest_nodes_inds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:19:09.725185Z",
     "start_time": "2019-07-11T10:19:09.721072Z"
    }
   },
   "source": [
    "## FRONTEND: 3. Build the TVB-NEST interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# options for a nonopinionated builder:\n",
    "from tvb_multiscale.core.interfaces.base.transformers.models.models import Transformers\n",
    "from tvb_multiscale.core.interfaces.base.transformers.builders import \\\n",
    "        DefaultTVBtoSpikeNetTransformers, DefaultSpikeNetToTVBTransformers, \\\n",
    "        DefaultTVBtoSpikeNetModels, DefaultSpikeNetToTVBModels\n",
    "from tvb_multiscale.tvb_nest.interfaces.builders import \\\n",
    "        TVBtoNESTModels, NESTInputProxyModels, DefaultTVBtoNESTModels, \\\n",
    "        NESTtoTVBModels, NESTOutputProxyModels, DefaultNESTtoTVBModels\n",
    "\n",
    "    \n",
    "    \n",
    "def print_enum(enum):\n",
    "    print(\"\\n\", enum)\n",
    "    for name, member in enum.__members__.items():\n",
    "        print(name,\"= \", member.value)\n",
    "    \n",
    "    \n",
    "print(\"Available input (NEST->TVB update) / output (TVB->NEST coupling) interface models:\")\n",
    "print_enum(TVBtoNESTModels)\n",
    "print_enum(NESTtoTVBModels)\n",
    "    \n",
    "    \n",
    "print(\"\\n\\nAvailable input (spikeNet->TVB update) / output (TVB->spikeNet coupling) transformer models:\")\n",
    "\n",
    "print_enum(DefaultTVBtoSpikeNetModels)\n",
    "print_enum(DefaultTVBtoSpikeNetTransformers)\n",
    "    \n",
    "print_enum(DefaultSpikeNetToTVBModels)\n",
    "print_enum(DefaultSpikeNetToTVBTransformers)    \n",
    "    \n",
    "    \n",
    "print(\"\\n\\nAvailable input (NEST->TVB update) / output (TVB->NEST coupling) proxy models:\")\n",
    "\n",
    "print_enum(DefaultTVBtoNESTModels)\n",
    "print_enum(NESTInputProxyModels)\n",
    "    \n",
    "print_enum(NESTOutputProxyModels)\n",
    "print_enum(DefaultNESTtoTVBModels)\n",
    "    \n",
    "print(\"\\n\\nAll basic transformer models:\")\n",
    "print_enum(Transformers)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:11.137992Z",
     "start_time": "2019-07-12T20:36:10.880947Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_TVB_interface(simulator=None):\n",
    "    \n",
    "    config, SIM_MODE, n_regions, NEST_MODEL_BUILDERS, nest_nodes_inds, n_neurons = configure()\n",
    "\n",
    "    tvb_interface_builder = None\n",
    "    if np.all(SIM_MODE.lower() == \"tvb-nest\"):\n",
    "\n",
    "        from tvb_multiscale.core.interfaces.tvb.builders import TVBRemoteInterfaceBuilder   \n",
    "        tvb_interface_builder =  TVBRemoteInterfaceBuilder(config=config)  # non opinionated builder\n",
    "\n",
    "    \n",
    "    if tvb_interface_builder is not None:\n",
    "        if simulator is not None:\n",
    "            tvb_interface_builder.tvb_cosimulator = simulator\n",
    "        # This can be used to set default tranformer and proxy models:\n",
    "        tvb_interface_builder.model = \"RATE\"          # \"RATE\" (or \"SPIKES\", \"CURRENT\") TVB->NEST interface\n",
    "        tvb_interface_builder.input_label = \"TransToTVB\"\n",
    "        tvb_interface_builder.output_label = \"TVBtoTrans\"\n",
    "        # If default_coupling_mode = \"TVB\", large scale coupling towards spiking regions is computed in TVB\n",
    "        # and then applied with no time delay via a single \"TVB proxy node\" / NEST device for each spiking region,\n",
    "        # \"1-to-1\" TVB->NEST coupling.\n",
    "        # If any other value, we need 1 \"TVB proxy node\" / NEST device for each TVB sender region node, and\n",
    "        # large-scale coupling for spiking regions is computed in NEST, \n",
    "        # taking into consideration the TVB connectome weights and delays, \n",
    "        # in this \"1-to-many\" TVB->NEST coupling.\n",
    "        tvb_interface_builder.default_coupling_mode = \"TVB\" \n",
    "        tvb_interface_builder.proxy_inds = nest_nodes_inds\n",
    "        # Set exclusive_nodes = True (Default) if the spiking regions substitute for the TVB ones:\n",
    "        tvb_interface_builder.exclusive_nodes = True  \n",
    "\n",
    "        tvb_interface_builder.output_interfaces = []\n",
    "        tvb_interface_builder.input_interfaces = []\n",
    "    \n",
    "    return tvb_interface_builder, nest_nodes_inds\n",
    "\n",
    "\n",
    "def prepare_TVBtoSpikeNet_transformer_interface():\n",
    "    \n",
    "    config, SIM_MODE, n_regions, NEST_MODEL_BUILDERS, nest_nodes_inds, n_neurons = configure()\n",
    "\n",
    "    tvb_to_spikeNet_trans_interface_builder = None\n",
    "    if np.all(SIM_MODE.lower() == \"tvb-nest\"):\n",
    "\n",
    "        from tvb_multiscale.core.interfaces.base.builders import TVBtoSpikeNetRemoteTransformerBuilder   \n",
    "        tvb_to_spikeNet_trans_interface_builder = \\\n",
    "            TVBtoSpikeNetRemoteTransformerBuilder(config=config)  # non opinionated builder\n",
    "\n",
    "\n",
    "    if tvb_to_spikeNet_trans_interface_builder is not None:\n",
    "\n",
    "        from tvb_multiscale.core.utils.file_utils import load_pickled_dict\n",
    "        sim_serial_filepath = os.path.join(config.out.FOLDER_RES, \"tvb_serial_cosimulator.pkl\")\n",
    "        if not os.path.isfile(sim_serial_filepath):\n",
    "            # In order to be independent create a TVB simulator, serialize it and write it to file:\n",
    "            build_tvb_simulator();\n",
    "        tvb_to_spikeNet_trans_interface_builder.tvb_simulator_serialized = load_pickled_dict(sim_serial_filepath)\n",
    "        \n",
    "        # This can be used to set default tranformer and proxy models:\n",
    "        tvb_to_spikeNet_trans_interface_builder.model = \"RATE\"          # \"RATE\" (or \"SPIKES\", \"CURRENT\") TVB->NEST interface\n",
    "        tvb_to_spikeNet_trans_interface_builder.input_label = \"TVBtoTrans\"\n",
    "        tvb_to_spikeNet_trans_interface_builder.output_label = \"TransToSpikeNet\"\n",
    "        # If default_coupling_mode = \"TVB\", large scale coupling towards spiking regions is computed in TVB\n",
    "        # and then applied with no time delay via a single \"TVB proxy node\" / NEST device for each spiking region,\n",
    "        # \"1-to-1\" TVB->NEST coupling.\n",
    "        # If any other value, we need 1 \"TVB proxy node\" / NEST device for each TVB sender region node, and\n",
    "        # large-scale coupling for spiking regions is computed in NEST, \n",
    "        # taking into consideration the TVB connectome weights and delays, \n",
    "        # in this \"1-to-many\" TVB->NEST coupling.\n",
    "        tvb_to_spikeNet_trans_interface_builder.proxy_inds = nest_nodes_inds\n",
    "        tvb_to_spikeNet_trans_interface_builder.N_E = n_neurons\n",
    "        tvb_to_spikeNet_trans_interface_builder.N_I = n_neurons\n",
    "\n",
    "        tvb_to_spikeNet_trans_interface_builder.output_interfaces = []\n",
    "        tvb_to_spikeNet_trans_interface_builder.input_interfaces = []\n",
    "        \n",
    "    return tvb_to_spikeNet_trans_interface_builder\n",
    "\n",
    "\n",
    "def prepare_spikeNetToTVB_transformer_interface():\n",
    "    \n",
    "    config, SIM_MODE, n_regions, NEST_MODEL_BUILDERS, nest_nodes_inds, n_neurons = configure()\n",
    "\n",
    "    spikeNet_to_tvb_trans_interface_builder = None\n",
    "    if np.all(SIM_MODE.lower() == \"tvb-nest\"):\n",
    "\n",
    "        from tvb_multiscale.core.interfaces.base.builders import SpikeNetToTVBRemoteTransformerBuilder   \n",
    "        spikeNet_to_tvb_trans_interface_builder = \\\n",
    "            SpikeNetToTVBRemoteTransformerBuilder(config=config)  # non opinionated builder\n",
    "\n",
    "\n",
    "    if spikeNet_to_tvb_trans_interface_builder is not None:\n",
    "\n",
    "        from tvb_multiscale.core.utils.file_utils import load_pickled_dict\n",
    "        sim_serial_filepath = os.path.join(config.out.FOLDER_RES, \"tvb_serial_cosimulator.pkl\")\n",
    "        if not os.path.isfile(sim_serial_filepath):\n",
    "            # In order to be independent create a TVB simulator, serialize it and write it to file:\n",
    "            build_tvb_simulator();\n",
    "        spikeNet_to_tvb_trans_interface_builder.tvb_simulator_serialized = load_pickled_dict(sim_serial_filepath)\n",
    "        \n",
    "        # This can be used to set default tranformer and proxy models:\n",
    "        spikeNet_to_tvb_trans_interface_builder.model = \"RATE\"          # \"RATE\" (or \"SPIKES\", \"CURRENT\") TVB->NEST interface\n",
    "        spikeNet_to_tvb_trans_interface_builder.input_label = \"spikeNetToTrans\"\n",
    "        spikeNet_to_tvb_trans_interface_builder.output_label = \"TransToTVB\"\n",
    "        # If default_coupling_mode = \"TVB\", large scale coupling towards spiking regions is computed in TVB\n",
    "        # and then applied with no time delay via a single \"TVB proxy node\" / NEST device for each spiking region,\n",
    "        # \"1-to-1\" TVB->NEST coupling.\n",
    "        # If any other value, we need 1 \"TVB proxy node\" / NEST device for each TVB sender region node, and\n",
    "        # large-scale coupling for spiking regions is computed in NEST, \n",
    "        # taking into consideration the TVB connectome weights and delays, \n",
    "        # in this \"1-to-many\" TVB->NEST coupling.\n",
    "        spikeNet_to_tvb_trans_interface_builder.proxy_inds = nest_nodes_inds\n",
    "        spikeNet_to_tvb_trans_interface_builder.N_E = n_neurons\n",
    "        spikeNet_to_tvb_trans_interface_builder.N_I = n_neurons\n",
    "\n",
    "        spikeNet_to_tvb_trans_interface_builder.output_interfaces = []\n",
    "        spikeNet_to_tvb_trans_interface_builder.input_interfaces = []\n",
    "        \n",
    "    return spikeNet_to_tvb_trans_interface_builder\n",
    "\n",
    "\n",
    "def prepare_spikeNet_interface_builder(nest_network=None):\n",
    "\n",
    "    config, SIM_MODE, n_regions, NEST_MODEL_BUILDERS, nest_nodes_inds, n_neurons = configure()\n",
    "\n",
    "    spikeNet_interface_builder = None\n",
    "    if np.all(SIM_MODE.lower() == \"tvb-nest\"):\n",
    "\n",
    "\n",
    "        # ---------------------------- Non opinionated TVB<->NEST interface builder----------------------------\n",
    "        from tvb_multiscale.tvb_nest.interfaces.builders import NESTRemoteInterfaceBuilder   \n",
    "        spikeNet_interface_builder = \\\n",
    "            NESTRemoteInterfaceBuilder(config=config)  # non opinionated builder\n",
    "        \n",
    "        if nest_network:\n",
    "            spikeNet_interface_builder.spiking_network = nest_network\n",
    "        \n",
    "        from tvb_multiscale.core.utils.file_utils import load_pickled_dict\n",
    "        sim_serial_filepath = os.path.join(config.out.FOLDER_RES, \"tvb_serial_cosimulator.pkl\")\n",
    "        if not os.path.isfile(sim_serial_filepath):\n",
    "            # In order to be independent create a TVB simulator, serialize it and write it to file:\n",
    "            build_tvb_simulator();\n",
    "        spikeNet_interface_builder.tvb_simulator_serialized = load_pickled_dict(sim_serial_filepath)\n",
    "        \n",
    "        # This can be used to set default tranformer and proxy models:\n",
    "        spikeNet_interface_builder.model = \"RATE\"          # \"RATE\" (or \"SPIKES\", \"CURRENT\") TVB->NEST interface\n",
    "        spikeNet_interface_builder.input_label = \"TransToSpikeNet\"\n",
    "        spikeNet_interface_builder.output_label = \"spikeNetToTrans\"\n",
    "        # If default_coupling_mode = \"TVB\", large scale coupling towards spiking regions is computed in TVB\n",
    "        # and then applied with no time delay via a single \"TVB proxy node\" / NEST device for each spiking region,\n",
    "        # \"1-to-1\" TVB->NEST coupling.\n",
    "        # If any other value, we need 1 \"TVB proxy node\" / NEST device for each TVB sender region node, and\n",
    "        # large-scale coupling for spiking regions is computed in NEST, \n",
    "        # taking into consideration the TVB connectome weights and delays, \n",
    "        # in this \"1-to-many\" TVB->NEST coupling.\n",
    "        spikeNet_interface_builder.default_coupling_mode = \"TVB\" \n",
    "        if nest_network is None:\n",
    "            # Number of neurons per population to be used to compute population mean instantaneous firing rates:\n",
    "            spikeNet_interface_builder.N_E = n_neurons\n",
    "            spikeNet_interface_builder.N_I = n_neurons\n",
    "        else:\n",
    "            # Number of neurons per population to be used to compute population mean instantaneous firing rates:\n",
    "            spikeNet_interface_builder.N_E = nest_network.brain_regions[nest_nodes_inds[0]][\"E\"].number_of_neurons\n",
    "            spikeNet_interface_builder.N_I = nest_network.brain_regions[nest_nodes_inds[0]][\"I\"].number_of_neurons\n",
    "        spikeNet_interface_builder.proxy_inds = nest_nodes_inds\n",
    "        # Set exclusive_nodes = True (Default) if the spiking regions substitute for the TVB ones:\n",
    "        spikeNet_interface_builder.exclusive_nodes = True  \n",
    "\n",
    "        spikeNet_interface_builder.output_interfaces = []\n",
    "        spikeNet_interface_builder.input_interfaces = []\n",
    "        \n",
    "    return spikeNet_interface_builder, nest_nodes_inds\n",
    "\n",
    "\n",
    "\n",
    "def configure_TVB_interfaces(simulator=None):\n",
    "    \n",
    "    tvb_interface_builder, nest_nodes_inds = prepare_TVB_interface(simulator=simulator)\n",
    "\n",
    "    # or setting a nonopinionated builder:\n",
    "\n",
    "    # This is a user defined TVB -> Spiking Network interface configuration:\n",
    "    tvb_interface_builder.output_interfaces = \\\n",
    "            [{'voi': np.array([\"E\"]),         # TVB state variable to get data from\n",
    "              # --------------- Arguments that can default if not given by the user:------------------------------\n",
    "              'model': 'RATE',                # This can be used to set default tranformer and proxy models\n",
    "              'coupling_mode': 'TVB',         # or \"spikeNet\", \"NEST\", etc\n",
    "              'proxy_inds': nest_nodes_inds  # TVB proxy region nodes' indices\n",
    "             }\n",
    "            ]\n",
    "\n",
    "    # These are user defined Spiking Network -> TVB interfaces configurations:\n",
    "    for pop, sv in zip([\"E\", \"I\"], [\"E\", \"I\"]):\n",
    "        tvb_interface_builder.input_interfaces.append(\n",
    "               {'voi': np.array([sv]),\n",
    "                'proxy_inds': nest_nodes_inds\n",
    "               }\n",
    "            )\n",
    "\n",
    "\n",
    "    # This is how the user defined TVB -> Spiking Network interface looks after configuration\n",
    "    print(\"\\noutput (TVB-> coupling) interfaces' configurations:\\n\")\n",
    "    display(tvb_interface_builder.output_interfaces)\n",
    "\n",
    "    # This is how the user defined Spiking Network -> TVB interfaces look after configuration\n",
    "    print(\"\\ninput (TVB<- update) interfaces' configurations:\\n\")\n",
    "    display(tvb_interface_builder.input_interfaces)\n",
    "    \n",
    "    tvb_interface_builder.dump_all_interfaces()\n",
    "        \n",
    "    return tvb_interface_builder\n",
    "\n",
    "\n",
    "def configure_TVBtoSpikeNet_transformer_interfaces():\n",
    "    \n",
    "    tvb_to_spikeNet_trans_interface_builder = prepare_TVBtoSpikeNet_transformer_interface()\n",
    "\n",
    "    # or setting a nonopinionated builder:\n",
    "    from tvb_multiscale.core.interfaces.tvb.interfaces import TVBtoSpikeNetModels\n",
    "\n",
    "    # This is a user defined TVB -> Spiking Network interface configuration:\n",
    "    tvb_to_spikeNet_trans_interface_builder.output_interfaces = \\\n",
    "            [{# Set the enum entry or the corresponding label name for the \"transformer_model\", \n",
    "              # or import and set the appropriate tranformer class, e.g., ScaleRate, directly\n",
    "              # options: \"RATE\", \"SPIKES\", \"SPIKES_SINGE_INTERACTION\", \"SPIKES_MULTIPLE_INTERACTION\", \"CURRENT\"\n",
    "              # see tvb_multiscale.core.interfaces.base.transformers.models.DefaultTVBtoSpikeNetTransformers for options and related Transformer classes,\n",
    "              # and tvb_multiscale.core.interfaces.base.transformers.models.DefaultTVBtoSpikeNetModels for default choices\n",
    "              'transformer_model': \"RATE\" \n",
    "             }\n",
    "            ]\n",
    "\n",
    "    for interface in tvb_to_spikeNet_trans_interface_builder.output_interfaces:\n",
    "        # The \"scale_factor\" scales the TVB state variable to convert it to an \n",
    "        # instantaneous rate:\n",
    "        if tvb_to_spikeNet_trans_interface_builder.model == TVBtoSpikeNetModels.SPIKES.name:\n",
    "            # The \"number_of_neurons\" will determine how many spike trains will be generated:\n",
    "            interface[\"transformer_params\"] = \\\n",
    "                        {\"scale_factor\": np.array([100]),\n",
    "                         \"number_of_neurons\": np.array([tvb_to_spikeNet_trans_interface_builder.N_E])}\n",
    "        else:  # RATE\n",
    "            # Here the rate is a total rate, assuming a number of sending neurons:\n",
    "            interface[\"transformer_params\"] = {\"scale_factor\": \n",
    "                                                1e6 * np.array([tvb_to_spikeNet_trans_interface_builder.N_E])}\n",
    "\n",
    "\n",
    "    # This is how the user defined TVB -> Spiking Network interface looks after configuration\n",
    "    print(\"\\noutput (->Transformer-> coupling) interfaces' configurations:\\n\")\n",
    "    display(tvb_to_spikeNet_trans_interface_builder.output_interfaces)\n",
    "    \n",
    "    tvb_to_spikeNet_trans_interface_builder.dump_all_interfaces()\n",
    "        \n",
    "    return tvb_to_spikeNet_trans_interface_builder\n",
    "\n",
    "\n",
    "def configure_spikeNetToTVB_transformer_interfaces():\n",
    "    \n",
    "    spikeNet_to_TVB_transformer_interface_builder = prepare_spikeNetToTVB_transformer_interface()\n",
    "\n",
    "    for ii, N in enumerate([spikeNet_to_TVB_transformer_interface_builder.N_E, \n",
    "                            spikeNet_to_TVB_transformer_interface_builder.N_I]):\n",
    "        spikeNet_to_TVB_transformer_interface_builder.input_interfaces.append(\n",
    "            {# Set the enum entry or the corresponding label name for the \"transformer_model\", \n",
    "             # or import and set the appropriate tranformer class, e.g., ElephantSpikesHistogramRate, directly\n",
    "             # options: \"SPIKES\", \"SPIKES_TO_RATE\", \"SPIKES_TO_HIST\", \"SPIKES_TO_HIST_RATE\"\n",
    "             # see tvb_multiscale.core.interfaces.base.transformers.models.DefaultSpikeNetToTVBTransformers for options and related Transformer classes,\n",
    "             # and tvb_multiscale.core.interfaces.base.transformers.models.DefaultSpikeNetToTVBModels for default choices\n",
    "             \"transformer_model\": \"SPIKES_TO_HIST_RATE\",\n",
    "             # The \"scale_factor\" scales the instantaneous rate coming from NEST, before setting it to TVB,\n",
    "             # in our case converting the rate to a mean reate \n",
    "             # and scaling it to be in the TVB model's state variable range [0.0, 1.0]\n",
    "             \"transformer_params\": {\"scale_factor\": np.array([1e-4]) / N}\n",
    "               })\n",
    "\n",
    "    # This is how the user defined Spiking Network -> TVB interfaces look after configuration\n",
    "    print(\"\\ninput (TVB<-...-Transformer<-...-spikeNet update) interfaces' configurations:\\n\")\n",
    "    display(spikeNet_to_TVB_transformer_interface_builder.input_interfaces)\n",
    "\n",
    "    spikeNet_to_TVB_transformer_interface_builder.dump_all_interfaces()\n",
    "        \n",
    "    return spikeNet_to_TVB_transformer_interface_builder\n",
    "\n",
    "\n",
    "def configure_spikeNet_interfaces(nest_network=None):\n",
    "    \n",
    "    spikeNet_interface_builder, nest_nodes_inds = prepare_spikeNet_interface_builder(nest_network)\n",
    "    \n",
    "    #     # Using all default parameters for this example of an opinionated builder\n",
    "    #     tvb_spikeNet_model_builder.default_config()\n",
    "\n",
    "\n",
    "    # or setting a nonopinionated builder:\n",
    "\n",
    "    # This is a user defined TVB -> Spiking Network interface configuration:\n",
    "    spikeNet_interface_builder.input_interfaces = \\\n",
    "            [{'populations': np.array([\"E\"]), # NEST populations to couple to\n",
    "            # --------------- Arguments that can default if not given by the user:------------------------------\n",
    "              'model': 'RATE',                # This can be used to set default tranformer and proxy models\n",
    "              'coupling_mode': 'TVB',         # or \"spikeNet\", \"NEST\", etc\n",
    "              'proxy_inds': nest_nodes_inds,  # TVB proxy region nodes' indices\n",
    "              # Set the enum entry or the corresponding label name for the \"proxy_model\", \n",
    "              # or import and set the appropriate NEST proxy device class, e.g., NESTInhomogeneousPoissonGeneratorSet, directly\n",
    "              # options: \"RATE\", \"RATE_TO_SPIKES\", SPIKES\", \"PARROT_SPIKES\" or CURRENT\"\n",
    "              # see tvb_multiscale.tvb_nest.interfaces.io.NESTInputProxyModels for options and related NESTDevice classes, \n",
    "              # and tvb_multiscale.tvb_nest.interfaces.io.DefaultTVBtoNESTModels for the default choices\n",
    "              'proxy_model': \"RATE\",  \n",
    "              'spiking_proxy_inds': nest_nodes_inds  # Same as \"proxy_inds\" for this kind of interface\n",
    "             }\n",
    "            ]\n",
    "\n",
    "    # These are user defined Spiking Network -> TVB interfaces configurations:\n",
    "    for pop in [\"E\", \"I\"]:\n",
    "        spikeNet_interface_builder.output_interfaces.append(\n",
    "               {'populations': np.array([pop]),\n",
    "                'proxy_inds': nest_nodes_inds,\n",
    "                # --------------- Arguments that can default if not given by the user:------------------------------\n",
    "                # Set the enum entry or the corresponding label name for the \"proxy_model\", \n",
    "                # or import and set the appropriate NEST proxy device class, e.g., NESTSpikeRecorderMeanSet, directly\n",
    "                # options \"SPIKES\" (i.e., spikes per neuron), \"SPIKES_MEAN\", \"SPIKES_TOTAL\" \n",
    "                # (the last two are identical for the moment returning all populations spikes together)\n",
    "                # see tvb_multiscale.tvb_nest.interfaces.io.NESTOutputProxyModels for options and related NESTDevice classes, \n",
    "                # and tvb_multiscale.tvb_nest.interfaces.io.DefaultNESTtoTVBModels for the default choices\n",
    "                'proxy_model': \"SPIKES_MEAN\",  \n",
    "               }\n",
    "            )\n",
    "\n",
    "    # This is how the user defined TVB -> Spiking Network interface looks after configuration\n",
    "    print(\"\\noutput (NEST -> coupling) interfaces' configurations:\\n\")\n",
    "    display(spikeNet_interface_builder.output_interfaces)\n",
    "\n",
    "    # This is how the user defined Spiking Network -> TVB interfaces look after configuration\n",
    "    print(\"\\ninput (NEST <- update) interfaces' configurations:\\n\")\n",
    "    display(spikeNet_interface_builder.input_interfaces)\n",
    "    \n",
    "    spikeNet_interface_builder.dump_all_interfaces()\n",
    "        \n",
    "    return spikeNet_interface_builder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_TVB_interfaces(simulator, tvb_interface_builder=None):\n",
    "    \n",
    "    if tvb_interface_builder is None:\n",
    "        tvb_interface_builder = prepare_TVB_interface(simulator=simulator)[0]\n",
    "    else:\n",
    "        tvb_interface_builder.tvb_cosimulator = simulator\n",
    "    \n",
    "    # Load TVB interfaces configurations\n",
    "    tvb_interface_builder.load_all_interfaces()\n",
    "    \n",
    "    # Configure TVB interfaces' builder:\n",
    "    tvb_interface_builder.configure()\n",
    "    # tvb_interface_builder.print_summary_info_details(recursive=1)\n",
    "    \n",
    "    # Build interfaces and attach them to TVB simulator\n",
    "    simulator = tvb_interface_builder.build()\n",
    "    \n",
    "    # simulator.print_summary_info(recursive=3)\n",
    "    # simulator.print_summary_info_details(recursive=3)\n",
    "\n",
    "    print(\"\\n\\noutput (TVB-> coupling) interfaces:\\n\")\n",
    "    simulator.output_interfaces.print_summary_info_details(recursive=2)\n",
    "    \n",
    "    print(\"\\n\\ninput (TVB<- update) interfaces:\\n\")\n",
    "    simulator.input_interfaces.print_summary_info_details(recursive=2)\n",
    "    \n",
    "    return simulator\n",
    "\n",
    "\n",
    "def build_TVBtoSpikeNet_transformer_interfaces(tvb_to_spikeNet_trans_interface_builder=None):\n",
    "    \n",
    "    if tvb_to_spikeNet_trans_interface_builder is None:\n",
    "        tvb_to_spikeNet_trans_interface_builder = prepare_TVBtoSpikeNet_transformer_interface()\n",
    "        \n",
    "    # Load TVB to spikeNet interfaces configurations\n",
    "    tvb_to_spikeNet_trans_interface_builder.load_all_interfaces()\n",
    "    \n",
    "    # Configure TVB to spikeNet interfaces' builder:\n",
    "    tvb_to_spikeNet_trans_interface_builder.configure()\n",
    "    # tvb_to_spikeNet_trans_interface_builder.print_summary_info_details(recursive=1)\n",
    "    \n",
    "    # Build TVB to spikeNet interfaces\n",
    "    tvb_to_spikeNet_trans_interfaces = tvb_to_spikeNet_trans_interface_builder.build()\n",
    "\n",
    "    print(\"\\n\\noutput (TVB -> ... -> Transformer -> ... -> spikeNet coupling) interfaces:\\n\")\n",
    "    tvb_to_spikeNet_trans_interfaces.print_summary_info_details(recursive=2)\n",
    "    \n",
    "    return tvb_to_spikeNet_trans_interfaces\n",
    "\n",
    "\n",
    "def build_spikeNetToTVB_transformer_interfaces(spikeNet_to_tvb_trans_interface_builder=None):\n",
    "    \n",
    "    if spikeNet_to_tvb_trans_interface_builder is None:\n",
    "        spikeNet_to_tvb_trans_interface_builder = prepare_spikeNetToTVB_transformer_interface()\n",
    "    \n",
    "    # Load spikeNet to TVB interfaces configurations\n",
    "    spikeNet_to_tvb_trans_interface_builder.load_all_interfaces()\n",
    "    \n",
    "    # Configure spikeNet to TVB interfaces' builder:\n",
    "    spikeNet_to_tvb_trans_interface_builder.configure()\n",
    "    # spikeNet_to_tvb_trans_interface_builder.print_summary_info_details(recursive=1)\n",
    "    \n",
    "    # Build spikeNet to TVB interfaces\n",
    "    spikeNet_to_tvb_trans_interfaces = spikeNet_to_tvb_trans_interface_builder.build()\n",
    "\n",
    "    print(\"\\n\\ninput (TVB<- ... <- Transformer <- ... <- spikeNet update) interfaces:\\n\")\n",
    "    spikeNet_to_tvb_trans_interfaces.print_summary_info_details(recursive=2)\n",
    "    \n",
    "    return spikeNet_to_tvb_trans_interfaces\n",
    "\n",
    "\n",
    "def build_spikeNet_interfaces(nest_network, spikeNet_interface_builder=None):\n",
    "    \n",
    "    if spikeNet_interface_builder is None:\n",
    "        spikeNet_interface_builder = prepare_spikeNet_interface_builder(nest_network)[0]\n",
    "    \n",
    "    # Load spikeNet interfaces configurations\n",
    "    spikeNet_interface_builder.load_all_interfaces()\n",
    "    \n",
    "    # Configure spikeNet interfaces' builder:\n",
    "    spikeNet_interface_builder.configure()\n",
    "    # spikeNet_interface_builder.print_summary_info_details(recursive=1)\n",
    "    \n",
    "    # Build spikeNet interfaces and attach them to spikeNet simulator\n",
    "    nest_network = spikeNet_interface_builder.build()\n",
    "\n",
    "    print(\"\\n\\noutput (TVB->NEST coupling) interfaces:\\n\")\n",
    "    nest_network.output_interfaces.print_summary_info_details(recursive=2)\n",
    "    \n",
    "    print(\"\\n\\ninput (NEST->TVB update) interfaces:\\n\")\n",
    "    nest_network.input_interfaces.print_summary_info_details(recursive=2)\n",
    "    \n",
    "    return nest_network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure simulator, simulate, gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:18.879872Z",
     "start_time": "2019-07-12T20:36:11.148945Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def simulate(simulation_length, simulator, nest_network):\n",
    "    \n",
    "    # Configure the simulator with the TVB-NEST interface...\n",
    "    # ...and simulate!\n",
    "\n",
    "    # Set the simulation time:\n",
    "    simulator.simulation_length = 1100.0\n",
    "\n",
    "    tic = time.time()\n",
    "    if np.all(SIM_MODE.lower() == \"tvb\"):\n",
    "        # For TVB \n",
    "        results = simulator.run()\n",
    "    else:\n",
    "        if np.all(SIM_MODE.lower() == \"nest\"):\n",
    "            print(\"Simulating only NEST...\")\n",
    "            # Integrate NEST for simulation_length + 1 NEST time step so that multimeters get the last time point\n",
    "            # unless you plan to continue simulation later\n",
    "            nest_network.nest_instance.Simulate(simulator.simulation_length + nest_network.nest_instance.GetKernelStatus(\"resolution\"))\n",
    "            results = None\n",
    "        else:\n",
    "            print(\"Simulating TVB-NEST...\")\n",
    "            nest_network.nest_instance.Prepare()\n",
    "            simulator.configure()\n",
    "            # Adjust simulation length to be an integer multiple of synchronization_time:\n",
    "            simulator.simulation_length = \\\n",
    "                np.ceil(simulator.simulation_length / simulator.synchronization_time) * simulator.synchronization_time\n",
    "            simulation_length = simulator.simulation_length\n",
    "            results = simulator.run()\n",
    "            nest_network.nest_instance.Run(nest_network.nest_instance.GetKernelStatus(\"resolution\"))\n",
    "            #  Cleanup NEST network unless you plan to continue simulation later\n",
    "            nest_network.nest_instance.Cleanup()\n",
    "    print(\"\\nSimulated in %f secs!\" % (time.time() - tic))\n",
    "    \n",
    "    return results, simulator, nest_network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frontEnd_TVB():\n",
    "    # This function will configure the TVB <-> Transformer <-> interfaces' builder\n",
    "    # and write the configurations to files    \n",
    "    return configure_TVB_interfaces() # not necessary to return anything\n",
    "\n",
    "    \n",
    "def backEnd_TVB(simulation_length, simulator=None, plotter=None):\n",
    "\n",
    "    if simulator is None:\n",
    "        # Build TVB simulator\n",
    "        simulator = build_tvb_simulator()\n",
    "    \n",
    "    if plotter is None:\n",
    "        from tvb_multiscale.core.plot.plotter import Plotter\n",
    "        plotter = Plotter(config.figures)\n",
    "    \n",
    "    plotter.plot_tvb_connectivity(simulator.connectivity);\n",
    "    \n",
    "    # Build TVB interfaces and attach them to TVB simulator\n",
    "    simulator = build_TVB_interfaces(simulator, tvb_interface_builder=None)\n",
    "\n",
    "    # results = simulate_TVB(simulator, simulation_length)\n",
    "    \n",
    "    return simulator  # results\n",
    "\n",
    "\n",
    "def frontEnd_spikeNet():\n",
    "    # This function configure the NEST <-> interfaces\n",
    "    # and write the configurations to files\n",
    "    return configure_spikeNet_interfaces() # not necessary to return anything\n",
    "\n",
    "\n",
    "def backEnd_spikeNet(simulation_length):\n",
    "    \n",
    "    # Build the spikeNet simulator\n",
    "    nest_network, nest_nodes_inds = build_nest_network()\n",
    "\n",
    "    # Build the spikeNet interfaces and attach them to the spikeNet network\n",
    "    nest_network = build_spikeNet_interfaces(nest_network, spikeNet_interface_builder=None)\n",
    "\n",
    "    # Configure the interfaces\n",
    "    if nest_network.input_interfaces:\n",
    "        nest_network.input_interfaces.configure()\n",
    "    if nest_network.output_interfaces:\n",
    "        nest_network.output_interfaces.configure()\n",
    "        \n",
    "    # simulate_spikeNet(nest_network, simulation_length)\n",
    "    \n",
    "    return nest_network \n",
    "\n",
    "\n",
    "def frontEnd_TVBtoSpikeNet():\n",
    "    return configure_TVBtoSpikeNet_transformer_interfaces() # not necessary to return anything\n",
    "    \n",
    "\n",
    "def backEnd_TVBtoSpikeNet():\n",
    "    # Build TVB to spikeNET interfaces\n",
    "    interfaces = build_TVBtoSpikeNet_transformer_interfaces()\n",
    "    if interfaces:\n",
    "        # ... configure them\n",
    "        interfaces.configure()\n",
    "        \n",
    "    # simulate_TVBtoSpikeNet(interfaces)  # a possible function to \"start interfaces running\"\n",
    "    \n",
    "    return interfaces\n",
    "\n",
    "\n",
    "def frontEnd_spikeNetToTVB():\n",
    "    return configure_spikeNetToTVB_transformer_interfaces() # not necessary to return anything\n",
    "\n",
    "\n",
    "def backEnd_spikeNetToTVB():\n",
    "    # Build spikeNET to TVB to x interfaces\n",
    "    interfaces = build_spikeNetToTVB_transformer_interfaces()\n",
    "    if interfaces:\n",
    "        # ... configure them\n",
    "        interfaces.configure()\n",
    "        \n",
    "    # simulate_spikeNetToTVB(interfaces)  # a possible function to \"start interfaces running\"\n",
    "    \n",
    "    return interfaces\n",
    "\n",
    "\n",
    "def frontEnd():\n",
    "    return frontEnd_TVB(), frontEnd_spikeNet(), frontEnd_TVBtoSpikeNet(), frontEnd_spikeNetToTVB()\n",
    "\n",
    "\n",
    "def simulate_spikeNet(simulation_length, nest_network):\n",
    "    \n",
    "    # Read input data from file interfaces and set the TVB proxies accordingly:\n",
    "    for interface in nest_network.input_interfaces.interfaces:\n",
    "        interface()\n",
    "\n",
    "    nest_network.nest_instance.Run(simulation_length)\n",
    "\n",
    "    # Get data from NEST recorders and set them to file interfaces for the TVB proxies\n",
    "    for interface in nest_network.output_interfaces.interfaces:\n",
    "        interface()\n",
    "            \n",
    "            \n",
    "def backEnd(simulation_length, simulator=None, plotter=None):\n",
    "    \n",
    "    simulator = backEnd_TVB(simulation_length)\n",
    "    nest_network = backEnd_spikeNet(simulation_length)\n",
    "    simulator.tvb_to_spikeNet_transform = backEnd_TVBtoSpikeNet()\n",
    "    simulator.spikeNet_to_tvb_transform = backEnd_spikeNetToTVB()\n",
    "    simulator.simulate_spiking_simulator = lambda simulation_length: simulate_spikeNet(simulation_length, nest_network)\n",
    "    \n",
    "    return simulate(simulation_length, simulator, nest_network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the whole workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config, SIM_MODE, n_regions, NEST_MODEL_BUILDERS, nest_nodes_inds, n_neurons = configure()\n",
    "\n",
    "FIGSIZE = config.figures.DEFAULT_SIZE\n",
    "\n",
    "from tvb_multiscale.core.plot.plotter import Plotter\n",
    "plotter = Plotter(config.figures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frontEnd()\n",
    "\n",
    "# tvb_interface_builder, tvb_to_spikeNet_trans_interface_builder, spikeNet_interface_builder = frontEnd()\n",
    "# spikeNet_interface_builder = frontEnd_spikeNet()\n",
    "# tvb_to_spikeNet_trans_interface_builder = frontEnd_TVBtoSpikeNet()\n",
    "# spikeNet_to_tvb_trans_interface_builder = frontEnd_spikeNetToTVB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_length = 1100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results, simulator, nest_network = backEnd(simulation_length, plotter=plotter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot results and write them to HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "# set to False for faster plotting of only mean field variables and dates, apart from spikes\" rasters:\n",
    "plot_per_neuron = False  \n",
    "MAX_VARS_IN_COLS = 3\n",
    "MAX_REGIONS_IN_ROWS = 10\n",
    "MIN_REGIONS_FOR_RASTER_PLOT = 9\n",
    "\n",
    "# Set the transient time to be optionally removed from results:\n",
    "simulation_length = simulator.simulation_length\n",
    "transient = 0.1 * simulation_length \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVB plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to see what the function above does, take the steps, one by one\n",
    "try:\n",
    "    # We need framework_tvb for writing and reading from HDF5 files\n",
    "    from tvb_multiscale.core.tvb.io.h5_writer import H5Writer\n",
    "    from examples.plot_write_results import write_RegionTimeSeriesXarray_to_h5\n",
    "    writer = H5Writer()\n",
    "    \n",
    "except:\n",
    "    writer = False\n",
    "    \n",
    "# Put the results in a Timeseries instance\n",
    "from tvb.contrib.scripts.datatypes.time_series_xarray import TimeSeriesRegion as TimeSeriesXarray\n",
    "\n",
    "source_ts = None\n",
    "t = simulation_length * simulator.integrator.dt\n",
    "if results is not None:\n",
    "    # Substitute with TimeSeriesRegion fot TVB like functionality:\n",
    "    # from tvb.contrib.scripts.datatypes.time_series import TimeSeriesRegion\n",
    "    source_ts = TimeSeriesXarray(  \n",
    "            data=results[0][1], time=results[0][0],\n",
    "            connectivity=simulator.connectivity,\n",
    "            labels_ordering=[\"Time\", \"State Variable\", \"Region\", \"Neurons\"],\n",
    "            labels_dimensions={\"State Variable\": list(simulator.model.variables_of_interest),\n",
    "                               \"Region\": simulator.connectivity.region_labels.tolist()},\n",
    "            sample_period=simulator.integrator.dt)\n",
    "    source_ts.configure()\n",
    "\n",
    "    t = source_ts.time\n",
    "\n",
    "    # Write to file\n",
    "    if writer:\n",
    "        write_RegionTimeSeriesXarray_to_h5(source_ts, writer,\n",
    "                                           os.path.join(config.out.FOLDER_RES, source_ts.title)+\".h5\")\n",
    "    source_ts   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot TVB time series\n",
    "if source_ts is not None:\n",
    "    source_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                          hue=\"Region\" if source_ts.shape[2] > MAX_REGIONS_IN_ROWS else None, \n",
    "                          per_variable=source_ts.shape[1] > MAX_VARS_IN_COLS, \n",
    "                          figsize=FIGSIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: raster plot\n",
    "if source_ts is not None and source_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "    source_ts.plot_raster(plotter_config=plotter.config, \n",
    "                          per_variable=source_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "                          figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series Raster\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: \n",
    "n_spiking_nodes = len(nest_nodes_inds)\n",
    "if source_ts is not None and n_spiking_nodes:\n",
    "    source_ts_nest = source_ts[:, :, nest_nodes_inds]\n",
    "    source_ts_nest.plot_timeseries(plotter_config=plotter.config, \n",
    "                                   hue=\"Region\" if source_ts_nest.shape[2] > MAX_REGIONS_IN_ROWS else None, \n",
    "                                   per_variable=source_ts_nest.shape[1] > MAX_VARS_IN_COLS, \n",
    "                                   figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: raster plot\n",
    "if source_ts is not None and n_spiking_nodes: # and source_ts_nest.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "    source_ts_nest.plot_raster(plotter_config=plotter.config, \n",
    "                               per_variable=source_ts_nest.shape[1] > MAX_VARS_IN_COLS,\n",
    "                               figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series Raster\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ...interactively as well\n",
    "# # For interactive plotting:\n",
    "# %matplotlib notebook \n",
    "# plotter.plot_timeseries_interactive(source_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiking Network plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeNet_analyzer = None\n",
    "if nest_network is not None:\n",
    "    from tvb_multiscale.core.data_analysis.spiking_network_analyser import SpikingNetworkAnalyser\n",
    "    # Create a SpikingNetworkAnalyzer:\n",
    "    spikeNet_analyzer = \\\n",
    "        SpikingNetworkAnalyser(spikeNet=nest_network,\n",
    "                               start_time=0.0, end_time=simulation_length, \n",
    "                               transient=transient, time_series_output_type=\"TVB\", \n",
    "                               return_data=True, force_homogeneous_results=True, \n",
    "                               period=simulator.monitors[0].period, connectivity=simulator.connectivity\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spikes' raster and mean spike rates and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spikes_res = None\n",
    "if spikeNet_analyzer is not None:\n",
    "    # Spikes rates and correlations per Population and Region\n",
    "    spikes_res = \\\n",
    "        spikeNet_analyzer.\\\n",
    "            compute_spikeNet_spikes_rates_and_correlations(\n",
    "                populations_devices=None, regions=None,\n",
    "                rates_methods=[], rates_kwargs=[{}],rate_results_names=[],\n",
    "                corrs_methods=[], corrs_kwargs=[{}], corrs_results_names=[], bin_kwargs={},\n",
    "                data_method=spikeNet_analyzer.get_spikes_from_device, data_kwargs={},\n",
    "                return_devices=False\n",
    "            );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(spikes_res[\"mean_rate\"])\n",
    "    print(spikes_res[\"spikes_correlation_coefficient\"])\n",
    "    # Plot spikes' rasters together with mean population's spikes' rates' time series\n",
    "    if plotter:\n",
    "        plotter.plot_spike_events(spikes_res[\"spikes\"], mean_results=spikes_res[\"mean_rate\"], # time_series=spikes_res[\"mean_rate_time_series\"], \n",
    "                                  figsize=(20, 22),  \n",
    "                                  stimulus=None,\n",
    "                                  stimulus_linewidth=5.0,\n",
    "                                  spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                                  n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                                  time_axis_min=0.0, time_axis_max=simulation_length)\n",
    "        from tvb_multiscale.core.plot.correlations_plot import plot_correlations\n",
    "        plot_correlations(spikes_res[\"spikes_correlation_coefficient\"], plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(\"Mean spike rates:\")\n",
    "    for pop in spikes_res[\"mean_rate\"].coords[\"Population\"]:\n",
    "        for reg in spikes_res[\"mean_rate\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_res[\"mean_rate\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_res[\"mean_rate\"].loc[pop, reg].values.item()))\n",
    "\n",
    "    # savemat(os.path.join(config.out.FOLDER_RES, \"spikes_mean_rates.mat\"), spikes_res[\"mean_rate\"].to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spikes_sync = None\n",
    "\n",
    "if spikeNet_analyzer is not None:\n",
    "\n",
    "    spikeNet_analyzer.resample = True\n",
    "    spikes_sync = \\\n",
    "        spikeNet_analyzer.compute_spikeNet_synchronization(populations_devices=None, regions=None,\n",
    "                                                           comp_methods=[spikeNet_analyzer.compute_spikes_sync, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_sync_time_series, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_distance, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_distance_time_series,\n",
    "                                                                         spikeNet_analyzer.compute_spikes_isi_distance, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_isi_distance_time_series],\n",
    "                                                           computations_kwargs=[{}], data_kwargs={},\n",
    "                                                           return_spikes_trains=False, return_devices=False)\n",
    "# print(spikes_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_sync_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_sync\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_distance_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_distance\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_isi_distance_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_isi_distance\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike synchronization:\")\n",
    "    for pop in spikes_sync[\"spikes_sync\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_sync\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_sync\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_sync\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_sync.mat\"), spikes_sync[\"spikes_sync\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_sync_time_series.mat\"), spikes_sync[\"spikes_sync_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike distance:\")\n",
    "    for pop in spikes_sync[\"spikes_distance\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_distance\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_distance\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_distance\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_distance.mat\"), spikes_sync[\"spikes_distance\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_distance_time_series.mat\"), spikes_sync[\"spikes_distance_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike ISI distance:\")\n",
    "    for pop in spikes_sync[\"spikes_isi_distance\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_isi_distance\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_isi_distance\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_isi_distance\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_isi_distance.mat\"), spikes_sync[\"spikes_isi_distance\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_isi_distance_time_series.mat\"), spikes_sync[\"spikes_isi_distance_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_res and writer:\n",
    "    writer.write_object(spikes_res[\"spikes\"].to_dict(), \n",
    "                        path=os.path.join(config.out.FOLDER_RES,  \"Spikes\") + \".h5\");\n",
    "    writer.write_object(spikes_res[\"mean_rate\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"mean_rate\"].name) + \".h5\");\n",
    "    write_RegionTimeSeriesXarray_to_h5(spikes_res[\"mean_rate_time_series\"], writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES,\n",
    "                                                    spikes_res[\"mean_rate_time_series\"].title + \".h5\"),\n",
    "                                       recursive=False);\n",
    "    writer.write_object(spikes_res[\"spikes_correlation_coefficient\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"spikes_correlation_coefficient\"].name) + \".h5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  SpikingNetwork mean field variable time series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Continuous time variables' data of spiking neurons\n",
    "spikeNet_ts = None\n",
    "mean_field_ts = None\n",
    "if spikeNet_analyzer:\n",
    "    if plot_per_neuron:\n",
    "        spikeNet_analyzer.return_data = True\n",
    "    else:\n",
    "        spikeNet_analyzer.return_data = False\n",
    "    spikeNet_ts = \\\n",
    "        spikeNet_analyzer. \\\n",
    "             compute_spikeNet_mean_field_time_series(populations_devices=None, regions=None, variables=None,\n",
    "                                                     computations_kwargs={}, data_kwargs={}, return_devices=False)\n",
    "    if spikeNet_ts:\n",
    "        if plot_per_neuron:\n",
    "            mean_field_ts = spikeNet_ts[\"mean_field_time_series\"]  # mean field\n",
    "            spikeNet_ts = spikeNet_ts[\"data_by_neuron\"]  # per neuron data\n",
    "        else:\n",
    "            mean_field_ts = spikeNet_ts\n",
    "            spikeNet_ts = None\n",
    "        if mean_field_ts and mean_field_ts.size > 0:\n",
    "            mean_field_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                                          per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS)\n",
    "            if mean_field_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "                mean_field_ts.plot_raster(plotter_config=plotter.config, \n",
    "                                          per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "                                          linestyle=\"--\", alpha=0.5, linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to file:\n",
    "if mean_field_ts and writer:\n",
    "    write_RegionTimeSeriesXarray_to_h5(mean_field_ts, writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES, mean_field_ts.title + \".h5\"), \n",
    "                                       recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute per neuron spikes' rates times series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if spikes_res and plot_per_neuron:\n",
    "    from tvb.simulator.plot.base_plotter import pyplot\n",
    "    spikeNet_analyzer.return_data = False\n",
    "    rates_ts_per_neuron = \\\n",
    "        spikeNet_analyzer. \\\n",
    "            compute_spikeNet_rates_time_series(populations_devices=None, regions=None,\n",
    "                                               computations_kwargs={}, data_kwargs={},\n",
    "                                               return_spikes_trains=False, return_devices=False);\n",
    "    if rates_ts_per_neuron is not None and rates_ts_per_neuron.size:\n",
    "        # Regions in rows\n",
    "        row = rates_ts_per_neuron.dims[2] if rates_ts_per_neuron.shape[2] > 1 else None\n",
    "        if row is None:\n",
    "            # Populations in rows\n",
    "            row = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "            col = None\n",
    "        else:\n",
    "            # Populations in columns\n",
    "            col = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "        pyplot.figure()\n",
    "        rates_ts_per_neuron.plot(y=rates_ts_per_neuron.dims[3], row=row, col=col, cmap=\"jet\")\n",
    "        plotter.base._save_figure(figure_name=\"Spike rates per neuron\")\n",
    "        # del rates_ts_per_neuron # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot per neuron SpikingNetwork time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regions in rows\n",
    "if spikeNet_ts is not None and spikeNet_ts.size:\n",
    "    row = spikeNet_ts.dims[2] if spikeNet_ts.shape[2] > 1 else None\n",
    "    if row is None:\n",
    "        # Populations in rows\n",
    "        row = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "        col = None\n",
    "    else:\n",
    "        # Populations in cols\n",
    "         col = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "    for var in spikeNet_ts.coords[spikeNet_ts.dims[1]]:\n",
    "        this_var_ts = spikeNet_ts.loc[:, var, :, :, :]\n",
    "        this_var_ts.name = var.item()\n",
    "        pyplot.figure()\n",
    "        this_var_ts.plot(y=spikeNet_ts.dims[4], row=row, col=col, cmap=\"jet\", figsize=FIGSIZE)\n",
    "        plotter.base._save_figure(\n",
    "            figure_name=\"Spiking Network variables' time series per neuron: %s\" % this_var_ts.name)\n",
    "    del spikeNet_ts # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# References\n",
    "\n",
    "1 Paula Sanz Leon, Stuart A. Knock, M. Marmaduke Woodman, Lia Domide, <br>\n",
    "  Jochen Mersmann, Anthony R. McIntosh, Viktor Jirsa (2013) <br>\n",
    "  The Virtual Brain: a simulator of primate brain network dynamics. <br>\n",
    "  Frontiers in Neuroinformatics (7:10. doi: 10.3389/fninf.2013.00010) <br>\n",
    "  https://www.thevirtualbrain.org/tvb/zwei <br>\n",
    "  https://github.com/the-virtual-brain <br>\n",
    "\n",
    "2 Ritter P, Schirner M, McIntosh AR, Jirsa VK. 2013.  <br>\n",
    "  The Virtual Brain integrates computational modeling  <br>\n",
    "  and multimodal neuroimaging. Brain Connectivity 3:121–145. <br>\n",
    "\n",
    "3 Jordan, Jakob; Mørk, Håkon; Vennemo, Stine Brekke;   Terhorst, Dennis; Peyser, <br>\n",
    "  Alexander; Ippen, Tammo; Deepu, Rajalekshmi;   Eppler, Jochen Martin; <br>\n",
    "  van Meegen, Alexander;   Kunkel, Susanne; Sinha, Ankur; Fardet, Tanguy; Diaz, <br>\n",
    "  Sandra; Morrison, Abigail; Schenck, Wolfram; Dahmen, David;   Pronold, Jari; <br>\n",
    "  Stapmanns, Jonas;   Trensch, Guido; Spreizer, Sebastian;   Mitchell, Jessica; <br>\n",
    "  Graber, Steffen; Senk, Johanna; Linssen, Charl; Hahne, Jan; Serenko, Alexey; <br>\n",
    "  Naoumenko, Daniel; Thomson, Eric;   Kitayama, Itaru; Berns, Sebastian;   <br>\n",
    "  Plesser, Hans Ekkehard <br>\n",
    "  NEST is a simulator for spiking neural network models that focuses <br>\n",
    "  on the dynamics, size and structure of neural systems rather than on <br>\n",
    "  the exact morphology of individual neurons. <br>\n",
    "  For further information, visit http://www.nest-simulator.org. <br>\n",
    "  The release notes for this release are available at  <br>\n",
    "  https://github.com/nest/nest-simulator/releases/tag/v2.18.0 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_network.output_interfaces.interfaces[0].proxy_gids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.tvb_to_spikeNet_transform.interfaces[0].transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_network.input_interfaces.interfaces[0].proxy.target[0].global_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
