{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVB-NEST: Bridging multiscale activity by co-simulation\n",
    "\n",
    "## Step-by-step learn how to perform a co-simulation embedding spiking neural networks into large-scale brain networks using TVB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='pics/ConceptGraph1.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='pics/ConceptGraph2.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tvb-multiscale toolbox:\n",
    "\n",
    "### https://github.com/the-virtual-brain/tvb-multiscale\n",
    "\n",
    "For questions use the git issue tracker, or write an e-mail to me: dionysios.perdikis@charite.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T13:37:40.905578Z",
     "start_time": "2019-07-11T13:37:40.894958Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TVB - NEST co-simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilson - Cowan TVB mean field model\n",
    "\n",
    "For every region node $n\\prime$ modelled as a mean-field node in TVB:\n",
    "\n",
    "Population activity dynamics (1 excitatory and 1 inhibitory population):\n",
    "\n",
    " $\\dot{E}_k = \\dfrac{1}{\\tau_e} (-E_k  + (k_e - r_e E_k) \\mathcal{S}_e (\\alpha_e \\left( c_{ee} E_k - c_{ei} I_k  + P_k - \\theta_e + \\mathbf{\\Gamma}(E_k, E_j, u_{kj}) + W_{\\zeta}\\cdot E_j + W_{\\zeta}\\cdot I_j\\right) )) $\n",
    " \n",
    "$\n",
    "            \\dot{I}_k = \\dfrac{1}{\\tau_i} (-I_k  + (k_i - r_i I_k) \\mathcal{S}_i (\\alpha_i \\left( c_{ie} E_k - c_{ee} I_k  + Q_k - \\theta_i + \\mathbf{\\Gamma}(E_k, E_j, u_{kj}) + W_{\\zeta}\\cdot E_j + W_{\\zeta}\\cdot I_j\\right) ))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking network model in NEST\n",
    "\n",
    "using \"iaf_cond_alpha\" spiking neuronal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVB to NEST coupling\n",
    "TVB couples to NEST via instantaneous spike rate $ w_{TVB->NEST} * E(t) $, \n",
    "\n",
    "Inhomogeneous spike generator NEST devices are used as TVB \"proxy\" nodes and generate independent Poisson-random spike trains \n",
    "\n",
    "$ \\left[ \\sum_k \\delta(t-\\tau_{n\\prime n}-{t_j}^k) \\right]_{j \\in n\\prime} $\n",
    "\n",
    "Alternatively, the spike trains are generated outside NEST using the Elephant software and inserted to NEST via spike generator devices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEST to TVB update\n",
    "\n",
    "A NEST spike detector device is used to count spike for each time step, and convert it to an instantaneous population mean rate that overrides\n",
    "\n",
    "$ {E_{_{n}}}(t) =  \\frac{\\sum_j\\left[ \\sum_k \\delta(t-\\tau_n-{t_j}^k) \\right]_{j \\in E_n}}{N_E * dt} $ \n",
    "\n",
    "$ {I_{_{n}}}(t) =  \\frac{\\sum_j\\left[ \\sum_k \\delta(t-\\tau_n-{t_j}^k) \\right]_{j \\in I_n}}{N_I * dt} $\n",
    "\n",
    "in  spikes/sec.\n",
    "\n",
    "This update process concerns only the TVB region nodes that are simulated exclusively in NEST, as spiking networks. All the rest of TVB nodes will follow the equations of the mean field model described above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator loop\n",
    "\n",
    "### Simulating several (i.e., minimally 2) NEST time steps for every 1 TVB time step for stable integration\n",
    "\n",
    "### Synchronizaion every minimum delay time between the two simulators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:57.561354Z",
     "start_time": "2019-07-12T20:35:52.475653Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from tvb_multiscale.tvb_nest.config import Config\n",
    "from examples.parallel.wilson_cowan.config import configure\n",
    "\n",
    "config = configure(config_class=Config)\n",
    "\n",
    "# Select here which kind of test Co-Simulation to perform,\n",
    "# - with Tsync = min_tvb_delay, or\n",
    "# - with Tsync = min_tvb_delay / 2:\n",
    "config.TVB_MIN_IDELAY_TO_SYNC_N_STEP_RATIO = 2\n",
    "# !!! Make sure to delete old data communication files first!!!\n",
    "\n",
    "# For interactive plotting:\n",
    "# %matplotlib notebook  \n",
    "\n",
    "# Otherwise:\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## BACKEND: 1. Load structural data <br> (minimally a TVB connectivity)  <br> & prepare TVB simulator  <br> (region mean field model, integrator, monitors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:59.690799Z",
     "start_time": "2019-07-12T20:35:57.571529Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This would run on TVB only before creating any multiscale cosimulation interface connections.\n",
    "from tvb_multiscale.core.tvb.cosimulator.cosimulator_parallel import CoSimulatorRemoteParallel\n",
    "from examples.parallel.tvb_nest.wilson_cowan.tvb_config import build_tvb_simulator\n",
    "\n",
    "simulator = build_tvb_simulator(config=config, config_class=Config, cosimulator_class=CoSimulatorRemoteParallel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKEND: 2. Build and connect the NEST network model <br> (networks of spiking neural populations for fine-scale <br>regions, stimulation devices, spike detectors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:10.862262Z",
     "start_time": "2019-07-12T20:36:10.000332Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This would run on NEST only before creating any multiscale cosimulation interface connections.\n",
    "# Here it is assumed that the TVB simulator is already created and we can get some of its attributes, \n",
    "# either by directly accessing it, or via serialization.\n",
    "\n",
    "from examples.parallel.tvb_nest.wilson_cowan.nest_config import build_nest_network\n",
    "\n",
    "\n",
    "# nest_network = build_nest_network(config=config, config_class=Config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:19:09.725185Z",
     "start_time": "2019-07-11T10:19:09.721072Z"
    }
   },
   "source": [
    "## FRONTEND: 3. Build the TVB-NEST interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# options for a nonopinionated builder:\n",
    "from tvb_multiscale.core.interfaces.base.transformers.models.models import Transformers\n",
    "from tvb_multiscale.core.interfaces.base.transformers.builders import \\\n",
    "        DefaultTVBtoSpikeNetTransformers, DefaultSpikeNetToTVBTransformers, \\\n",
    "        DefaultTVBtoSpikeNetModels, DefaultSpikeNetToTVBModels\n",
    "from tvb_multiscale.tvb_nest.interfaces.builders import \\\n",
    "        TVBtoNESTModels, NESTInputProxyModels, DefaultTVBtoNESTModels, \\\n",
    "        NESTtoTVBModels, NESTOutputProxyModels, DefaultNESTtoTVBModels\n",
    "\n",
    "    \n",
    "    \n",
    "def print_enum(enum):\n",
    "    print(\"\\n\", enum)\n",
    "    for name, member in enum.__members__.items():\n",
    "        print(name,\"= \", member.value)\n",
    "    \n",
    "    \n",
    "print(\"Available input (NEST->TVB update) / output (TVB->NEST coupling) interface models:\")\n",
    "print_enum(TVBtoNESTModels)\n",
    "print_enum(NESTtoTVBModels)\n",
    "    \n",
    "    \n",
    "print(\"\\n\\nAvailable input (spikeNet->TVB update) / output (TVB->spikeNet coupling) transformer models:\")\n",
    "\n",
    "print_enum(DefaultTVBtoSpikeNetModels)\n",
    "print_enum(DefaultTVBtoSpikeNetTransformers)\n",
    "    \n",
    "print_enum(DefaultSpikeNetToTVBModels)\n",
    "print_enum(DefaultSpikeNetToTVBTransformers)    \n",
    "    \n",
    "    \n",
    "print(\"\\n\\nAvailable input (NEST->TVB update) / output (TVB->NEST coupling) proxy models:\")\n",
    "\n",
    "print_enum(DefaultTVBtoNESTModels)\n",
    "print_enum(NESTInputProxyModels)\n",
    "    \n",
    "print_enum(NESTOutputProxyModels)\n",
    "print_enum(DefaultNESTtoTVBModels)\n",
    "    \n",
    "print(\"\\n\\nAll basic transformer models:\")\n",
    "print_enum(Transformers)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:11.137992Z",
     "start_time": "2019-07-12T20:36:10.880947Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from examples.parallel.tvb_nest.wilson_cowan.tvb_interface_config import configure_TVB_remote_interfaces\n",
    "from examples.parallel.tvb_nest.wilson_cowan.nest_interface_config import configure_NEST_remote_interfaces\n",
    "from examples.parallel.tvb_nest.wilson_cowan.transformers_config import \\\n",
    "    configure_TVBtoNEST_remote_transformer_interfaces, configure_NESTtoTVB_remote_transformer_interfaces\n",
    "\n",
    "tvb_interface_builder = configure_TVB_remote_interfaces(simulator=simulator, config=config, config_class=Config)\n",
    "\n",
    "nest_interface_builder = configure_NEST_remote_interfaces(config=config, config_class=Config)\n",
    "\n",
    "tvb_to_nest_interface_builder = configure_TVBtoNEST_remote_transformer_interfaces(config=config, config_class=Config)\n",
    "\n",
    "nest_to_tvb_interface_builder = configure_NESTtoTVB_remote_transformer_interfaces(config=config, config_class=Config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKEND:\n",
    "### - Build TVB and Spiking Network models and simulators\n",
    "### - Build interfaces\n",
    "### - Configure co-simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tvb_backend_init(config, tvb_cosimulator_builder, **kwargs):\n",
    "    \n",
    "    from tvb_multiscale.core.tvb.cosimulator.cosimulator_builder import CoSimulatorRemoteParallelBuilder\n",
    "    from tvb_multiscale.core.orchestrators.tvb_app import TVBRemoteParallelApp\n",
    "\n",
    "    # Create a TVBApp\n",
    "    tvb_app = TVBRemoteParallelApp(config=config,\n",
    "                                   **kwargs)\n",
    "    # Set...\n",
    "    if isinstance(tvb_cosimulator_builder, CoSimulatorRemoteParallelBuilder):\n",
    "        # ...a TVB CoSimulator builder class instance:\n",
    "        tvb_app.cosimulator_builder = tvb_cosimulator_builder\n",
    "    else:\n",
    "        # ...or, a callable function\n",
    "        tvb_app.cosimulator_builder_function = tvb_cosimulator_builder\n",
    "\n",
    "    tvb_app.start()\n",
    "    # Configure App (and CoSimulator and interface builders)\n",
    "    tvb_app.configure()\n",
    "\n",
    "    # Build (CoSimulator if not built already, and interfaces)\n",
    "    tvb_app.build()\n",
    "    \n",
    "    # Configure App for CoSimulation\n",
    "    tvb_app.configure_simulation()\n",
    "    \n",
    "    return tvb_app\n",
    "\n",
    "\n",
    "\n",
    "def spikeNet_backend_init(config, spiking_network_builder, **kwargs):\n",
    "    \n",
    "    from tvb_multiscale.core.spiking_models.builders.base import SpikingNetworkBuilder\n",
    "    from tvb_multiscale.tvb_nest.orchestrators import NESTRemoteParallelApp\n",
    "\n",
    "    # Create a SpikeNetApp\n",
    "    spikeNet_app = NESTRemoteParallelApp(config=config,\n",
    "                                         synchronization_time=getattr(config, \"SYNCHRONIZATION_TIME\", 0.0),\n",
    "                                         **kwargs)\n",
    "\n",
    "    # Set...\n",
    "    if isinstance(spiking_network_builder, SpikingNetworkBuilder):\n",
    "        # ...a Spiking Network builder class instance:\n",
    "        spikeNet_app.spikeNet_builder = spiking_network_builder\n",
    "    else:\n",
    "        # ...or, a callable function\n",
    "        spikeNet_app.spikeNet_builder_function = spiking_network_builder\n",
    "\n",
    "    spikeNet_app.start()\n",
    "    # Configure App (and CoSimulator and interface builders)\n",
    "    spikeNet_app.configure()\n",
    "\n",
    "    # Build (CoSimulator if not built already, and interfaces)\n",
    "    spikeNet_app.build()\n",
    "\n",
    "    # Configure App for CoSimulation\n",
    "    spikeNet_app.configure_simulation()\n",
    "    \n",
    "    return spikeNet_app\n",
    "\n",
    "\n",
    "\n",
    "def transformers_backend_init(config, transformer_app_class, **kwargs):\n",
    "    \n",
    "    # Create a TransformerApp\n",
    "    transformer_app = \\\n",
    "        transformer_app_class(config=config,\n",
    "                              **kwargs)\n",
    "\n",
    "    transformer_app.start()\n",
    "    # Configure App (and Transformer interface builders)\n",
    "    transformer_app.configure()\n",
    "\n",
    "    # Build (Transformer interfaces)\n",
    "    transformer_app.build()\n",
    "\n",
    "    # Configure App for CoSimulation\n",
    "    transformer_app.configure_simulation()\n",
    "    \n",
    "    return transformer_app\n",
    "\n",
    "\n",
    "def tvb_to_spikeNet_transformer_backend_init(config, **kwargs):\n",
    "    from tvb_multiscale.core.orchestrators.transformer_app import TVBtoSpikeNetRemoteTransformerApp\n",
    "    return transformers_backend_init(config, TVBtoSpikeNetRemoteTransformerApp, **kwargs)\n",
    "\n",
    "\n",
    "def spikeNet_to_tvb_transformer_backend_init(config, **kwargs):\n",
    "    from tvb_multiscale.core.orchestrators.transformer_app import SpikeNetToTVBRemoteTransformerApp\n",
    "    return transformers_backend_init(config, SpikeNetToTVBRemoteTransformerApp, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tvb_app = tvb_backend_init(config, \n",
    "                           tvb_cosimulator_builder=lambda config:\n",
    "                               build_tvb_simulator(config, cosimulator_class=CoSimulatorRemoteParallel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spikeNet_app = spikeNet_backend_init(config, build_nest_network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvb_to_spikeNet_app = tvb_to_spikeNet_transformer_backend_init(config)\n",
    "\n",
    "spikeNet_to_tvb_app = spikeNet_to_tvb_transformer_backend_init(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulate, gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Keep the following cosimulation attributes safe and easy to access:\n",
    "simulation_length = tvb_app.cosimulator.simulation_length \n",
    "synchronization_time = tvb_app.cosimulator.synchronization_time\n",
    "synchronization_n_step = tvb_app.cosimulator.synchronization_n_step  # store the configured value\n",
    "simulation_length += synchronization_time\n",
    "dt = tvb_app.cosimulator.integrator.dt\n",
    "\n",
    "# Initial conditions of co-simulation:\n",
    "# Steps left to simulate:\n",
    "remaining_steps = int(np.round(simulation_length / dt))\n",
    "# Steps already simulated:\n",
    "simulated_steps = 0\n",
    "# TVB initial condition cosimulation coupling towards NEST:\n",
    "tvb_to_trans_cosim_updates = tvb_app.tvb_init_cosim_coupling\n",
    "# NEST initial condition update towards TVB:\n",
    "nest_to_trans_cosim_updates = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:18.879872Z",
     "start_time": "2019-07-12T20:36:11.148945Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def run_for_synchronization_time(tvb_app, nest_app, tvb_to_nest_app, nest_to_tvb_app):\n",
    "#     \"\"\"Function for cosimulating for one loop of synchronization time.\n",
    "#        It could be the highest level possible ENTRYPOINT for a parallel cosimulation.\n",
    "#        In that case, the cosimulation manager would be completely agnostic\n",
    "#        - of what the Apps of the different processed do,\n",
    "#        - including the transformation function they employ.\n",
    "#        The ENTRYPOINT here is just the cosimulation updates' data,\n",
    "#        which are \"thrown over the wall\" for the necessary data exchanges.\n",
    "#     \"\"\"\n",
    "#     # Transform NEST -> TVB updates at time t...\n",
    "#     trans_to_tvb_cosim_updates = nest_to_tvb_app.run_for_synchronization_time()\n",
    "#     # Transform TVB->NEST coupling at time t...\n",
    "#     trans_to_nest_cosim_updates = tvb_to_nest_app.run_for_synchronization_time()\n",
    "#     # TVB t -> t + Tsync\n",
    "#     # Simulate TVB with or without inputs\n",
    "#     tvb_to_trans_cosim_updates = tvb_app.run_for_synchronization_time()\n",
    "#     # NEST t -> t + Tsync\n",
    "#     # Simulate TVB with or without inputs\n",
    "#     nest_to_trans_cosim_updates = nest_app.run_for_synchronization_time()\n",
    "#     # Outputs only for debugging\n",
    "#     return tvb_to_trans_cosim_updates, nest_to_trans_cosim_updates, \\\n",
    "#            trans_to_tvb_cosim_updates, trans_to_nest_cosim_updates\n",
    "\n",
    "\n",
    "def run_for_synchronization_time_sync_min_delay(tvb_app, nest_app, tvb_to_nest_app, nest_to_tvb_app):\n",
    "    \"\"\"Function for cosimulating for one loop of synchronization time.\n",
    "       It could be the highest level possible ENTRYPOINT for a parallel cosimulation.\n",
    "       In that case, the cosimulation manager would be completely agnostic\n",
    "       - of what the Apps of the different processed do,\n",
    "       - including the transformation function they employ.\n",
    "       The ENTRYPOINT here is just the cosimulation updates' data,\n",
    "       which are \"thrown over the wall\" for the necessary data exchanges.\n",
    "    \"\"\"\n",
    "    # Transform TVB -> NEST couplings of times [t, t + Tsync] = [t, t + min_tvb_delay]...\n",
    "    trans_to_nest_cosim_updates = tvb_to_nest_app.run_for_synchronization_time()\n",
    "    # Transform NEST -> TVB updates of times [t - Tsync, t] = [t - min_tvb_delay, t]...\n",
    "    trans_to_tvb_cosim_updates = nest_to_tvb_app.run_for_synchronization_time()\n",
    "    # TVB t -> t + Tsync\n",
    "    # Simulate TVB for times [t, t + Tsync] = [t, t + min_tvb_delay]\n",
    "    # with or without NEST update inputs of times [t - Tsync, t] = [t - min_tvb_delay, t]\n",
    "    tvb_to_trans_cosim_updates = tvb_app.run_for_synchronization_time()\n",
    "    # NEST t -> t + Tsync\n",
    "    # Simulate NEST for times [t, t + Tsync] = [t, t + min_tvb_delay]\n",
    "    # with or without TVB coupling inputs of times [t, t + min_tvb_delay]\n",
    "    nest_to_trans_cosim_updates = nest_app.run_for_synchronization_time()\n",
    "    # Outputs only for debugging\n",
    "    return tvb_to_trans_cosim_updates, trans_to_nest_cosim_updates, \\\n",
    "           nest_to_trans_cosim_updates, trans_to_tvb_cosim_updates\n",
    "\n",
    "\n",
    "def run_for_synchronization_time_sync_min_delay2(tvb_app, nest_app, tvb_to_nest_app, nest_to_tvb_app):\n",
    "    \"\"\"Function for cosimulating for one loop of synchronization time.\n",
    "       It could be the highest level possible ENTRYPOINT for a parallel cosimulation.\n",
    "       In that case, the cosimulation manager would be completely agnostic\n",
    "       - of what the Apps of the different processed do,\n",
    "       - including the transformation function they employ.\n",
    "       The ENTRYPOINT here is just the cosimulation updates' data,\n",
    "       which are \"thrown over the wall\" for the necessary data exchanges.\n",
    "    \"\"\"\n",
    "    # TVB t -> t + Tsync\n",
    "    # Simulate TVB for times [t, t + Tsync] = [t, t + min_tvb_delay]\n",
    "    # with or without NEST update inputs of times [t - Tsync, t] = [t - min_tvb_delay, t]\n",
    "    tvb_to_trans_cosim_updates = tvb_app.run_for_synchronization_time()\n",
    "    # NEST t -> t + Tsync\n",
    "    # Simulate NEST for times [t, t + Tsync] = [t, t + min_tvb_delay]\n",
    "    # with or without TVB coupling inputs of times [t, t + min_tvb_delay]\n",
    "    nest_to_trans_cosim_updates = nest_app.run_for_synchronization_time()\n",
    "    # Transform TVB -> NEST couplings of times [t + Tsync, t + 2*Tsync]=[t + Tsync, t + min_tvb_delay]...\n",
    "    trans_to_nest_cosim_updates = tvb_to_nest_app.run_for_synchronization_time()\n",
    "    # Transform NEST -> TVB updates of times [t, t + Tsync] = [t, t + min_tvb_delay/2]...\n",
    "    trans_to_tvb_cosim_updates = nest_to_tvb_app.run_for_synchronization_time()\n",
    "    # Outputs only for debugging\n",
    "    return tvb_to_trans_cosim_updates, trans_to_nest_cosim_updates, \\\n",
    "           nest_to_trans_cosim_updates, trans_to_tvb_cosim_updates\n",
    "\n",
    "\n",
    "def run_cosimulation(tvb_app, nest_app, tvb_to_nest_app, nest_to_tvb_app,\n",
    "                     advance_simulation_for_delayed_monitors_output=True):\n",
    "    \"\"\"Function for running the whole cosimulation, assuming all Apps are built and configured.\n",
    "       This function shows the necessary initialization of the cosimulation.\n",
    "    \"\"\"\n",
    "\n",
    "    import time\n",
    "    import numpy as np\n",
    "\n",
    "    # Keep the following cosimulation attributes safe and easy to access:\n",
    "    simulation_length = tvb_app.cosimulator.simulation_length \n",
    "    synchronization_time = tvb_app.cosimulator.synchronization_time\n",
    "    synchronization_n_step = tvb_app.cosimulator.synchronization_n_step  # store the configured value\n",
    "    if advance_simulation_for_delayed_monitors_output:\n",
    "        simulation_length += synchronization_time\n",
    "    dt = tvb_app.cosimulator.integrator.dt\n",
    "\n",
    "    # Initial conditions of co-simulation:\n",
    "    # Steps left to simulate:\n",
    "    remaining_steps = int(np.round(simulation_length / dt))\n",
    "    # Steps already simulated:\n",
    "    simulated_steps = 0\n",
    "   # TVB initial condition cosimulation coupling towards NEST for 0...Tsync:\n",
    "    tvb_to_trans_cosim_updates = tvb_app.get_tvb_init_cosim_coupling(relative_output_interfaces_time_steps=0)\n",
    "    if tvb_app.cosimulator.min_idelay_sync_n_step_ratio == 2:\n",
    "        run_for_synchronization_time = run_for_synchronization_time_sync_min_delay2\n",
    "        # Transform the initial condition for [0, Tsync] = [0 min_tvb_delay/2] from TVB to NEST:\n",
    "        if tvb_to_trans_cosim_updates is not None:\n",
    "            # ...if any:\n",
    "            trans_to_nest_cosim_updates = tvb_to_nest_app.run_for_synchronization_time()\n",
    "        else:\n",
    "            trans_to_nest_cosim_updates = None\n",
    "        # Given that this is a TVB coupling interface, \n",
    "        # we advance the data sent from TVB towards the transformer,\n",
    "        # by Tsync = min_tvb_delay / 2\n",
    "        # TVB initial condition cosimulation coupling towards NEST for Tsync....2*Tsync = min_tvb_delay\n",
    "        tvb_to_trans_cosim_updates = tvb_app.get_tvb_init_cosim_coupling(\n",
    "            relative_output_interfaces_time_steps=tvb_app.cosimulator.synchronization_n_step)\n",
    "    else:\n",
    "        run_for_synchronization_time = run_for_synchronization_time_sync_min_delay\n",
    "        trans_to_nest_cosim_updates = None\n",
    "    # nest initial condition update towards TVB:\n",
    "    nest_to_trans_cosim_updates = None\n",
    "    # Transformer to TVB initial condition:\n",
    "    trans_to_tvb_cosim_updates = None\n",
    "    outputs = (tvb_to_trans_cosim_updates, trans_to_nest_cosim_updates, \n",
    "               nest_to_trans_cosim_updates, trans_to_tvb_cosim_updates)\n",
    "    # Loop for steps_to_simulate in steps of synchronization_time:\n",
    "    tvb_app.cosimulator._tic = time.time()\n",
    "    while remaining_steps > 0:\n",
    "        # Set the remaining steps as simulation time, \n",
    "        # if it is less than the original synchronization time:\n",
    "        tvb_app.cosimulator.synchronization_n_step = np.minimum(remaining_steps, synchronization_n_step)\n",
    "        time_to_simulate = dt * tvb_app.cosimulator.synchronization_n_step\n",
    "        tvb_app.cosimulator.synchronization_time = time_to_simulate\n",
    "        nest_app.synchronization_time = time_to_simulate\n",
    "        outputs = run_for_synchronization_time(tvb_app, nest_app, tvb_to_nest_app, nest_to_tvb_app)\n",
    "        simulated_steps += tvb_app.cosimulator.n_tvb_steps_ran_since_last_synch\n",
    "        tvb_app.cosimulator._log_print_progress_message(simulated_steps, simulation_length)\n",
    "        remaining_steps -= tvb_app.cosimulator.n_tvb_steps_ran_since_last_synch\n",
    "\n",
    "    # Update the simulation length of the TVB cosimulator:\n",
    "    tvb_app.cosimulator.simulation_length = simulated_steps * dt  # update the configured value\n",
    "    # Restore the original synchronization_time\n",
    "    tvb_app.cosimulator.synchronization_n_step = synchronization_n_step\n",
    "    tvb_app.cosimulator.synchronization_time = synchronization_time\n",
    "    nest_app.synchronization_time = synchronization_time\n",
    "            \n",
    "    return tvb_app, nest_app, tvb_to_nest_app, nest_to_tvb_app, outputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app, outputs = \\\n",
    "    run_cosimulation(tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app, \n",
    "                     advance_simulation_for_delayed_monitors_output=True)\n",
    "\n",
    "results = tvb_app.return_tvb_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot results and write them to HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "from tvb_multiscale.core.plot.plotter import Plotter\n",
    "\n",
    "\n",
    "# set to False for faster plotting of only mean field variables and dates, apart from spikes\" rasters:\n",
    "plot_per_neuron = False  \n",
    "MAX_VARS_IN_COLS = 3\n",
    "MAX_REGIONS_IN_ROWS = 10\n",
    "MIN_REGIONS_FOR_RASTER_PLOT = 9\n",
    "\n",
    "# Set the transient time to be optionally removed from results:\n",
    "simulation_length = tvb_app.cosimulator.simulation_length\n",
    "transient = getattr(config, \"TRANSIENT\", 0.1*simulation_length)\n",
    "                    \n",
    "simulator = tvb_app.cosimulator\n",
    "nest_network = spikeNet_app.spiking_network\n",
    "nest_nodes_inds = tvb_app.cosimulator.proxy_inds\n",
    "\n",
    "config.figures.SHOW_FLAG = True \n",
    "config.figures.SAVE_FLAG = True\n",
    "config.figures.FIG_FORMAT = 'png'\n",
    "config.figures.DEFAULT_SIZE= config.figures.NOTEBOOK_SIZE\n",
    "FIGSIZE = config.figures.DEFAULT_SIZE\n",
    "\n",
    "plotter = Plotter(config.figures)\n",
    "\n",
    "try:\n",
    "    # We need framework_tvb for writing and reading from HDF5 files\n",
    "    from tvb_multiscale.core.tvb.io.h5_writer import H5Writer\n",
    "    from examples.plot_write_results import write_RegionTimeSeriesXarray_to_h5\n",
    "    writer = H5Writer()\n",
    "    \n",
    "except:\n",
    "    writer = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVB plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "tvb_app.plot(transient=transient, plotter=plotter, writer=writer)\n",
    "    \n",
    "# If you want to see what the function above does, take the steps, one by one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the results in a Timeseries instance\n",
    "from tvb.contrib.scripts.datatypes.time_series_xarray import TimeSeriesRegion as TimeSeriesXarray\n",
    "\n",
    "source_ts = None\n",
    "t = simulation_length * simulator.integrator.dt\n",
    "if results is not None:\n",
    "    # Substitute with TimeSeriesRegion fot TVB like functionality:\n",
    "    # from tvb.contrib.scripts.datatypes.time_series import TimeSeriesRegion\n",
    "    source_ts = TimeSeriesXarray(  \n",
    "            data=results[0][1], time=results[0][0],\n",
    "            connectivity=simulator.connectivity,\n",
    "            labels_ordering=[\"Time\", \"State Variable\", \"Region\", \"Neurons\"],\n",
    "            labels_dimensions={\"State Variable\": list(simulator.model.variables_of_interest),\n",
    "                               \"Region\": simulator.connectivity.region_labels.tolist()},\n",
    "            sample_period=simulator.integrator.dt)\n",
    "    source_ts.configure()\n",
    "\n",
    "    t = source_ts.time\n",
    "\n",
    "    # Write to file\n",
    "    if writer:\n",
    "        write_RegionTimeSeriesXarray_to_h5(source_ts, writer,\n",
    "                                           os.path.join(config.out.FOLDER_RES, source_ts.title)+\".h5\")\n",
    "    source_ts   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot TVB time series\n",
    "if source_ts is not None:\n",
    "    source_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                          hue=\"Region\" if source_ts.shape[2] > MAX_REGIONS_IN_ROWS else None, \n",
    "                          per_variable=source_ts.shape[1] > MAX_VARS_IN_COLS, \n",
    "                          figsize=FIGSIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: raster plot\n",
    "if source_ts is not None and source_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "    source_ts.plot_raster(plotter_config=plotter.config, \n",
    "                          per_variable=source_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "                          figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series Raster\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: \n",
    "n_spiking_nodes = len(nest_nodes_inds)\n",
    "if source_ts is not None and n_spiking_nodes:\n",
    "    source_ts_nest = source_ts[:, :, nest_nodes_inds]\n",
    "    source_ts_nest.plot_timeseries(plotter_config=plotter.config, \n",
    "                                   hue=\"Region\" if source_ts_nest.shape[2] > MAX_REGIONS_IN_ROWS else None, \n",
    "                                   per_variable=source_ts_nest.shape[1] > MAX_VARS_IN_COLS, \n",
    "                                   figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: raster plot\n",
    "if source_ts is not None and n_spiking_nodes: # and source_ts_nest.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "    source_ts_nest.plot_raster(plotter_config=plotter.config, \n",
    "                               per_variable=source_ts_nest.shape[1] > MAX_VARS_IN_COLS,\n",
    "                               figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series Raster\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ...interactively as well\n",
    "# # For interactive plotting:\n",
    "# %matplotlib notebook \n",
    "# plotter.plot_timeseries_interactive(source_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiking Network plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikeNet_app.plot(time=t, transient=transient,\n",
    "#                   plot_per_neuron=plot_per_neuron, plotter=plotter, writer=writer)\n",
    "\n",
    "# If you want to see what the function above does, take the steps, one by one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeNet_analyzer = None\n",
    "if nest_network is not None:\n",
    "    from tvb_multiscale.core.data_analysis.spiking_network_analyser import SpikingNetworkAnalyser\n",
    "    # Create a SpikingNetworkAnalyzer:\n",
    "    spikeNet_analyzer = \\\n",
    "        SpikingNetworkAnalyser(spikeNet=nest_network,\n",
    "                               start_time=0.0, end_time=simulation_length, \n",
    "                               transient=transient, time_series_output_type=\"TVB\", \n",
    "                               return_data=True, force_homogeneous_results=True, \n",
    "                               period=simulator.monitors[0].period, connectivity=simulator.connectivity\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spikes' raster and mean spike rates and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spikes_res = None\n",
    "if spikeNet_analyzer is not None:\n",
    "    # Spikes rates and correlations per Population and Region\n",
    "    spikes_res = \\\n",
    "        spikeNet_analyzer.\\\n",
    "            compute_spikeNet_spikes_rates_and_correlations(\n",
    "                populations_devices=None, regions=None,\n",
    "                rates_methods=[], rates_kwargs=[{}],rate_results_names=[],\n",
    "                corrs_methods=[], corrs_kwargs=[{}], corrs_results_names=[], bin_kwargs={},\n",
    "                data_method=spikeNet_analyzer.get_spikes_from_device, data_kwargs={},\n",
    "                return_devices=False\n",
    "            );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(spikes_res[\"mean_rate\"])\n",
    "    print(spikes_res[\"spikes_correlation_coefficient\"])\n",
    "    # Plot spikes' rasters together with mean population's spikes' rates' time series\n",
    "    if plotter:\n",
    "        plotter.plot_spike_events(spikes_res[\"spikes\"], mean_results=spikes_res[\"mean_rate\"], # time_series=spikes_res[\"mean_rate_time_series\"], \n",
    "                                  figsize=(20, 22),  \n",
    "                                  stimulus=None,\n",
    "                                  stimulus_linewidth=5.0,\n",
    "                                  spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                                  n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                                  time_axis_min=0.0, time_axis_max=simulation_length)\n",
    "        from tvb_multiscale.core.plot.correlations_plot import plot_correlations\n",
    "        plot_correlations(spikes_res[\"spikes_correlation_coefficient\"], plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(\"Mean spike rates:\")\n",
    "    for pop in spikes_res[\"mean_rate\"].coords[\"Population\"]:\n",
    "        for reg in spikes_res[\"mean_rate\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_res[\"mean_rate\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_res[\"mean_rate\"].loc[pop, reg].values.item()))\n",
    "\n",
    "    # savemat(os.path.join(config.out.FOLDER_RES, \"spikes_mean_rates.mat\"), spikes_res[\"mean_rate\"].to_dict())\n",
    "\n",
    "# Mean spike rates with min_nest_delay = 0.1ms and wTVB_to_NEST = 5000.0:\n",
    "# E - bankssts_L: 28.85\n",
    "# E - bankssts_R: 27.8552\n",
    "# I - bankssts_L: 28.85\n",
    "# I - bankssts_R: 27.8552\n",
    "\n",
    "# with min_nest_delay = 1ms and wTVB_to_NEST = 2500.0:\n",
    "\n",
    "# Mean spike rates, with synchronization_time = min_tvb_delay:\n",
    "# E - bankssts_L: 28.3725\n",
    "# E - bankssts_R: 30.1632\n",
    "# I - bankssts_L: 30.8396\n",
    "# I - bankssts_R: 39.7931\n",
    "# completed in 91.5748 sec!\n",
    "\n",
    "# Mean spike rates, with synchronization_time = min_tvb_delay / 2:\n",
    "# E - bankssts_L: 29.1409\n",
    "# E - bankssts_R: 29.8684\n",
    "# I - bankssts_L: 33.8848\n",
    "# I - bankssts_R: 38.8678\n",
    "# completed in 121.62 sec!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spikes_sync = None\n",
    "\n",
    "if spikeNet_analyzer is not None:\n",
    "\n",
    "    spikeNet_analyzer.resample = True\n",
    "    spikes_sync = \\\n",
    "        spikeNet_analyzer.compute_spikeNet_synchronization(populations_devices=None, regions=None,\n",
    "                                                           comp_methods=[spikeNet_analyzer.compute_spikes_sync, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_sync_time_series, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_distance, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_distance_time_series,\n",
    "                                                                         spikeNet_analyzer.compute_spikes_isi_distance, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_isi_distance_time_series],\n",
    "                                                           computations_kwargs=[{}], data_kwargs={},\n",
    "                                                           return_spikes_trains=False, return_devices=False)\n",
    "# print(spikes_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_sync_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_sync\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_distance_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_distance\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_isi_distance_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_isi_distance\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike synchronization:\")\n",
    "    for pop in spikes_sync[\"spikes_sync\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_sync\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_sync\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_sync\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_sync.mat\"), spikes_sync[\"spikes_sync\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_sync_time_series.mat\"), spikes_sync[\"spikes_sync_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike distance:\")\n",
    "    for pop in spikes_sync[\"spikes_distance\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_distance\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_distance\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_distance\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_distance.mat\"), spikes_sync[\"spikes_distance\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_distance_time_series.mat\"), spikes_sync[\"spikes_distance_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike ISI distance:\")\n",
    "    for pop in spikes_sync[\"spikes_isi_distance\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_isi_distance\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_isi_distance\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_isi_distance\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_isi_distance.mat\"), spikes_sync[\"spikes_isi_distance\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_isi_distance_time_series.mat\"), spikes_sync[\"spikes_isi_distance_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_res and writer:\n",
    "    writer.write_object(spikes_res[\"spikes\"].to_dict(), \n",
    "                        path=os.path.join(config.out.FOLDER_RES,  \"Spikes\") + \".h5\");\n",
    "    writer.write_object(spikes_res[\"mean_rate\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"mean_rate\"].name) + \".h5\");\n",
    "    write_RegionTimeSeriesXarray_to_h5(spikes_res[\"mean_rate_time_series\"], writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES,\n",
    "                                                    spikes_res[\"mean_rate_time_series\"].title + \".h5\"),\n",
    "                                       recursive=False);\n",
    "    writer.write_object(spikes_res[\"spikes_correlation_coefficient\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"spikes_correlation_coefficient\"].name) + \".h5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  SpikingNetwork mean field variable time series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Continuous time variables' data of spiking neurons\n",
    "spikeNet_ts = None\n",
    "mean_field_ts = None\n",
    "if spikeNet_analyzer:\n",
    "    if plot_per_neuron:\n",
    "        spikeNet_analyzer.return_data = True\n",
    "    else:\n",
    "        spikeNet_analyzer.return_data = False\n",
    "    spikeNet_ts = \\\n",
    "        spikeNet_analyzer. \\\n",
    "             compute_spikeNet_mean_field_time_series(populations_devices=None, regions=None, variables=None,\n",
    "                                                     computations_kwargs={}, data_kwargs={}, return_devices=False)\n",
    "    if spikeNet_ts:\n",
    "        if plot_per_neuron:\n",
    "            mean_field_ts = spikeNet_ts[\"mean_field_time_series\"]  # mean field\n",
    "            spikeNet_ts = spikeNet_ts[\"data_by_neuron\"]  # per neuron data\n",
    "        else:\n",
    "            mean_field_ts = spikeNet_ts\n",
    "            spikeNet_ts = None\n",
    "        if mean_field_ts and mean_field_ts.size > 0:\n",
    "            mean_field_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                                          per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS)\n",
    "            if mean_field_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "                mean_field_ts.plot_raster(plotter_config=plotter.config, \n",
    "                                          per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "                                          linestyle=\"--\", alpha=0.5, linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to file:\n",
    "if mean_field_ts and writer:\n",
    "    write_RegionTimeSeriesXarray_to_h5(mean_field_ts, writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES, mean_field_ts.title + \".h5\"), \n",
    "                                       recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute per neuron spikes' rates times series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if spikes_res and plot_per_neuron:\n",
    "    from tvb.simulator.plot.base_plotter import pyplot\n",
    "    spikeNet_analyzer.return_data = False\n",
    "    rates_ts_per_neuron = \\\n",
    "        spikeNet_analyzer. \\\n",
    "            compute_spikeNet_rates_time_series(populations_devices=None, regions=None,\n",
    "                                               computations_kwargs={}, data_kwargs={},\n",
    "                                               return_spikes_trains=False, return_devices=False);\n",
    "    if rates_ts_per_neuron is not None and rates_ts_per_neuron.size:\n",
    "        # Regions in rows\n",
    "        row = rates_ts_per_neuron.dims[2] if rates_ts_per_neuron.shape[2] > 1 else None\n",
    "        if row is None:\n",
    "            # Populations in rows\n",
    "            row = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "            col = None\n",
    "        else:\n",
    "            # Populations in columns\n",
    "            col = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "        pyplot.figure()\n",
    "        rates_ts_per_neuron.plot(y=rates_ts_per_neuron.dims[3], row=row, col=col, cmap=\"jet\")\n",
    "        plotter.base._save_figure(figure_name=\"Spike rates per neuron\")\n",
    "        # del rates_ts_per_neuron # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot per neuron SpikingNetwork time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regions in rows\n",
    "if spikeNet_ts is not None and spikeNet_ts.size:\n",
    "    row = spikeNet_ts.dims[2] if spikeNet_ts.shape[2] > 1 else None\n",
    "    if row is None:\n",
    "        # Populations in rows\n",
    "        row = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "        col = None\n",
    "    else:\n",
    "        # Populations in cols\n",
    "         col = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "    for var in spikeNet_ts.coords[spikeNet_ts.dims[1]]:\n",
    "        this_var_ts = spikeNet_ts.loc[:, var, :, :, :]\n",
    "        this_var_ts.name = var.item()\n",
    "        pyplot.figure()\n",
    "        this_var_ts.plot(y=spikeNet_ts.dims[4], row=row, col=col, cmap=\"jet\", figsize=FIGSIZE)\n",
    "        plotter.base._save_figure(\n",
    "            figure_name=\"Spiking Network variables' time series per neuron: %s\" % this_var_ts.name)\n",
    "    del spikeNet_ts # to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def final(app):\n",
    "    app.clean_up()\n",
    "    app.stop()\n",
    "    \n",
    "    \n",
    "final(spikeNet_to_tvb_app)\n",
    "final(tvb_to_spikeNet_app)\n",
    "final(spikeNet_app)\n",
    "final(tvb_app)\n",
    "\n",
    "del tvb_app, spikeNet_app, tvb_to_spikeNet_app, spikeNet_to_tvb_app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# References\n",
    "\n",
    "1 Paula Sanz Leon, Stuart A. Knock, M. Marmaduke Woodman, Lia Domide, <br>\n",
    "  Jochen Mersmann, Anthony R. McIntosh, Viktor Jirsa (2013) <br>\n",
    "  The Virtual Brain: a simulator of primate brain network dynamics. <br>\n",
    "  Frontiers in Neuroinformatics (7:10. doi: 10.3389/fninf.2013.00010) <br>\n",
    "  https://www.thevirtualbrain.org/tvb/zwei <br>\n",
    "  https://github.com/the-virtual-brain <br>\n",
    "\n",
    "2 Ritter P, Schirner M, McIntosh AR, Jirsa VK. 2013.  <br>\n",
    "  The Virtual Brain integrates computational modeling  <br>\n",
    "  and multimodal neuroimaging. Brain Connectivity 3:121–145. <br>\n",
    "\n",
    "3 Jordan, Jakob; Mørk, Håkon; Vennemo, Stine Brekke;   Terhorst, Dennis; Peyser, <br>\n",
    "  Alexander; Ippen, Tammo; Deepu, Rajalekshmi;   Eppler, Jochen Martin; <br>\n",
    "  van Meegen, Alexander;   Kunkel, Susanne; Sinha, Ankur; Fardet, Tanguy; Diaz, <br>\n",
    "  Sandra; Morrison, Abigail; Schenck, Wolfram; Dahmen, David;   Pronold, Jari; <br>\n",
    "  Stapmanns, Jonas;   Trensch, Guido; Spreizer, Sebastian;   Mitchell, Jessica; <br>\n",
    "  Graber, Steffen; Senk, Johanna; Linssen, Charl; Hahne, Jan; Serenko, Alexey; <br>\n",
    "  Naoumenko, Daniel; Thomson, Eric;   Kitayama, Itaru; Berns, Sebastian;   <br>\n",
    "  Plesser, Hans Ekkehard <br>\n",
    "  NEST is a simulator for spiking neural network models that focuses <br>\n",
    "  on the dynamics, size and structure of neural systems rather than on <br>\n",
    "  the exact morphology of individual neurons. <br>\n",
    "  For further information, visit http://www.nest-simulator.org. <br>\n",
    "  The release notes for this release are available at  <br>\n",
    "  https://github.com/nest/nest-simulator/releases/tag/v2.18.0 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
