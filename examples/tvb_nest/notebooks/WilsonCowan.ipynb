{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVB-NEST: Bridging multiscale activity by co-simulation\n",
    "\n",
    "## Step-by-step learn how to perform a co-simulation embedding spiking neural networks into large-scale brain networks using TVB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='pics/ConceptGraph.png',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tvb-multiscale toolbox:\n",
    "\n",
    "### https://github.com/the-virtual-brain/tvb-multiscale\n",
    "\n",
    "For questions use the git issue tracker, or write an e-mail to me: dionysios.perdikis@charite.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T13:37:40.905578Z",
     "start_time": "2019-07-11T13:37:40.894958Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TVB - NEST co-simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilson - Cowan TVB mean field model\n",
    "\n",
    "For every region node $n\\prime$ modelled as a mean-field node in TVB:\n",
    "\n",
    "Population activity dynamics (1 excitatory and 1 inhibitory population):\n",
    "\n",
    " $\\dot{E}_k = \\dfrac{1}{\\tau_e} (-E_k  + (k_e - r_e E_k) \\mathcal{S}_e (\\alpha_e \\left( c_{ee} E_k - c_{ei} I_k  + P_k - \\theta_e + \\mathbf{\\Gamma}(E_k, E_j, u_{kj}) + W_{\\zeta}\\cdot E_j + W_{\\zeta}\\cdot I_j\\right) )) $\n",
    " \n",
    "$\n",
    "            \\dot{I}_k = \\dfrac{1}{\\tau_i} (-I_k  + (k_i - r_i I_k) \\mathcal{S}_i (\\alpha_i \\left( c_{ie} E_k - c_{ee} I_k  + Q_k - \\theta_i + \\mathbf{\\Gamma}(E_k, E_j, u_{kj}) + W_{\\zeta}\\cdot E_j + W_{\\zeta}\\cdot I_j\\right) ))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:57.561354Z",
     "start_time": "2019-07-12T20:35:52.475653Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from tvb.basic.profile import TvbProfile\n",
    "TvbProfile.set_profile(TvbProfile.LIBRARY_PROFILE)\n",
    "\n",
    "from tvb_multiscale.tvb_nest.config import *\n",
    "\n",
    "# ----------- Simulation options ----------------\n",
    "SIM_MODE = \"tvb-nest\"  # \"tvb-nest\"  for multiscale cosimulation, \"tvb\" (\"nest\") for only TVB (NEST) simulation, respectively\n",
    "NEST_MODEL_BUILDERS = None #  , \"opinionated\", \"nonopinionated\", None\n",
    "\n",
    "# For a minimal example, select:\n",
    "N_REGIONS = None # total TVB brain regions\n",
    "NEST_NODES_INDS = np.array([0, 1])  # the brain region nodes to place spiking networks from [0, N_REGIONS-1] interval\n",
    "N_NEURONS = 100 # number of neurons per spiking population\n",
    "\n",
    "# Interface basic configurations:\n",
    "INTERFACE_MODEL = \"RATE\"  # \"RATE\" (or \"SPIKES\", \"CURRENT\") TVB->NEST interface\n",
    "INTERFACE_COUPLING_MODE = \"TVB\"  # \"spikeNet\" # \"TVB\"\n",
    "w_TVB_to_NEST = 2500.0  # TVB->NEST interface scaling weight\n",
    "# -----------------------------------------------\n",
    "\n",
    "work_path = os.getcwd()\n",
    "outputs_path = os.path.join(work_path, \"outputs/TVB-NEST_WilsonCowan%s_%s\" % (INTERFACE_MODEL, INTERFACE_COUPLING_MODE))\n",
    "if NEST_MODEL_BUILDERS is None:\n",
    "    outputs_path += \"NoNESTBuilders\"\n",
    "elif NEST_MODEL_BUILDERS == \"opinionated\":\n",
    "    outputs_path += \"OpinionBuilders\"\n",
    "elif NEST_MODEL_BUILDERS == \"nonopinionated\":\n",
    "    outputs_path += \"NonOpinionBuilders\"\n",
    "    \n",
    "if SIM_MODE.lower() == \"nest\":\n",
    "    outputs_path += \"NESTonly\"\n",
    "elif SIM_MODE.lower() == \"tvb\":\n",
    "    outputs_path += \"TVBonly\"\n",
    "    \n",
    "config = Config(output_base=outputs_path)\n",
    "config.figures.SHOW_FLAG = True \n",
    "config.figures.SAVE_FLAG = True\n",
    "config.figures.FIG_FORMAT = 'png'\n",
    "config.figures.DEFAULT_SIZE= config.figures.NOTEBOOK_SIZE\n",
    "FIGSIZE = config.figures.DEFAULT_SIZE\n",
    "\n",
    "# config.RAY_PARALLEL = False\n",
    "\n",
    "from tvb_multiscale.core.plot.plotter import Plotter\n",
    "plotter = Plotter(config.figures)\n",
    "\n",
    "# For interactive plotting:\n",
    "# %matplotlib notebook  \n",
    "\n",
    "# Otherwise:\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Load structural data <br> (minimally a TVB connectivity)  <br> & prepare TVB simulator  <br> (region mean field model, integrator, monitors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:35:59.690799Z",
     "start_time": "2019-07-12T20:35:57.571529Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This would run on TVB only before creating any multiscale cosimulation interface connections.\n",
    "\n",
    "from tvb_multiscale.core.tvb.cosimulator.models.wilson_cowan_constraint import WilsonCowan\n",
    "\n",
    "\n",
    "# Create a TVB simulator and set all desired inputs\n",
    "# (connectivity, model, surface, stimuli etc)\n",
    "# We choose all defaults in this example\n",
    "# -----------------------------------Wilson Cowan oscillatory regime--------------------------------\n",
    "model_params = {\n",
    "        \"r_e\": np.array([0.0]),\n",
    "        \"r_i\": np.array([0.0]),\n",
    "        \"k_e\": np.array([1.0]),\n",
    "        \"k_i\": np.array([1.0]),\n",
    "        \"tau_e\": np.array([10.0]),\n",
    "        \"tau_i\": np.array([10.0]),\n",
    "        \"c_ee\": np.array([10.0]),\n",
    "        \"c_ei\": np.array([6.0]),\n",
    "        \"c_ie\": np.array([10.0]),\n",
    "        \"c_ii\": np.array([1.0]),\n",
    "        \"alpha_e\": np.array([1.2]),\n",
    "        \"alpha_i\": np.array([2.0]),\n",
    "        \"a_e\": np.array([1.0]),\n",
    "        \"a_i\": np.array([1.0]),\n",
    "        \"b_e\": np.array([0.0]),\n",
    "        \"b_i\": np.array([0.0]),\n",
    "        \"c_e\": np.array([1.0]),\n",
    "        \"c_i\": np.array([1.0]),\n",
    "        \"theta_e\": np.array([2.0]),\n",
    "        \"theta_i\": np.array([3.5]),\n",
    "        \"P\": np.array([0.5]),\n",
    "        \"Q\": np.array([0.0]),\n",
    "        \"shift_sigmoid\": np.array([False])\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------------Build cosimunlator manually--------------------------------\n",
    "from tvb_multiscale.core.tvb.cosimulator.cosimulator_serial import CoSimulatorSerial\n",
    "from tvb.datatypes.connectivity import Connectivity\n",
    "from tvb.simulator.coupling import Linear\n",
    "from tvb.simulator.integrators import HeunStochastic\n",
    "from tvb.simulator.monitors import Raw  # , Bold, EEG\n",
    "\n",
    "\n",
    "# Load connectivity\n",
    "# config.DEFAULT_CONNECTIVITY_ZIP = \"/home/docker/packages/tvb_data/tvb_data/mouse/allen_2mm/ConnectivityAllen2mm.zip\"                                  \n",
    "connectivity = Connectivity.from_file(config.DEFAULT_CONNECTIVITY_ZIP)\n",
    "\n",
    "connectivity.configure()\n",
    "\n",
    "# -------------- Pick a minimal brain of only the first N_REGIONS regions: ----------------\n",
    "if N_REGIONS is not None:\n",
    "    connectivity.number_of_regions = N_REGIONS\n",
    "    connectivity.region_labels = connectivity.region_labels[:N_REGIONS]\n",
    "    connectivity.centres = connectivity.centres[:N_REGIONS]\n",
    "    connectivity.areas = connectivity.areas[:N_REGIONS]\n",
    "    connectivity.orientations = connectivity.orientations[:N_REGIONS]\n",
    "    connectivity.hemispheres = connectivity.hemispheres[:N_REGIONS]\n",
    "    connectivity.cortical = connectivity.cortical[:N_REGIONS]\n",
    "    connectivity.weights = connectivity.weights[:N_REGIONS][:, :N_REGIONS]\n",
    "    connectivity.tract_lengths = connectivity.tract_lengths[:N_REGIONS][:, :N_REGIONS]\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "# Remove diagonal self-connections:\n",
    "np.fill_diagonal(connectivity.weights, 0.0)\n",
    "    \n",
    "# Normalize connectivity weights\n",
    "connectivity.weights /= np.percentile(connectivity.weights, 99)\n",
    "# connectivity.weights[connectivity.weights > 1.0] = 1.0\n",
    "\n",
    "# connectivity.tract_lengths = np.maximum(connectivity.speed * simulator.integrator.dt, \n",
    "#                                          connectivity.tract_lengths)\n",
    "\n",
    "\n",
    "simulator = CoSimulatorSerial()\n",
    "\n",
    "simulator.model = WilsonCowan(**model_params)\n",
    "\n",
    "simulator.connectivity = connectivity\n",
    "\n",
    "simulator.coupling = Linear()\n",
    "\n",
    "simulator.integrator = HeunStochastic()\n",
    "simulator.integrator.dt = 0.1\n",
    "simulator.integrator.noise.nsig = np.array([config.DEFAULT_NSIG, config.DEFAULT_NSIG]) # 0.001\n",
    "\n",
    "simulator.initial_conditions = np.zeros((1, 2, simulator.connectivity.number_of_regions, 1))\n",
    "\n",
    "mon_raw = Raw(period=1.0)  # ms\n",
    "simulator.monitors = (mon_raw, )\n",
    "\n",
    "# # -----------------------------------Or use the CoSimulator builder--------------------------------\n",
    "# from tvb_multiscale.core.tvb.cosimulator.cosimulator_builder import CoSimulatorSerialBuilder\n",
    "\n",
    "# simulator_builder = CoSimulatorSerialBuilder()\n",
    "# simulator_builder.config = config\n",
    "# simulator_builder.model = WilsonCowan()\n",
    "# simulator_builder..connectivity = connectivity\n",
    "# simulator_builder.model_params = model_params\n",
    "# simulator_builder.initial_conditions = np.zeros((1, 1, 1, 1))\n",
    "\n",
    "# simulator_builder.configure()\n",
    "# simulator_builder.print_summary_info_details(recursive=1)\n",
    "\n",
    "# simulator = simulator_builder.build()\n",
    "\n",
    "simulator.configure()\n",
    "\n",
    "\n",
    "# simulator.print_summary_info_details(recursive=1)\n",
    "\n",
    "# Plot TVB connectome:\n",
    "plotter.plot_tvb_connectivity(simulator.connectivity);\n",
    "\n",
    "\n",
    "# Serializing TVB cosimulator is necessary for parallel cosimulation:\n",
    "from tvb_multiscale.core.utils.file_utils import dump_pickled_dict\n",
    "from tvb_multiscale.core.tvb.cosimulator.cosimulator_serialization import serialize_tvb_cosimulator\n",
    "sim_serial_filepath = os.path.join(config.out.FOLDER_RES, \"tvb_serial_cosimulator.pkl\")\n",
    "sim_serial = serialize_tvb_cosimulator(simulator)\n",
    "display(sim_serial)\n",
    "\n",
    "# Dumping the serialized TVB cosimulator to a file will be necessary for parallel cosimulation.\n",
    "dump_pickled_dict(sim_serial, sim_serial_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build and connect the NEST network model <br> (networks of spiking neural populations for fine-scale <br>regions, stimulation devices, spike detectors etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='pics/Example_Net_General.jpg',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking network model in NEST\n",
    "\n",
    "using \"iaf_cond_alpha\" spiking neuronal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:10.862262Z",
     "start_time": "2019-07-12T20:36:10.000332Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This would run on NEST only before creating any multiscale cosimulation interface connections.\n",
    "# Here it is assumed that the TVB simulator is already created and we can get some of its attributes, \n",
    "# either by directly accessing it, or via serialization.\n",
    "\n",
    "\n",
    "nest = None\n",
    "nest_network = None\n",
    "    \n",
    "if \"nest\" in SIM_MODE.lower():\n",
    "    \n",
    "    # Build a NEST network model with the corresponding builder\n",
    "    from tvb_multiscale.tvb_nest.nest_models.builders.nest_factory import load_nest, configure_nest_kernel\n",
    "\n",
    "    from tvb_multiscale.core.utils.file_utils import load_pickled_dict\n",
    "    sim_serial = load_pickled_dict(sim_serial_filepath)\n",
    "\n",
    "    # Load NEST and use defaults to configure its kernel:\n",
    "    nest = configure_nest_kernel(load_nest(config=config), config)\n",
    "\n",
    "    # Local (i.e. within brain region) neuronal populations' connections' rescaling\n",
    "    # to account for the reduction (increase) to the number of neurons,\n",
    "    # with respect to the originally set 100 neurons per population.\n",
    "    w_n_neurons_factor = 100.0 / N_NEURONS\n",
    "\n",
    "    # the brain region nodes to place spiking networks from [0, N_REGIONS-1] interval:\n",
    "    nest_nodes_inds = NEST_NODES_INDS \n",
    "    \n",
    "    if NEST_MODEL_BUILDERS:\n",
    "\n",
    "        if NEST_MODEL_BUILDERS == \"opinionated\":\n",
    "\n",
    "            # ------------------- Instantiating an opinionated nest network builder for this model, ------------------- \n",
    "            # using all default parameters for this example\n",
    "\n",
    "            from tvb_multiscale.tvb_nest.nest_models.models.wilson_cowan import WilsonCowanBuilder\n",
    "\n",
    "            nest_model_builder = WilsonCowanBuilder(sim_serial,  # simulator, \n",
    "                                                    spiking_nodes_inds=nest_nodes_inds, \n",
    "                                                    spiking_simulator=nest, config=config)\n",
    "\n",
    "            # ... or modifying some of the builder's attributes:\n",
    "            nest_model_builder.w_ee = w_n_neurons_factor * sim_serial['model.c_ee'][0]  # simulator.model.c_ie[0]\n",
    "            nest_model_builder.w_ei = w_n_neurons_factor * sim_serial['model.c_ei'][0]  # simulator.model.c_ie[0]\n",
    "            nest_model_builder.w_ie = -w_n_neurons_factor * sim_serial['model.c_ie'][0] # simulator.model.c_ie[0]\n",
    "            nest_model_builder.w_ii = -w_n_neurons_factor * sim_serial['model.c_ii'][0] # simulator.model.c_ii[0]\n",
    "            nest_model_builder.output_devices_record_to = \"memory\"  # \"ascii\"\n",
    "            nest_model_builder.population_order = N_NEURONS\n",
    "            nest_model_builder.tvb_to_spiking_dt_ratio = 2 # 2 NEST integration steps for 1 TVB integration step\n",
    "            nest_model_builder.def_min_delay = config.DEFAULT_SPIKING_MIN_DELAY\n",
    "            nest_model_builder.monitor_period = 1.0\n",
    "\n",
    "        else:\n",
    "\n",
    "            # ------ Alternatively, instantiating a non-opinionated nest network builder for this model, ----------------- \n",
    "            # ... and setting desired network description:\n",
    "\n",
    "            from tvb_multiscale.tvb_nest.nest_models.builders.base import NESTNetworkBuilder\n",
    "\n",
    "            nest_model_builder = NESTNetworkBuilder(sim_serial, # simulator, \n",
    "                                                    spiking_nodes_inds=nest_nodes_inds, \n",
    "                                                    spiking_simulator=nest, config=config)\n",
    "            nest_model_builder.w_ee = w_n_neurons_factor * sim_serial['model.c_ee'][0]  # simulator.model.c_ie[0]\n",
    "            nest_model_builder.w_ei = w_n_neurons_factor * sim_serial['model.c_ei'][0]  # simulator.model.c_ie[0]\n",
    "            nest_model_builder.w_ie = -w_n_neurons_factor * sim_serial['model.c_ie'][0] # simulator.model.c_ie[0]\n",
    "            nest_model_builder.w_ii = -w_n_neurons_factor * sim_serial['model.c_ii'][0] # simulator.model.c_ii[0]\n",
    "            nest_model_builder.output_devices_record_to = \"memory\"  # \"ascii\"\n",
    "            nest_model_builder.population_order = N_NEURONS\n",
    "            nest_model_builder.tvb_to_spiking_dt_ratio = 2 # 2 NEST integration steps for 1 TVB integration step\n",
    "            nest_model_builder.spiking_dt = sim_serial['integrator.dt'] / nest_model_builder.tvb_to_spiking_dt_ratio\n",
    "            nest_model_builder.def_min_delay = config.DEFAULT_SPIKING_MIN_DELAY\n",
    "            nest_model_builder.monitor_period = 1.0\n",
    "\n",
    "            # Set populations:\n",
    "            nest_model_builder.populations = []\n",
    "            for pop in [\"E\", \"I\"]:\n",
    "                nest_model_builder.populations.append(\n",
    "                    {\"label\": pop, \n",
    "                     \"model\": config.DEFAULT_SPIKING_MODEL,  # \"iaf_cond_alpha\" by default\n",
    "                     # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                     \"params\": {},   # parameters for NEST neuronal model\n",
    "                     \"scale\": 1.0,   # nest_model_builder.multiply population_order for the exact populations' size\n",
    "                     # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                     \"nodes\": None}) # None means \"all\" -> building this population to all spiking_nodes_inds\n",
    "\n",
    "\n",
    "            # \"static_synapse\" by default:\n",
    "            synapse_model = config.DEFAULT_CONNECTION[\"synapse_model\"] \n",
    "            # Default conn_spec: {'rule': \"all_to_all\", \"allow_autapses\": True, 'allow_multapses': True}\n",
    "            conn_spec =  config.DEFAULT_CONNECTION[\"conn_spec\"]  \n",
    "\n",
    "            # Set populations' connections within brain region nodes\n",
    "            nest_model_builder.populations_connections = [\n",
    "                {\"source\": \"E\", \"target\": \"E\",  # E -> E This is a self-connection for population \"E\"\n",
    "                 # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                 \"synapse_model\": synapse_model,  \n",
    "                 \"conn_spec\": conn_spec,\n",
    "                 \"weight\": nest_model_builder.w_ee, \n",
    "                 \"delay\": nest_model_builder.def_min_delay, # 1 ms by default\n",
    "                 \"receptor_type\": 0, # default = 0\n",
    "                 # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                 \"nodes\": None}, # None means \"all\" -> performing this connection to all spiking_nodes_inds\n",
    "                {\"source\": \"E\", \"target\": \"I\",  # E -> I\n",
    "                 \"synapse_model\": synapse_model,\n",
    "                 \"conn_spec\": conn_spec, \n",
    "                 \"weight\":nest_model_builder.w_ei, \n",
    "                 \"delay\": nest_model_builder.def_min_delay,\n",
    "                 \"receptor_type\": 0, \n",
    "                 \"nodes\": None},\n",
    "                {\"source\": \"I\", \"target\": \"E\",  # I -> E\n",
    "                 \"synapse_model\": synapse_model,\n",
    "                 \"conn_spec\": conn_spec, \n",
    "                 \"weight\": nest_model_builder.w_ie,\n",
    "                 \"delay\": nest_model_builder.def_min_delay,\n",
    "                 \"receptor_type\": 0, \n",
    "                 \"nodes\": None},\n",
    "                {\"source\": \"I\", \"target\": \"I\",  # I -> I, This is a self-connection for population \"I\"\n",
    "                 \"synapse_model\": synapse_model,\n",
    "                 \"conn_spec\": conn_spec, \n",
    "                 \"weight\": nest_model_builder.w_ii, # -simulator.model.c_ii[0],\n",
    "                 \"delay\": nest_model_builder.def_min_delay,\n",
    "                 \"receptor_type\": 0, \n",
    "                 \"nodes\": None}\n",
    "            ]\n",
    "\n",
    "            # Set populations' connections among brain region node:\n",
    "            nest_model_builder.nodes_connections = [\n",
    "                {\"source\": \"E\", \"target\": [\"E\", \"I\"],\n",
    "                 #--------- Possibly functions of (source_node_ind, target_node_ind, *args, **kwargs) -------------\n",
    "                 \"synapse_model\": synapse_model,\n",
    "                 \"conn_spec\": conn_spec,\n",
    "                 # ...using TVB connectome weights:\n",
    "                 \"weight\": \n",
    "                     lambda source_node_ind, target_node_ind: \n",
    "                         sim_serial['coupling.a'][0] * sim_serial['connectivity.weights'][target_node_ind, source_node_ind],\n",
    "                 # ...using TVB connectome delays\n",
    "                 \"delay\": \n",
    "                     lambda source_node_ind, target_node_ind: \n",
    "                         np.maximum(nest_model_builder.def_min_delay,\n",
    "                                    sim_serial['connectivity.delays'][target_node_ind, source_node_ind]),  \n",
    "                 \"receptor_type\": 0, \n",
    "                 #--------- Possibly functions of (source_node_ind, target_node_ind, *args, **kwargs) -------------\n",
    "                 \"source_nodes\": None,  # None means \"all\" -> performing this connection from all spiking_nodes_inds\n",
    "                 \"target_nodes\": None}  # None means \"all\" -> performing this connection to all spiking_nodes_inds\n",
    "            ]\n",
    "\n",
    "            # Set output recorder devices:\n",
    "            params_spike_recorder = config.NEST_OUTPUT_DEVICES_PARAMS_DEF[\"spike_recorder\"].copy()\n",
    "            params_spike_recorder[\"record_to\"] = nest_model_builder.output_devices_record_to\n",
    "            params_multimeter = config.NEST_OUTPUT_DEVICES_PARAMS_DEF[\"multimeter\"].copy()\n",
    "            params_multimeter[\"record_to\"] = nest_model_builder.output_devices_record_to\n",
    "            params_multimeter[\"interval\"] = nest_model_builder.monitor_period\n",
    "            nest_model_builder.output_devices = [\n",
    "                {\"model\": \"spike_recorder\", \n",
    "                 \"connections\": {\"E\": \"E\",   # Record spikes with label \"E\" from populations \"E\"\n",
    "                                 \"I\": \"I\"},  # Record spikes with label \"I\" from populations \"I\"\n",
    "                 # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                 \"params\": params_spike_recorder,\n",
    "                 # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                 \"nodes\": None},  # None means all here -> recording from all spiking_nodes_inds\n",
    "                {\"model\": \"multimeter\", \n",
    "                 \"connections\": {\"Excitatory\": \"E\",   # Record time series with label \"E_ts\" from populations \"E\"\n",
    "                                 \"Inhibitory\": \"I\"},  # Record time series with label \"I_ts\" from populations \"I\"\n",
    "                 # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                 \"params\": params_multimeter,\n",
    "                 # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                 \"nodes\": None},  # None means all here -> recording from all spiking_nodes_inds\n",
    "\n",
    "            ]\n",
    "\n",
    "\n",
    "            # Set input stimulation devices:\n",
    "            nest_model_builder.input_devices = [\n",
    "                {\"model\": \"poisson_generator\",\n",
    "                \"connections\": {\"Stimulus\": \"E\"}, # connect stimulus \"Stimulus\" to populations \"E\"\n",
    "                 # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                 \"params\": {\"rate\": 7000.0, \"origin\": 0.0, \"start\": nest_model_builder.spiking_dt}, \n",
    "                 \"weights\": 1.0,\n",
    "                 \"delays\": nest_model_builder.def_min_delay,\n",
    "                 \"receptor_type\": 0,\n",
    "                 # ---------------- Possibly functions of spiking_nodes_inds --------------------------\n",
    "                \"nodes\": None  # None means all here -> stimulating all spiking_nodes_inds\n",
    "                }\n",
    "\n",
    "            ]\n",
    "\n",
    "\n",
    "        nest_model_builder.configure()\n",
    "\n",
    "        nest_network = nest_model_builder.build()\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        # ------------------- Construct the NEST network model manually ------------------- \n",
    "\n",
    "        from tvb_multiscale.tvb_nest.nest_models.network import NESTNetwork\n",
    "        from tvb_multiscale.tvb_nest.nest_models.brain import NESTBrain\n",
    "        from tvb_multiscale.tvb_nest.nest_models.region_node import NESTRegionNode\n",
    "        from tvb_multiscale.tvb_nest.nest_models.population import NESTPopulation\n",
    "        from tvb_multiscale.core.spiking_models.devices import DeviceSet, DeviceSets\n",
    "        from tvb_multiscale.tvb_nest.nest_models.devices import NESTSpikeRecorder, NESTMultimeter\n",
    "        from tvb_multiscale.tvb_nest.nest_models.devices import NESTPoissonGenerator\n",
    "\n",
    "\n",
    "        # First configure NEST kernel:\n",
    "        tvb_to_spiking_dt_ratio = 2 # 2 NEST integration steps for 1 TVB integration step\n",
    "        spiking_dt = sim_serial['integrator.dt'] / tvb_to_spiking_dt_ratio\n",
    "        nest.SetKernelStatus({\"resolution\": spiking_dt})\n",
    "\n",
    "        print(\"Building NESTNetwork...\")\n",
    "\n",
    "        # Create NEST network...\n",
    "        nest_network = NESTNetwork(nest)\n",
    "\n",
    "        w_ee = w_n_neurons_factor * sim_serial['model.c_ee'][0]  # simulator.model.c_ie[0]\n",
    "        w_ei = w_n_neurons_factor * sim_serial['model.c_ei'][0]  # simulator.model.c_ie[0]\n",
    "        w_ie = -w_n_neurons_factor * sim_serial['model.c_ie'][0] # simulator.model.c_ie[0]\n",
    "        w_ii = -w_n_neurons_factor * sim_serial['model.c_ii'][0] # simulator.model.c_ii[0]\n",
    "\n",
    "        # ...starting from neuronal populations located at specific brain regions...\n",
    "        nest_network.brain_regions = NESTBrain()\n",
    "        for node_ind in nest_nodes_inds:\n",
    "            region_name = sim_serial['connectivity.region_labels'][node_ind]\n",
    "            # region_name = simulator.connectivity.region_labels[node_ind]\n",
    "            if region_name not in nest_network.brain_regions.keys():\n",
    "                nest_network.brain_regions[region_name] = NESTRegionNode(label=region_name)\n",
    "            for pop in [\"E\", \"I\"]:\n",
    "                nest_network.brain_regions[region_name][pop] = \\\n",
    "                           NESTPopulation(nest.Create(config.DEFAULT_SPIKING_MODEL, N_NEURONS), # possible NEST model params as well here\n",
    "                                          nest, label=pop, brain_region=region_name)\n",
    "                print(\"\\n...created: %s...\" % nest_network.brain_regions[region_name][pop].summary_info())\n",
    "\n",
    "        # \"static_synapse\" by default:\n",
    "        synapse_model = config.DEFAULT_CONNECTION[\"synapse_model\"] \n",
    "        # Default \n",
    "        conn_spec = {'rule': \"all_to_all\", \"allow_autapses\": True, 'allow_multapses': True}\n",
    "\n",
    "\n",
    "        # Connecting populations...\n",
    "        for src_node_ind in nest_nodes_inds: \n",
    "            src_node_lbl = sim_serial['connectivity.region_labels'][src_node_ind]\n",
    "            # src_node_lbl = simulator.connectivity.region_labels[src_node_ind]\n",
    "            for trg_node_ind in nest_nodes_inds: \n",
    "                trg_node_lbl = sim_serial['connectivity.region_labels'][trg_node_ind]\n",
    "                # trg_node_lbl = simulator.connectivity.region_labels[trg_node_ind]\n",
    "                if src_node_ind == trg_node_ind:\n",
    "                    # ...within brain regions...:\n",
    "                    for src_pop, trg_pop, w in zip([\"E\", \"E\", \"I\", \"I\"], \n",
    "                                                   [\"E\", \"I\", \"E\", \"I\"], \n",
    "                                                   [w_ee, w_ei,  w_ie, w_ii]):\n",
    "                        nest.Connect(nest_network.brain_regions[src_node_lbl][src_pop].nodes, \n",
    "                                     nest_network.brain_regions[src_node_lbl][trg_pop].nodes, \n",
    "                                     syn_spec={\"synapse_model\": synapse_model, \n",
    "                                               \"weight\": w, \n",
    "                                               \"delay\": config.DEFAULT_SPIKING_MIN_DELAY, \n",
    "                                               \"receptor_type\": 0}, \n",
    "                                     conn_spec=conn_spec)\n",
    "                        print(\"\\n...connected populations %s -> %s in brain region %s...\" \n",
    "                              % (src_pop, trg_pop, src_node_lbl))\n",
    "                else:\n",
    "\n",
    "                    # ...between brain regions...:\n",
    "                    nest.Connect(nest_network.brain_regions[src_node_lbl][\"E\"].nodes, \n",
    "                                 nest.NodeCollection(nest_network.brain_regions[trg_node_lbl][\"E\"].gids \n",
    "                                                     + nest_network.brain_regions[trg_node_lbl][\"I\"].gids), \n",
    "                                 syn_spec={\"synapse_model\": synapse_model, \n",
    "                                           \"weight\": \n",
    "                                               sim_serial['coupling.a'][0].item() * \n",
    "                                               sim_serial['connectivity.weights'][trg_node_ind, src_node_ind].item(),\n",
    "                                           \"delay\":\n",
    "                                               np.maximum(config.DEFAULT_SPIKING_MIN_DELAY, \n",
    "                                                          sim_serial['connectivity.delays'][trg_node_ind, src_node_ind].item()),\n",
    "                                           \"receptor_type\": 0}, \n",
    "                                 conn_spec=conn_spec)\n",
    "                    print(\"\\n...connected populations E - %s -> [E, I] - %s...\" % (src_node_lbl, trg_node_lbl))\n",
    "\n",
    "\n",
    "        # Create output recorder devices:\n",
    "        params_spike_recorder = config.NEST_OUTPUT_DEVICES_PARAMS_DEF[\"spike_recorder\"].copy()\n",
    "        params_spike_recorder[\"record_to\"] = \"memory\"\n",
    "        params_multimeter = config.NEST_OUTPUT_DEVICES_PARAMS_DEF[\"multimeter\"].copy()\n",
    "        params_multimeter[\"record_to\"] = \"memory\"\n",
    "        params_multimeter[\"interval\"] = 1.0\n",
    "        for pop in [\"E\", \"I\"]:\n",
    "            nest_network.output_devices[pop] = DeviceSet(label=pop, model=\"spike_recorder\")\n",
    "            pop_lbl = np.where(pop == \"E\", \"Excitatory\", \"Inhibitory\").item()\n",
    "            nest_network.output_devices[pop_lbl] = DeviceSet(label=pop_lbl, model=\"multimeter\")\n",
    "            for node_ind in nest_nodes_inds:\n",
    "                region_name = sim_serial['connectivity.region_labels'][node_ind]\n",
    "                # region_name = simulator.connectivity.region_labels[node_ind]\n",
    "\n",
    "                # Create and connect population spike recorder for this region:\n",
    "                nest_network.output_devices[pop][region_name] = \\\n",
    "                    NESTSpikeRecorder(nest.Create(\"spike_recorder\", 1, params=params_spike_recorder), \n",
    "                                      nest, model=\"spike_recorder\", label=pop, brain_region=region_name)\n",
    "                nest.Connect(nest_network.brain_regions[region_name][pop].nodes, \n",
    "                             nest_network.output_devices[pop][region_name].device)\n",
    "                nest_network.output_devices[pop].update() # update DeviceSet after the new NESTDevice entry\n",
    "                print(\"\\n...created spike_recorder device for population %s in brain region %s...\" % (pop, region_name))\n",
    "\n",
    "                # Create and connect population multimeter for this region:\n",
    "                nest_network.output_devices[pop_lbl][region_name] = \\\n",
    "                    NESTMultimeter(nest.Create(\"multimeter\", 1, params=params_multimeter), \n",
    "                                   nest, model=\"multimeter\", label=pop_lbl, brain_region=region_name)\n",
    "                nest.Connect(nest_network.output_devices[pop_lbl][region_name].device, \n",
    "                             nest_network.brain_regions[region_name][pop].nodes)\n",
    "                nest_network.output_devices[pop_lbl].update() # update DeviceSet after the new NESTDevice entry\n",
    "                print(\"\\n...created multimeter device for population %s in brain region %s...\" % (pop, region_name))\n",
    "\n",
    "\n",
    "        # Create input stimulation devices:\n",
    "        nest_network.input_devices[\"Stimulus\"] = DeviceSet(label=\"Stimulus\", model=\"poisson_generator\")\n",
    "        nest_dt = nest.GetKernelStatus('resolution')\n",
    "        for node_ind in nest_nodes_inds:\n",
    "                region_name = sim_serial['connectivity.region_labels'][node_ind]\n",
    "                # region_name = simulator.connectivity.region_labels[node_ind]\n",
    "                # Create and connect population spike recorder for this region:\n",
    "                nest_network.input_devices[\"Stimulus\"][region_name] = \\\n",
    "                    NESTPoissonGenerator(nest.Create(\"poisson_generator\", 1, \n",
    "                                                     params={\"rate\": 7000.0, \"origin\": 0.0, \"start\": nest_dt}), \n",
    "                                         nest, model=\"poisson_generator\", label=\"Stimulus\", brain_region=region_name)\n",
    "                nest.Connect(nest_network.input_devices[\"Stimulus\"][region_name].device,\n",
    "                             nest_network.brain_regions[region_name][\"E\"].nodes, \n",
    "                             syn_spec={\"weight\": 1.0, \"delay\": config.DEFAULT_SPIKING_MIN_DELAY})\n",
    "                nest_network.input_devices[\"Stimulus\"].update()  # update DeviceSet after the new NESTDevice entry\n",
    "                print(\"\\n...created poisson_generator device for population E in brain region %s...\" % region_name)   \n",
    "\n",
    "\n",
    "\n",
    "    # Configure NESTNetwork class:\n",
    "    nest_network.configure()\n",
    "    nest_network.print_summary_info_details(recursive=3, connectivity=True)\n",
    "\n",
    "else:\n",
    "    # the brain region nodes to place spiking networks from [0, N_REGIONS-1] interval:\n",
    "    nest_nodes_inds = np.array([])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T10:19:09.725185Z",
     "start_time": "2019-07-11T10:19:09.721072Z"
    }
   },
   "source": [
    "## 3. Build the TVB-NEST interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvb_spikeNet_model_builder = None\n",
    "\n",
    "if np.all(SIM_MODE.lower() == \"tvb-nest\"):\n",
    "    \n",
    "    # Build a TVB-NEST interface with all the appropriate connections between the\n",
    "    # TVB and NEST modelled regions\n",
    "    \n",
    "#     # ---------------------------- Opinionated TVB<->NEST interface builder----------------------------\n",
    "#     from tvb_multiscale.tvb_nest.interfaces.models.wilson_cowan import WilsonCowanTVBNESTInterfaceBuilder   \n",
    "#     tvb_spikeNet_model_builder =  WilsonCowanTVBNESTInterfaceBuilder(config=config)  # opinionated builder\n",
    "    \n",
    "    # ---------------------------- Non opinionated TVB<->NEST interface builder----------------------------\n",
    "    from tvb_multiscale.tvb_nest.interfaces.builders import TVBNESTInterfaceBuilder   \n",
    "    tvb_spikeNet_model_builder =  TVBNESTInterfaceBuilder(config=config)  # non opinionated builder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:11.137992Z",
     "start_time": "2019-07-12T20:36:10.880947Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if tvb_spikeNet_model_builder is not None:\n",
    "\n",
    "    tvb_spikeNet_model_builder.tvb_cosimulator = simulator            \n",
    "    tvb_spikeNet_model_builder.spiking_network = nest_network\n",
    "    # This can be used to set default tranformer and proxy models:\n",
    "    tvb_spikeNet_model_builder.model = INTERFACE_MODEL  # \"RATE\" (or \"SPIKES\", \"CURRENT\") TVB->NEST interface\n",
    "    tvb_spikeNet_model_builder.input_flag = True   # If True, NEST->TVB update will be implemented\n",
    "    tvb_spikeNet_model_builder.output_flag = True  # If True, TVB->NEST coupling will be implemented\n",
    "    # If default_coupling_mode = \"TVB\", large scale coupling towards spiking regions is computed in TVB\n",
    "    # and then applied with no time delay via a single \"TVB proxy node\" / NEST device for each spiking region,\n",
    "    # \"1-to-1\" TVB->NEST coupling.\n",
    "    # If any other value, we need 1 \"TVB proxy node\" / NEST device for each TVB sender region node, and\n",
    "    # large-scale coupling for spiking regions is computed in NEST, \n",
    "    # taking into consideration the TVB connectome weights and delays, \n",
    "    # in this \"1-to-many\" TVB->NEST coupling.\n",
    "    tvb_spikeNet_model_builder.default_coupling_mode = INTERFACE_COUPLING_MODE  # \"spikeNet\" # \"TVB\" \n",
    "    # Number of neurons per population to be used to compute population mean instantaneous firing rates:\n",
    "    tvb_spikeNet_model_builder.N_E = nest_network.brain_regions[nest_nodes_inds[0]][\"E\"].number_of_neurons\n",
    "    tvb_spikeNet_model_builder.N_I = nest_network.brain_regions[nest_nodes_inds[0]][\"I\"].number_of_neurons\n",
    "    tvb_spikeNet_model_builder.proxy_inds = nest_nodes_inds\n",
    "    # Set exclusive_nodes = True (Default) if the spiking regions substitute for the TVB ones:\n",
    "    tvb_spikeNet_model_builder.exclusive_nodes = True  \n",
    "\n",
    "    tvb_spikeNet_model_builder.output_interfaces = []\n",
    "    tvb_spikeNet_model_builder.input_interfaces = []\n",
    "    \n",
    "   \n",
    "    \n",
    "    # options for a nonopinionated builder:\n",
    "    from tvb_multiscale.core.interfaces.transformers.models.models import Transformers\n",
    "    from tvb_multiscale.core.interfaces.transformers.builders import \\\n",
    "            DefaultTVBtoSpikeNetTransformers, DefaultSpikeNetToTVBTransformers, \\\n",
    "            TVBtoSpikeNetTransformers, SpikeNetToTVBTransformers\n",
    "    from tvb_multiscale.tvb_nest.interfaces.builders import \\\n",
    "            TVBtoNESTModels, NESTInputProxyModels, DefaultTVBtoNESTModels, \\\n",
    "            NESTtoTVBModels, NESTOutputProxyModels, DefaultNESTtoTVBModels\n",
    "\n",
    "\n",
    "    def print_enum_like(enum_like):\n",
    "        print(\"\\n\", enum_like.__name__)\n",
    "        for name, value in enum_like.__dict__.items():\n",
    "            if name[0] != \"_\":\n",
    "                print(name,\"= \", value)\n",
    "\n",
    "    def print_enum(enum):\n",
    "        print(\"\\n\", enum)\n",
    "        for name, member in enum.__members__.items():\n",
    "            print(name,\"= \", member.value)\n",
    "\n",
    "\n",
    "    print(\"Available input (NEST->TVB update) / output (TVB->NEST coupling) interface models:\")\n",
    "    print_enum(TVBtoNESTModels)\n",
    "    print_enum(NESTtoTVBModels)\n",
    "\n",
    "\n",
    "    print(\"\\n\\nAvailable input (spikeNet->TVB update) / output (TVB->spikeNet coupling) transformer models:\")\n",
    "\n",
    "    print_enum(TVBtoSpikeNetTransformers)\n",
    "    print_enum_like(DefaultTVBtoSpikeNetTransformers)\n",
    "\n",
    "    print_enum(SpikeNetToTVBTransformers)\n",
    "    print_enum_like(DefaultSpikeNetToTVBTransformers)    \n",
    "\n",
    "\n",
    "    print(\"\\n\\nAvailable input (NEST->TVB update) / output (TVB->NEST coupling) proxy models:\")\n",
    "\n",
    "    print_enum_like(DefaultTVBtoNESTModels)\n",
    "    print_enum(NESTInputProxyModels)\n",
    "\n",
    "    print_enum(NESTOutputProxyModels)\n",
    "    print_enum_like(DefaultNESTtoTVBModels)\n",
    "\n",
    "    print(\"\\n\\nAll basic transformer models:\")\n",
    "    print_enum(Transformers)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVB to NEST coupling\n",
    "TVB couples to NEST via instantaneous spike rate $ w_{TVB->NEST} * E(t) $, \n",
    "\n",
    "Inhomogeneous spike generator NEST devices are used as TVB \"proxy\" nodes and generate independent Poisson-random spike trains \n",
    "\n",
    "$ \\left[ \\sum_k \\delta(t-\\tau_{n\\prime n}-{t_j}^k) \\right]_{j \\in n\\prime} $\n",
    "\n",
    "Alternatively, the spike trains are generated outside NEST using the Elephant software and inserted to NEST via spike generator devices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Image(filename='pics/TVB-NESTcoupling.jpg',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The above is the case, in which long range coupling towards the spiking region nodes is formed in NEST by connecting them with the TVB proxy nodes, using the weights and delays from TVB connectome.\n",
    "\n",
    "Alternatively, TVB coupling can be computed in TVB just like for any other TVB region node, and then the total coupling towards the spiking region nodes, i.e, $ w_{TVB->NEST} * coupling(t) $ is transferred via one TVB proxy node per target spiking region node, with minimum delay (e.g., equal to a single NEST time step), and unit weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='pics/TVBcoupling-NEST.jpg',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEST to TVB update\n",
    "\n",
    "A NEST spike detector device is used to count spike for each time step, and convert it to an instantaneous population mean rate that ovewrites\n",
    "\n",
    "$ {E_{_{n}}}(t) =  \\frac{\\sum_j\\left[ \\sum_k \\delta(t-\\tau_n-{t_j}^k) \\right]_{j \\in E_n}}{N_E * dt} $ \n",
    "\n",
    "$ {I_{_{n}}}(t) =  \\frac{\\sum_j\\left[ \\sum_k \\delta(t-\\tau_n-{t_j}^k) \\right]_{j \\in I_n}}{N_I * dt} $\n",
    "\n",
    "in  spikes/sec.\n",
    "\n",
    "This update process concerns only the TVB region nodes that are simulated exclusively in NEST, as spiking networks. All the rest of TVB nodes will follow the equations of the mean field model described above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='pics/NEST-TVB.jpg',  width=1000, unconfined=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if tvb_spikeNet_model_builder is not None:\n",
    "\n",
    "#     # Using all default parameters for this example of an opinionated builder\n",
    "#     tvb_spikeNet_model_builder.default_config()\n",
    "   \n",
    "    \n",
    "    # or setting a nonopinionated builder:\n",
    "    from tvb_multiscale.core.interfaces.tvb.interfaces import TVBtoSpikeNetModels\n",
    "    \n",
    "    if tvb_spikeNet_model_builder.default_coupling_mode == \"TVB\":\n",
    "        proxy_inds = nest_nodes_inds\n",
    "    else:\n",
    "        proxy_inds = np.arange(simulator.connectivity.number_of_regions).astype('i')\n",
    "        proxy_inds = np.delete(proxy_inds, nest_nodes_inds)\n",
    "        tvb_spikeNet_model_builder.global_coupling_scaling = np.array([1.0])\n",
    "        w_TVB_to_NEST /= 100\n",
    "    # This is a user defined TVB -> Spiking Network interface configuration:\n",
    "    tvb_spikeNet_model_builder.output_interfaces = \\\n",
    "        [{'voi': np.array([\"E\"]),         # TVB state variable to get data from\n",
    "          'populations': np.array([\"E\"]), # NEST populations to couple to\n",
    "        # --------------- Arguments that can default if not given by the user:------------------------------\n",
    "          'model': tvb_spikeNet_model_builder.model, # This can be used to set default tranformer and proxy models\n",
    "         # 'coupling_mode': 'TVB',         # or \"spikeNet\", \"NEST\", etc\n",
    "         'proxy_inds': proxy_inds,  # TVB proxy region nodes' indices\n",
    "          # Set the enum entry or the corresponding label name for the \"proxy_model\", \n",
    "          # or import and set the appropriate NEST proxy device class, e.g., NESTInhomogeneousPoissonGeneratorSet, directly\n",
    "          # options: \"RATE\", \"RATE_TO_SPIKES\", SPIKES\", \"PARROT_SPIKES\" or CURRENT\"\n",
    "          # see tvb_multiscale.tvb_nest.interfaces.io.NESTInputProxyModels for options and related NESTDevice classes, \n",
    "          # and tvb_multiscale.tvb_nest.interfaces.io.DefaultTVBtoNESTModels for the default choices\n",
    "          'proxy_model': tvb_spikeNet_model_builder.model,  \n",
    "          # Set the enum entry or the corresponding label name for the \"transformer_model\", \n",
    "          # or import and set the appropriate tranformer class, e.g., ScaleRate, directly\n",
    "          # options: \"RATE\", \"SPIKES\", \"SPIKES_SINGE_INTERACTION\", \"SPIKES_MULTIPLE_INTERACTION\", \"CURRENT\"\n",
    "          # see tvb_multiscale.core.interfaces.transformers.models.DefaultTVBtoSpikeNetTransformers for options and related Transformer classes,\n",
    "          # and tvb_multiscale.core.interfaces.transformers.models.DefaultTVBtoSpikeNetModels for default choices\n",
    "          'transformer_model': tvb_spikeNet_model_builder.model,  \n",
    "          'spiking_proxy_inds': nest_nodes_inds  # Same as \"proxy_inds\" for this kind of interface\n",
    "         }\n",
    "        ]\n",
    "    \n",
    "    for interface in tvb_spikeNet_model_builder.output_interfaces:\n",
    "        # The \"scale_factor\" scales the TVB state variable to convert it to an \n",
    "        # instantaneous rate:\n",
    "        if tvb_spikeNet_model_builder.model == TVBtoSpikeNetModels.SPIKES.name:\n",
    "            # The \"number_of_neurons\" will determine how many spike trains will be generated:\n",
    "            interface[\"transformer_params\"] = \\\n",
    "                    {\"scale_factor\": np.array([100*w_TVB_to_NEST]),\n",
    "                     \"number_of_neurons\": np.array([tvb_spikeNet_model_builder.N_E])}\n",
    "        elif tvb_spikeNet_model_builder.model == TVBtoSpikeNetModels.CURRENT.name:  # CURRENT\n",
    "            # Here the rate is a total rate, assuming a number of sending neurons:\n",
    "            interface[\"transformer_params\"] = {\"scale_factor\": w_TVB_to_NEST/25 * np.array([tvb_spikeNet_model_builder.N_E])}\n",
    "        else:  # RATE\n",
    "            # Here the rate is a total rate, assuming a number of sending neurons:\n",
    "            interface[\"transformer_params\"] = {\"scale_factor\": w_TVB_to_NEST * np.array([tvb_spikeNet_model_builder.N_E])}\n",
    "                \n",
    "    # These are user defined Spiking Network -> TVB interfaces configurations:\n",
    "    for pop, sv in zip([\"E\", \"I\"], [\"E\", \"I\"]):\n",
    "        tvb_spikeNet_model_builder.input_interfaces.append(\n",
    "           {'voi': np.array([sv]),\n",
    "            'populations': np.array([pop]),\n",
    "            'proxy_inds': nest_nodes_inds,\n",
    "            # --------------- Arguments that can default if not given by the user:------------------------------\n",
    "            # Set the enum entry or the corresponding label name for the \"proxy_model\", \n",
    "            # or import and set the appropriate NEST proxy device class, e.g., NESTSpikeRecorderMeanSet, directly\n",
    "            # options \"SPIKES\" (i.e., spikes per neuron), \"SPIKES_MEAN\", \"SPIKES_TOTAL\" \n",
    "            # (the last two are identical for the moment returning all populations spikes together)\n",
    "            # see tvb_multiscale.tvb_nest.interfaces.io.NESTOutputProxyModels for options and related NESTDevice classes, \n",
    "            # and tvb_multiscale.tvb_nest.interfaces.io.DefaultNESTtoTVBModels for the default choices\n",
    "            'proxy_model': \"SPIKES_MEAN\",  \n",
    "            # Set the enum entry or the corresponding label name for the \"transformer_model\", \n",
    "            # or import and set the appropriate tranformer class, e.g., ElephantSpikesHistogramRate, directly\n",
    "            # options: \"SPIKES\", \"SPIKES_TO_RATE\", \"SPIKES_TO_HIST\", \"SPIKES_TO_HIST_RATE\"\n",
    "            # see tvb_multiscale.core.interfaces.transformers.models.DefaultSpikeNetToTVBTransformers for options and related Transformer classes,\n",
    "            # and tvb_multiscale.core.interfaces.transformers.models.DefaultSpikeNetToTVBModels for default choices\n",
    "            'transformer_model': \"SPIKES_TO_HIST_RATE\",\n",
    "           }\n",
    "        )\n",
    "    \n",
    "    for interface, N in zip(tvb_spikeNet_model_builder.input_interfaces, \n",
    "                            [tvb_spikeNet_model_builder.N_E, tvb_spikeNet_model_builder.N_I]):\n",
    "        # The \"scale_factor\" scales the instantaneous rate coming from NEST, before setting it to TVB,\n",
    "        # in our case converting the rate to a mean reate \n",
    "        # and scaling it to be in the TVB model's state variable range [0.0, 1.0]\n",
    "        interface[\"transformer_params\"] = {\"scale_factor\": np.array([1e-4]) / N}\n",
    "        \n",
    "    \n",
    "    # Configure and build:\n",
    "    tvb_spikeNet_model_builder.configure()\n",
    "    # tvb_spikeNet_model_builder.print_summary_info_details(recursive=1)\n",
    "    \n",
    "    # This is how the user defined TVB -> Spiking Network interface looks after configuration\n",
    "    print(\"\\noutput (TVB->NEST coupling) interfaces' configurations:\\n\")\n",
    "    display(tvb_spikeNet_model_builder.output_interfaces)\n",
    "    \n",
    "    # This is how the user defined Spiking Network -> TVB interfaces look after configuration\n",
    "    print(\"\\ninput (NEST->TVB update) interfaces' configurations:\\n\")\n",
    "    display(tvb_spikeNet_model_builder.input_interfaces)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if tvb_spikeNet_model_builder is not None:\n",
    "    simulator = tvb_spikeNet_model_builder.build()\n",
    "\n",
    "    simulator.simulate_spiking_simulator = nest_network.nest_instance.Run  # set the method to run NEST\n",
    "    \n",
    "    # simulator.print_summary_info(recursive=3)\n",
    "    # simulator.print_summary_info_details(recursive=3)\n",
    "    \n",
    "    print(\"\\n\\noutput (TVB->NEST coupling) interfaces:\\n\")\n",
    "    simulator.output_interfaces.print_summary_info_details(recursive=2)\n",
    "    \n",
    "    print(\"\\n\\ninput (NEST->TVB update) interfaces:\\n\")\n",
    "    simulator.input_interfaces.print_summary_info_details(recursive=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure simulator, simulate, gather results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator loop\n",
    "\n",
    "### Simulating several (i.e., minimally 2) NEST time steps for every 1 TVB time step for stable integration\n",
    "\n",
    "### Synchronizaion every minimum delay time between the two simulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:36:18.879872Z",
     "start_time": "2019-07-12T20:36:11.148945Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Configure the simulator with the TVB-NEST interface...\n",
    "# ...and simulate!\n",
    "\n",
    "# Set the simulation time:\n",
    "simulator.simulation_length = 1100.0\n",
    "\n",
    "tic = time.time()\n",
    "if np.all(SIM_MODE.lower() == \"tvb\"):\n",
    "    # For TVB \n",
    "    results = simulator.run()\n",
    "else:\n",
    "    if np.all(SIM_MODE.lower() == \"nest\"):\n",
    "        print(\"Simulating only NEST...\")\n",
    "        # Integrate NEST for simulation_length + 1 NEST time step so that multimeters get the last time point\n",
    "        # unless you plan to continue simulation later\n",
    "        nest_network.nest_instance.Simulate(simulator.simulation_length + nest_network.nest_instance.GetKernelStatus(\"resolution\"))\n",
    "        results = None\n",
    "    else:\n",
    "        print(\"Simulating TVB-NEST...\")\n",
    "        nest_network.nest_instance.Prepare()\n",
    "        simulator.configure()\n",
    "        # Adjust simulation length to be an integer multiple of synchronization_time:\n",
    "        simulator.simulation_length = \\\n",
    "            np.ceil(simulator.simulation_length / simulator.synchronization_time) * simulator.synchronization_time\n",
    "        results = simulator.run()\n",
    "        nest_network.nest_instance.Run(nest_network.nest_instance.GetKernelStatus(\"resolution\"))\n",
    "        #  Cleanup NEST network unless you plan to continue simulation later\n",
    "        nest_network.nest_instance.Cleanup()\n",
    "\n",
    "print(\"\\nSimulated in %f secs!\" % (time.time() - tic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot results and write them to HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "# set to False for faster plotting of only mean field variables and dates, apart from spikes\" rasters:\n",
    "plot_per_neuron = False  \n",
    "MAX_VARS_IN_COLS = 3\n",
    "MAX_REGIONS_IN_ROWS = 10\n",
    "MIN_REGIONS_FOR_RASTER_PLOT = 9\n",
    "\n",
    "# Set the transient time to be optionally removed from results:\n",
    "simulation_length = simulator.simulation_length\n",
    "transient = 100.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVB plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to see what the function above does, take the steps, one by one\n",
    "try:\n",
    "    # We need framework_tvb for writing and reading from HDF5 files\n",
    "    from tvb_multiscale.core.tvb.io.h5_writer import H5Writer\n",
    "    from examples.plot_write_results import write_RegionTimeSeriesXarray_to_h5\n",
    "    writer = H5Writer()\n",
    "    \n",
    "except:\n",
    "    writer = None\n",
    "    \n",
    "# Put the results in a Timeseries instance\n",
    "from tvb.contrib.scripts.datatypes.time_series_xarray import TimeSeriesRegion as TimeSeriesXarray\n",
    "\n",
    "source_ts = None\n",
    "t = simulation_length * simulator.integrator.dt\n",
    "if results is not None:\n",
    "    # Substitute with TimeSeriesRegion fot TVB like functionality:\n",
    "    # from tvb.contrib.scripts.datatypes.time_series import TimeSeriesRegion\n",
    "    source_ts = TimeSeriesXarray(  \n",
    "            data=results[0][1], time=results[0][0],\n",
    "            connectivity=simulator.connectivity,\n",
    "            labels_ordering=[\"Time\", \"State Variable\", \"Region\", \"Neurons\"],\n",
    "            labels_dimensions={\"State Variable\": list(simulator.model.variables_of_interest),\n",
    "                               \"Region\": simulator.connectivity.region_labels.tolist()},\n",
    "            sample_period=simulator.integrator.dt)\n",
    "    source_ts.configure()\n",
    "\n",
    "    t = source_ts.time\n",
    "\n",
    "    # Write to file\n",
    "    if writer:\n",
    "        write_RegionTimeSeriesXarray_to_h5(source_ts, writer,\n",
    "                                           os.path.join(config.out.FOLDER_RES, source_ts.title)+\".h5\")\n",
    "    source_ts   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot TVB time series\n",
    "if source_ts is not None:\n",
    "    source_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                          hue=\"Region\" if source_ts.shape[2] > MAX_REGIONS_IN_ROWS else None, \n",
    "                          per_variable=source_ts.shape[1] > MAX_VARS_IN_COLS, \n",
    "                          figsize=FIGSIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: raster plot\n",
    "if source_ts is not None and source_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "    source_ts.plot_raster(plotter_config=plotter.config, \n",
    "                          per_variable=source_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "                          figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series Raster\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: \n",
    "n_spiking_nodes = len(nest_nodes_inds)\n",
    "if source_ts is not None and n_spiking_nodes:\n",
    "    source_ts_nest = source_ts[:, :, nest_nodes_inds]\n",
    "    source_ts_nest.plot_timeseries(plotter_config=plotter.config, \n",
    "                                   hue=\"Region\" if source_ts_nest.shape[2] > MAX_REGIONS_IN_ROWS else None, \n",
    "                                   per_variable=source_ts_nest.shape[1] > MAX_VARS_IN_COLS, \n",
    "                                   figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Focus on the nodes modelled in NEST: raster plot\n",
    "if source_ts is not None and n_spiking_nodes: # and source_ts_nest.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "    source_ts_nest.plot_raster(plotter_config=plotter.config, \n",
    "                               per_variable=source_ts_nest.shape[1] > MAX_VARS_IN_COLS,\n",
    "                               figsize=FIGSIZE, figname=\"Spiking nodes TVB Time Series Raster\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ...interactively as well\n",
    "# # For interactive plotting:\n",
    "# %matplotlib notebook \n",
    "# plotter.plot_timeseries_interactive(source_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiking Network plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeNet_analyzer = None\n",
    "if nest_network is not None:\n",
    "    from tvb_multiscale.core.data_analysis.spiking_network_analyser import SpikingNetworkAnalyser\n",
    "    # Create a SpikingNetworkAnalyzer:\n",
    "    spikeNet_analyzer = \\\n",
    "        SpikingNetworkAnalyser(spikeNet=nest_network,\n",
    "                               start_time=0.0, end_time=simulation_length, \n",
    "                               transient=transient, time_series_output_type=\"TVB\", \n",
    "                               return_data=True, force_homogeneous_results=True, \n",
    "                               period=simulator.monitors[0].period, connectivity=simulator.connectivity\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spikes' raster and mean spike rates and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spikes_res = None\n",
    "if spikeNet_analyzer is not None:\n",
    "    # Spikes rates and correlations per Population and Region\n",
    "    spikes_res = \\\n",
    "        spikeNet_analyzer.\\\n",
    "            compute_spikeNet_spikes_rates_and_correlations(\n",
    "                populations_devices=None, regions=None,\n",
    "                rates_methods=[], rates_kwargs=[{}],rate_results_names=[],\n",
    "                corrs_methods=[], corrs_kwargs=[{}], corrs_results_names=[], bin_kwargs={},\n",
    "                data_method=spikeNet_analyzer.get_spikes_from_device, data_kwargs={},\n",
    "                return_devices=False\n",
    "            );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(spikes_res[\"mean_rate\"])\n",
    "    print(spikes_res[\"spikes_correlation_coefficient\"])\n",
    "    # Plot spikes' rasters together with mean population's spikes' rates' time series\n",
    "    if plotter:\n",
    "        plotter.plot_spike_events(spikes_res[\"spikes\"], mean_results=spikes_res[\"mean_rate\"], # time_series=spikes_res[\"mean_rate_time_series\"], \n",
    "                                  figsize=(20, 22),  \n",
    "                                  stimulus=None,\n",
    "                                  stimulus_linewidth=5.0,\n",
    "                                  spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                                  n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                                  time_axis_min=0.0, time_axis_max=simulation_length)\n",
    "        from tvb_multiscale.core.plot.correlations_plot import plot_correlations\n",
    "        plot_correlations(spikes_res[\"spikes_correlation_coefficient\"], plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_res:\n",
    "    print(\"Mean spike rates:\")\n",
    "    for pop in spikes_res[\"mean_rate\"].coords[\"Population\"]:\n",
    "        for reg in spikes_res[\"mean_rate\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_res[\"mean_rate\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_res[\"mean_rate\"].loc[pop, reg].values.item()))\n",
    "\n",
    "    # savemat(os.path.join(config.out.FOLDER_RES, \"spikes_mean_rates.mat\"), spikes_res[\"mean_rate\"].to_dict())\n",
    "\n",
    "\n",
    "# RAY_PARALLEL = False:\n",
    "# No spiking model builders!\n",
    "# TODO: Figure out the reasons for the differences!:\n",
    "# Mean spike rates:\n",
    "# With def_min_delay = 0.1 ms and w_TVB_to_NEST = 5000.0:\n",
    "# E - bankssts_L: 27.8552\n",
    "# E - bankssts_R: 27.875\n",
    "# I - bankssts_L: 27.8552\n",
    "# I - bankssts_R: 27.8552\n",
    "# With def_min_delay = 1.0 ms and w_TVB_to_NEST = 2500.0:\n",
    "# Mean spike rates:\n",
    "# E - bankssts_L: 28.1138\n",
    "# E - bankssts_R: 28.2829\n",
    "# I - bankssts_L: 27.8552\n",
    "# I - bankssts_R: 30.8396\n",
    "# Simulated in 4.756102 secs! when built with Dockerfile\n",
    "# Simulated in 77.105816 secs! when built with DockerfileNEST...\n",
    "\n",
    "# RAY_PARALLEL = True:\n",
    "# E - bankssts_L: 28.1138\n",
    "# E - bankssts_R: 28.2829\n",
    "# I - bankssts_L: 27.8552\n",
    "# I - bankssts_R: 30.8396\n",
    "# Simulated in 10.579931 secs! when built with Dockerfile\n",
    "\n",
    "# Nonopinionated spiking model builders:\n",
    "# Mean spike rates:\n",
    "# E - bankssts_L: 28.1138\n",
    "# E - bankssts_R: 28.2829\n",
    "# I - bankssts_L: 27.8552\n",
    "# I - bankssts_R: 30.8396\n",
    "\n",
    "# Opinionated spiking model builders:\n",
    "# Mean spike rates:\n",
    "# E - bankssts_L: 28.1138\n",
    "# E - bankssts_R: 28.2829\n",
    "# I - bankssts_L: 27.8552\n",
    "# I - bankssts_R: 30.8396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spikes_sync = None\n",
    "\n",
    "if spikeNet_analyzer is not None:\n",
    "\n",
    "    spikeNet_analyzer.resample = True\n",
    "    spikes_sync = \\\n",
    "        spikeNet_analyzer.compute_spikeNet_synchronization(populations_devices=None, regions=None,\n",
    "                                                           comp_methods=[spikeNet_analyzer.compute_spikes_sync, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_sync_time_series, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_distance, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_distance_time_series,\n",
    "                                                                         spikeNet_analyzer.compute_spikes_isi_distance, \n",
    "                                                                         spikeNet_analyzer.compute_spikes_isi_distance_time_series],\n",
    "                                                           computations_kwargs=[{}], data_kwargs={},\n",
    "                                                           return_spikes_trains=False, return_devices=False)\n",
    "# print(spikes_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_sync_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_sync\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_distance_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_distance\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    plotter.config.FONTSIZE = 20 # plotter.config.LARGE_FONTSIZE  # LARGE = 12, default = 10\n",
    "    plotter.plot_spike_events(spikes_res[\"spikes\"], \n",
    "                              time_series=spikes_sync[\"spikes_isi_distance_time_series\"], \n",
    "                              mean_results=spikes_sync[\"spikes_isi_distance\"], \n",
    "                              stimulus_linewidth=5.0,\n",
    "                              spikes_markersize=0.5, spikes_alpha=0.5,\n",
    "                              n_y_ticks=3, n_time_ticks=5, show_time_axis=True, \n",
    "                              time_axis_min=0.0, time_axis_max=simulation_length, figsize=(20, 22)\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike synchronization:\")\n",
    "    for pop in spikes_sync[\"spikes_sync\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_sync\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_sync\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_sync\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_sync.mat\"), spikes_sync[\"spikes_sync\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_sync_time_series.mat\"), spikes_sync[\"spikes_sync_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike distance:\")\n",
    "    for pop in spikes_sync[\"spikes_distance\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_distance\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_distance\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_distance\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_distance.mat\"), spikes_sync[\"spikes_distance\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_distance_time_series.mat\"), spikes_sync[\"spikes_distance_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_sync:\n",
    "    print(\"Spike ISI distance:\")\n",
    "    for pop in spikes_sync[\"spikes_isi_distance\"].coords[\"Population\"]:\n",
    "        for reg in spikes_sync[\"spikes_isi_distance\"].coords[\"Region\"]:\n",
    "            if not np.isnan(spikes_sync[\"spikes_isi_distance\"].loc[pop, reg]):\n",
    "                print(\"%s - %s: %g\" % (pop.values.item().split(\"_spikes\")[0], reg.values.item(), \n",
    "                                       spikes_sync[\"spikes_isi_distance\"].loc[pop, reg].values.item()))\n",
    "\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_isi_distance.mat\"), spikes_sync[\"spikes_isi_distance\"].to_dict())\n",
    "#     savemat(os.path.join(config.out.FOLDER_RES, \"spikes_isi_distance_time_series.mat\"), spikes_sync[\"spikes_isi_distance_time_series\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if spikes_res and writer:\n",
    "    writer.write_object(spikes_res[\"spikes\"].to_dict(), \n",
    "                        path=os.path.join(config.out.FOLDER_RES,  \"Spikes\") + \".h5\");\n",
    "    writer.write_object(spikes_res[\"mean_rate\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"mean_rate\"].name) + \".h5\");\n",
    "    write_RegionTimeSeriesXarray_to_h5(spikes_res[\"mean_rate_time_series\"], writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES,\n",
    "                                                    spikes_res[\"mean_rate_time_series\"].title + \".h5\"),\n",
    "                                       recursive=False);\n",
    "    writer.write_object(spikes_res[\"spikes_correlation_coefficient\"].to_dict(),\n",
    "                        path=os.path.join(config.out.FOLDER_RES,\n",
    "                                          spikes_res[\"spikes_correlation_coefficient\"].name) + \".h5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  SpikingNetwork mean field variable time series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Continuous time variables' data of spiking neurons\n",
    "spikeNet_ts = None\n",
    "mean_field_ts = None\n",
    "if spikeNet_analyzer:\n",
    "    if plot_per_neuron:\n",
    "        spikeNet_analyzer.return_data = True\n",
    "    else:\n",
    "        spikeNet_analyzer.return_data = False\n",
    "    spikeNet_ts = \\\n",
    "        spikeNet_analyzer. \\\n",
    "             compute_spikeNet_mean_field_time_series(populations_devices=None, regions=None, variables=None,\n",
    "                                                     computations_kwargs={}, data_kwargs={}, return_devices=False)\n",
    "    if spikeNet_ts:\n",
    "        if plot_per_neuron:\n",
    "            mean_field_ts = spikeNet_ts[\"mean_field_time_series\"]  # mean field\n",
    "            spikeNet_ts = spikeNet_ts[\"data_by_neuron\"]  # per neuron data\n",
    "        else:\n",
    "            mean_field_ts = spikeNet_ts\n",
    "            spikeNet_ts = None\n",
    "        if mean_field_ts and mean_field_ts.size > 0:\n",
    "            mean_field_ts.plot_timeseries(plotter_config=plotter.config, \n",
    "                                          per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS)\n",
    "            if mean_field_ts.number_of_labels > MIN_REGIONS_FOR_RASTER_PLOT:\n",
    "                mean_field_ts.plot_raster(plotter_config=plotter.config, \n",
    "                                          per_variable=mean_field_ts.shape[1] > MAX_VARS_IN_COLS,\n",
    "                                          linestyle=\"--\", alpha=0.5, linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to file:\n",
    "if mean_field_ts and writer:\n",
    "    write_RegionTimeSeriesXarray_to_h5(mean_field_ts, writer,\n",
    "                                       os.path.join(config.out.FOLDER_RES, mean_field_ts.title + \".h5\"), \n",
    "                                       recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute per neuron spikes' rates times series and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if spikes_res and plot_per_neuron:\n",
    "    from tvb.simulator.plot.base_plotter import pyplot\n",
    "    spikeNet_analyzer.return_data = False\n",
    "    rates_ts_per_neuron = \\\n",
    "        spikeNet_analyzer. \\\n",
    "            compute_spikeNet_rates_time_series(populations_devices=None, regions=None,\n",
    "                                               computations_kwargs={}, data_kwargs={},\n",
    "                                               return_spikes_trains=False, return_devices=False);\n",
    "    if rates_ts_per_neuron is not None and rates_ts_per_neuron.size:\n",
    "        # Regions in rows\n",
    "        row = rates_ts_per_neuron.dims[2] if rates_ts_per_neuron.shape[2] > 1 else None\n",
    "        if row is None:\n",
    "            # Populations in rows\n",
    "            row = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "            col = None\n",
    "        else:\n",
    "            # Populations in columns\n",
    "            col = rates_ts_per_neuron.dims[1] if rates_ts_per_neuron.shape[1] > 1 else None\n",
    "        pyplot.figure()\n",
    "        rates_ts_per_neuron.plot(y=rates_ts_per_neuron.dims[3], row=row, col=col, cmap=\"jet\")\n",
    "        plotter.base._save_figure(figure_name=\"Spike rates per neuron\")\n",
    "        # del rates_ts_per_neuron # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot per neuron SpikingNetwork time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regions in rows\n",
    "if spikeNet_ts is not None and spikeNet_ts.size:\n",
    "    row = spikeNet_ts.dims[2] if spikeNet_ts.shape[2] > 1 else None\n",
    "    if row is None:\n",
    "        # Populations in rows\n",
    "        row = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "        col = None\n",
    "    else:\n",
    "        # Populations in cols\n",
    "         col = spikeNet_ts.dims[3] if spikeNet_ts.shape[3] > 1 else None\n",
    "    for var in spikeNet_ts.coords[spikeNet_ts.dims[1]]:\n",
    "        this_var_ts = spikeNet_ts.loc[:, var, :, :, :]\n",
    "        this_var_ts.name = var.item()\n",
    "        pyplot.figure()\n",
    "        this_var_ts.plot(y=spikeNet_ts.dims[4], row=row, col=col, cmap=\"jet\", figsize=FIGSIZE)\n",
    "        plotter.base._save_figure(\n",
    "            figure_name=\"Spiking Network variables' time series per neuron: %s\" % this_var_ts.name)\n",
    "    del spikeNet_ts # to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# References\n",
    "\n",
    "1 Paula Sanz Leon, Stuart A. Knock, M. Marmaduke Woodman, Lia Domide, <br>\n",
    "  Jochen Mersmann, Anthony R. McIntosh, Viktor Jirsa (2013) <br>\n",
    "  The Virtual Brain: a simulator of primate brain network dynamics. <br>\n",
    "  Frontiers in Neuroinformatics (7:10. doi: 10.3389/fninf.2013.00010) <br>\n",
    "  https://www.thevirtualbrain.org/tvb/zwei <br>\n",
    "  https://github.com/the-virtual-brain <br>\n",
    "\n",
    "2 Ritter P, Schirner M, McIntosh AR, Jirsa VK. 2013.  <br>\n",
    "  The Virtual Brain integrates computational modeling  <br>\n",
    "  and multimodal neuroimaging. Brain Connectivity 3:121145. <br>\n",
    "\n",
    "3 Jordan, Jakob; Mrk, Hkon; Vennemo, Stine Brekke;   Terhorst, Dennis; Peyser, <br>\n",
    "  Alexander; Ippen, Tammo; Deepu, Rajalekshmi;   Eppler, Jochen Martin; <br>\n",
    "  van Meegen, Alexander;   Kunkel, Susanne; Sinha, Ankur; Fardet, Tanguy; Diaz, <br>\n",
    "  Sandra; Morrison, Abigail; Schenck, Wolfram; Dahmen, David;   Pronold, Jari; <br>\n",
    "  Stapmanns, Jonas;   Trensch, Guido; Spreizer, Sebastian;   Mitchell, Jessica; <br>\n",
    "  Graber, Steffen; Senk, Johanna; Linssen, Charl; Hahne, Jan; Serenko, Alexey; <br>\n",
    "  Naoumenko, Daniel; Thomson, Eric;   Kitayama, Itaru; Berns, Sebastian;   <br>\n",
    "  Plesser, Hans Ekkehard <br>\n",
    "  NEST is a simulator for spiking neural network models that focuses <br>\n",
    "  on the dynamics, size and structure of neural systems rather than on <br>\n",
    "  the exact morphology of individual neurons. <br>\n",
    "  For further information, visit http://www.nest-simulator.org. <br>\n",
    "  The release notes for this release are available at  <br>\n",
    "  https://github.com/nest/nest-simulator/releases/tag/v2.18.0 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
